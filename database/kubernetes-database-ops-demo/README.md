# Kubernetesæ•°æ®åº“è¿ç»´å®Œæ•´æŒ‡å—

## ğŸ¯ æ¦‚è¿°

Kubernetesæ•°æ®åº“è¿ç»´æ˜¯ç°ä»£äº‘åŸç”Ÿæ•°æ®åº“ç®¡ç†çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œé€šè¿‡Operatoræ¨¡å¼ã€StatefulSetå’Œè‡ªåŠ¨åŒ–å·¥å…·å®ç°æ•°æ®åº“çš„æ ‡å‡†åŒ–ã€è‡ªåŠ¨åŒ–è¿ç»´ã€‚æœ¬æŒ‡å—æä¾›ä»åŸºç¡€è¿ç»´åˆ°é«˜çº§ç®¡ç†çš„å®Œæ•´Kubernetesæ•°æ®åº“è¿ç»´è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

1. [Kubernetesæ•°æ®åº“è¿ç»´åŸºç¡€](#1-kubernetesæ•°æ®åº“è¿ç»´åŸºç¡€)
2. [Operatoræ¨¡å¼å®è·µ](#2-operatoræ¨¡å¼å®è·µ)
3. [StatefulSeté«˜çº§è¿ç»´](#3-statefulseté«˜çº§è¿ç»´)
4. [è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·](#4-è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·)
5. [ç›‘æ§å‘Šè­¦ä½“ç³»](#5-ç›‘æ§å‘Šè­¦ä½“ç³»)
6. [å¤‡ä»½æ¢å¤ç­–ç•¥](#6-å¤‡ä»½æ¢å¤ç­–ç•¥)

---

## 1. Kubernetesæ•°æ®åº“è¿ç»´åŸºç¡€

### 1.1 æ•°æ®åº“è¿ç»´æ¶æ„æ¨¡å¼

#### Kubernetesæ•°æ®åº“è¿ç»´æ¶æ„
```mermaid
graph TD
    A[è¿ç»´å›¢é˜Ÿ] --> B[GitOpsæµç¨‹]
    B --> C[Helm Charts]
    C --> D[Kubernetesé›†ç¾¤]
    
    D --> E[MySQL Operator]
    D --> F[PostgreSQL Operator]
    D --> G[MongoDB Operator]
    
    E --> H[MySQLå®ä¾‹1]
    E --> I[MySQLå®ä¾‹2]
    E --> J[MySQLå®ä¾‹3]
    
    F --> K[PostgreSQLä¸»èŠ‚ç‚¹]
    F --> L[PostgreSQLä»èŠ‚ç‚¹1]
    F --> M[PostgreSQLä»èŠ‚ç‚¹2]
    
    G --> N[MongoDBå‰¯æœ¬é›†1]
    G --> O[MongoDBå‰¯æœ¬é›†2]
    
    subgraph "ç›‘æ§å±‚"
        P[Prometheus]
        Q[Grafana]
        R[AlertManager]
    end
    
    subgraph "å­˜å‚¨å±‚"
        S[PersistentVolumes]
        T[StorageClasses]
        U[BackupStorage]
    end
    
    P --> H
    P --> K
    P --> N
    Q --> P
    R --> Q
    
    H --> S
    K --> S
    N --> S
```

#### è¿ç»´æ¨¡å¼å¯¹æ¯”åˆ†æ
```python
# Kubernetesæ•°æ®åº“è¿ç»´æ¨¡å¼å¯¹æ¯”
class DatabaseOpsPatterns:
    def __init__(self):
        self.patterns = {
            'manual_deployment': {
                'description': 'æ‰‹å·¥éƒ¨ç½²æ¨¡å¼',
                'characteristics': {
                    'complexity': 'é«˜',
                    'automation_level': 'ä½',
                    'maintenance_cost': 'é«˜',
                    'scaling_capability': 'æœ‰é™'
                },
                'use_cases': ['å°å‹é¡¹ç›®', 'å®éªŒç¯å¢ƒ', 'ç‰¹æ®Šå®šåˆ¶éœ€æ±‚']
            },
            
            'helm_charts': {
                'description': 'Helm Chartæ¨¡å¼',
                'characteristics': {
                    'complexity': 'ä¸­ç­‰',
                    'automation_level': 'ä¸­ç­‰',
                    'maintenance_cost': 'ä¸­ç­‰',
                    'scaling_capability': 'è‰¯å¥½'
                },
                'use_cases': ['æ ‡å‡†æ•°æ®åº“éƒ¨ç½²', 'å¤šç¯å¢ƒéƒ¨ç½²', 'ç‰ˆæœ¬ç®¡ç†']
            },
            
            'operator_pattern': {
                'description': 'Operatoræ¨¡å¼',
                'characteristics': {
                    'complexity': 'è¾ƒé«˜',
                    'automation_level': 'é«˜',
                    'maintenance_cost': 'è¾ƒä½',
                    'scaling_capability': 'ä¼˜ç§€'
                },
                'use_cases': ['ç”Ÿäº§ç¯å¢ƒ', 'è‡ªåŠ¨åŒ–è¿ç»´', 'å¤æ‚é›†ç¾¤ç®¡ç†']
            },
            
            'gitops_approach': {
                'description': 'GitOpsæ¨¡å¼',
                'characteristics': {
                    'complexity': 'é«˜',
                    'automation_level': 'å¾ˆé«˜',
                    'maintenance_cost': 'å¾ˆä½',
                    'scaling_capability': 'æä½³'
                },
                'use_cases': ['ä¼ä¸šçº§éƒ¨ç½²', 'å¤šé›†ç¾¤ç®¡ç†', 'åˆè§„è¦æ±‚']
            }
        }
    
    def evaluate_ops_pattern(self, requirements):
        """è¯„ä¼°é€‚åˆçš„è¿ç»´æ¨¡å¼"""
        scores = {}
        
        for pattern_name, pattern_info in self.patterns.items():
            score = self._calculate_pattern_score(pattern_name, requirements)
            scores[pattern_name] = score
        
        best_pattern = max(scores, key=scores.get)
        return {
            'recommended': best_pattern,
            'score': scores[best_pattern],
            'details': self.patterns[best_pattern],
            'alternatives': sorted(scores.items(), key=lambda x: x[1], reverse=True)
        }
    
    def _calculate_pattern_score(self, pattern_name, requirements):
        """è®¡ç®—æ¨¡å¼å¾—åˆ†"""
        pattern = self.patterns[pattern_name]
        score = 0
        
        # ç¯å¢ƒè§„æ¨¡è¯„åˆ†
        environment_scale = requirements.get('environment_scale', 'small')
        scale_mapping = {'small': 1, 'medium': 2, 'large': 3, 'enterprise': 4}
        
        if scale_mapping[environment_scale] <= 2 and pattern_name == 'manual_deployment':
            score += 30
        elif scale_mapping[environment_scale] <= 3 and pattern_name == 'helm_charts':
            score += 30
        elif scale_mapping[environment_scale] >= 3 and pattern_name == 'operator_pattern':
            score += 30
        elif scale_mapping[environment_scale] == 4 and pattern_name == 'gitops_approach':
            score += 30
        
        # è‡ªåŠ¨åŒ–è¦æ±‚è¯„åˆ†
        automation_need = requirements.get('automation_need', 'low')
        automation_mapping = {'low': 1, 'medium': 2, 'high': 3, 'very_high': 4}
        
        if automation_mapping[automation_need] <= pattern['characteristics']['automation_level']:
            score += 25
        
        # è¿ç»´å›¢é˜ŸæŠ€èƒ½è¯„åˆ†
        team_skill = requirements.get('team_skill_level', 'beginner')
        skill_mapping = {'beginner': 1, 'intermediate': 2, 'advanced': 3, 'expert': 4}
        
        pattern_complexity = pattern['characteristics']['complexity']
        complexity_mapping = {'ä½': 1, 'ä¸­ç­‰': 2, 'è¾ƒé«˜': 3, 'é«˜': 4}
        
        if skill_mapping[team_skill] >= complexity_mapping[pattern_complexity]:
            score += 20
        
        # æˆæœ¬è€ƒè™‘è¯„åˆ†
        budget_constraint = requirements.get('budget_constraint', 'medium')
        cost_mapping = {'low': 1, 'medium': 2, 'high': 3, 'very_high': 4}
        maintenance_cost = pattern['characteristics']['maintenance_cost']
        maintenance_mapping = {'ä½': 1, 'ä¸­ç­‰': 2, 'è¾ƒé«˜': 3, 'é«˜': 4}
        
        if cost_mapping[budget_constraint] >= maintenance_mapping[maintenance_cost]:
            score += 15
        
        # åˆè§„è¦æ±‚è¯„åˆ†
        compliance_need = requirements.get('compliance_need', False)
        if compliance_need and pattern_name in ['gitops_approach', 'operator_pattern']:
            score += 10
        elif not compliance_need:
            score += 5
        
        return score

# ä½¿ç”¨ç¤ºä¾‹
ops_patterns = DatabaseOpsPatterns()

requirements = {
    'environment_scale': 'large',
    'automation_need': 'high',
    'team_skill_level': 'advanced',
    'budget_constraint': 'high',
    'compliance_need': True
}

evaluation = ops_patterns.evaluate_ops_pattern(requirements)
print(f"æ¨èè¿ç»´æ¨¡å¼: {evaluation['recommended']}")
print(f"è¯¦ç»†ä¿¡æ¯: {evaluation['details']}")
```

### 1.2 åŸºç¡€è¿ç»´ç¯å¢ƒå‡†å¤‡

#### Kubernetesç¯å¢ƒé…ç½®
```yaml
# kubernetes-database-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: database-ops
  labels:
    name: database-ops
    purpose: database-operations
---
# database-storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: database-fast-ssd
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  fsType: ext4
  iops: "3000"
  throughput: "125"
reclaimPolicy: Retain
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
mountOptions:
  - discard
---
# database-resource-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: database-quota
  namespace: database-ops
spec:
  hard:
    requests.cpu: "20"
    requests.memory: 40Gi
    limits.cpu: "40"
    limits.memory: 80Gi
    persistentvolumeclaims: "50"
    requests.storage: 2Ti
---
# database-limit-range.yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: database-limits
  namespace: database-ops
spec:
  limits:
  - default:
      cpu: "2"
      memory: 4Gi
    defaultRequest:
      cpu: "1"
      memory: 2Gi
    type: Container
  - max:
      storage: 500Gi
    min:
      storage: 10Gi
    type: PersistentVolumeClaim
```

## 2. Operatoræ¨¡å¼å®è·µ

### 2.1 MySQL Operatoréƒ¨ç½²

#### MySQL Operatorå®‰è£…é…ç½®
```yaml
# mysql-operator-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-operator
  namespace: database-ops
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql-operator
  template:
    metadata:
      labels:
        app: mysql-operator
    spec:
      serviceAccountName: mysql-operator
      containers:
      - name: mysql-operator
        image: mysql/mysql-operator:8.0.35-2.1.1
        imagePullPolicy: IfNotPresent
        env:
        - name: MYSQL_OPERATOR_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MYSQL_OPERATOR_WATCH_NAMESPACE
          value: ""
        - name: MYSQL_OPERATOR_SERVICE_ACCOUNT
          value: "mysql-operator"
        ports:
        - containerPort: 8080
          name: metrics
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
---
# mysql-operator-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mysql-operator
  namespace: database-ops
---
# mysql-operator-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: mysql-operator
  namespace: database-ops
rules:
- apiGroups:
  - apps
  resources:
  - deployments
  - statefulsets
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - configmaps
  - secrets
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mysql-operator
  namespace: database-ops
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: mysql-operator
subjects:
- kind: ServiceAccount
  name: mysql-operator
  namespace: database-ops
```

#### MySQLé›†ç¾¤è‡ªå®šä¹‰èµ„æºå®šä¹‰
```yaml
# mysql-cluster-cr.yaml
apiVersion: mysql.oracle.com/v2
kind: InnoDBCluster
metadata:
  name: mysql-production-cluster
  namespace: database-ops
spec:
  secretName: mysql-root-password
  tlsUseSelfSigned: true
  instances: 3
  router:
    instances: 1
  datadirVolumeClaimTemplate:
    accessModes:
      - ReadWriteOnce
    storageClassName: database-fast-ssd
    resources:
      requests:
        storage: 200Gi
  podSpec:
    terminationGracePeriodSeconds: 600
    containers:
    - name: mysql
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - mysql-innodbcluster
            topologyKey: kubernetes.io/hostname
  service:
    type: ClusterIP
```

### 2.2 PostgreSQL Operatorå®è·µ

#### PostgreSQL Operatoréƒ¨ç½²
```yaml
# postgresql-operator-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres-operator
  namespace: database-ops
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres-operator
  template:
    metadata:
      labels:
        app: postgres-operator
    spec:
      serviceAccountName: postgres-operator
      containers:
      - name: postgres-operator
        image: registry.opensource.zalan.do/acid/postgres-operator:v1.8.2
        imagePullPolicy: IfNotPresent
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_MAP_NAME
          value: postgres-operator
        ports:
        - containerPort: 8080
          name: metrics
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
---
# postgresql-operator-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-operator
  namespace: database-ops
data:
  # Operatoré…ç½®
  docker_image: registry.opensource.zalan.do/acid/spilo-14:2.1-p7
  enable_master_load_balancer: "false"
  enable_replica_load_balancer: "false"
  enable_replica_connection_pooler: "true"
  
  # èµ„æºé…ç½®
  resources:
    requests:
      cpu: "100m"
      memory: "256Mi"
    limits:
      cpu: "1"
      memory: "512Mi"
  
  # å­˜å‚¨é…ç½®
  storage_resize_mode: "pvc"
  enable_shm_volume: "true"
  enable_lazy_spilo_upgrade: "false"
  
  # å¤‡ä»½é…ç½®
  enable_logical_backup: "true"
  logical_backup_schedule: "0 2 * * *"
  logical_backup_docker_image: "registry.opensource.zalan.do/acid/logical-backup:v1.8.2"
```

#### PostgreSQLé›†ç¾¤å®šä¹‰
```yaml
# postgresql-cluster-cr.yaml
apiVersion: acid.zalan.do/v1
kind: postgresql
metadata:
  name: postgres-production-cluster
  namespace: database-ops
spec:
  teamId: "production"
  volume:
    size: 200Gi
    storageClass: database-fast-ssd
  numberOfInstances: 3
  users:
    appuser:
    - superuser
    - createdb
  databases:
    myapp: appuser
  postgresql:
    version: "14"
  resources:
    requests:
      cpu: "1"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
  patroni:
    initdb:
      encoding: "UTF8"
      locale: "en_US.UTF-8"
      data-checksums: "true"
    pg_hba:
    - hostssl all all 0.0.0.0/0 md5
    - host    all all 0.0.0.0/0 md5
  tls:
    secretName: postgres-tls-secret
  clone:
    cluster: "postgres-source-cluster"
    timestamp: "2024-01-01T00:00:00+00:00"
    s3_wal_path: "s3://postgres-backups/wal/"
  standby:
    s3_wal_path: "s3://postgres-backups/wal/"
```

## 3. StatefulSeté«˜çº§è¿ç»´

### 3.1 StatefulSetè¿ç»´æœ€ä½³å®è·µ

#### é«˜çº§StatefulSeté…ç½®æ¨¡æ¿
```yaml
# advanced-statefulset-template.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database-cluster
  namespace: database-ops
spec:
  serviceName: database-cluster
  replicas: 3
  selector:
    matchLabels:
      app: database-cluster
  template:
    metadata:
      labels:
        app: database-cluster
        version: v1.0.0
    spec:
      # åˆå§‹åŒ–å®¹å™¨
      initContainers:
      - name: init-permissions
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          echo "Setting up permissions..."
          chown -R 1001:1001 /bitnami/mysql
          chmod 755 /bitnami/mysql
        volumeMounts:
        - name: data
          mountPath: /bitnami/mysql
        securityContext:
          runAsUser: 0
      
      - name: init-config
        image: mysql:8.0.35
        command:
        - sh
        - -c
        - |
          echo "Initializing configuration..."
          # é…ç½®éªŒè¯å’Œåˆå§‹åŒ–é€»è¾‘
        envFrom:
        - secretRef:
            name: database-secret
        volumeMounts:
        - name: config
          mountPath: /etc/mysql/conf.d
      
      # ä¸»å®¹å™¨
      containers:
      - name: database
        image: mysql:8.0.35
        ports:
        - containerPort: 3306
          name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: root-password
        - name: MYSQL_DATABASE
          value: "production_db"
        - name: MYSQL_USER
          value: "appuser"
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: user-password
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
        - name: config
          mountPath: /etc/mysql/conf.d
        - name: logs
          mountPath: /var/log/mysql
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
        
        # å¥åº·æ£€æŸ¥
        livenessProbe:
          exec:
            command:
            - mysqladmin
            - ping
            - -h
            - localhost
            - -u
            - root
            - -p$(MYSQL_ROOT_PASSWORD)
          initialDelaySeconds: 300
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -u
            - root
            - -p$(MYSQL_ROOT_PASSWORD)
            - -e
            - SELECT 1
          initialDelaySeconds: 60
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        startupProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -u
            - root
            - -p$(MYSQL_ROOT_PASSWORD)
            - -e
            - SELECT 1
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
        
        # å®‰å…¨ä¸Šä¸‹æ–‡
        securityContext:
          runAsUser: 1001
          runAsGroup: 1001
          fsGroup: 1001
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
      
      # å·é…ç½®
      volumes:
      - name: config
        configMap:
          name: database-config
      - name: logs
        emptyDir: {}
      
      # èŠ‚ç‚¹äº²å’Œæ€§
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: database-node
                operator: In
                values:
                - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - database-cluster
            topologyKey: kubernetes.io/hostname
      
      # å®¹å¿åº¦
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "database"
        effect: "NoSchedule"
      
      # ä¼˜å…ˆçº§ç±»
      priorityClassName: database-priority
      
      # æœåŠ¡è´¦æˆ·
      serviceAccountName: database-sa
  
  # æŒä¹…åŒ–å·å£°æ˜æ¨¡æ¿
  volumeClaimTemplates:
  - metadata:
      name: data
      annotations:
        volume.beta.kubernetes.io/storage-class: database-fast-ssd
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: database-fast-ssd
      resources:
        requests:
          storage: 200Gi
```

### 3.2 æ»šåŠ¨æ›´æ–°ç­–ç•¥

#### æ•°æ®åº“æ»šåŠ¨æ›´æ–°é…ç½®
```yaml
# rolling-update-strategy.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-rolling-update
  namespace: database-ops
spec:
  # æ›´æ–°ç­–ç•¥
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0  # ä»åºå·0å¼€å§‹æ›´æ–°
  
  # Podç®¡ç†ç­–ç•¥
  podManagementPolicy: OrderedReady
  
  template:
    spec:
      # ä¼˜é›…ç»ˆæ­¢é…ç½®
      terminationGracePeriodSeconds: 300
      
      containers:
      - name: mysql
        image: mysql:8.0.35
        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - |
                echo "Preparing for graceful shutdown..."
                mysqladmin -u root -p$MYSQL_ROOT_PASSWORD shutdown
          
          postStart:
            exec:
              command:
              - sh
              - -c
              - |
                echo "Post-start initialization..."
                # æ•°æ®åº“åˆå§‹åŒ–é€»è¾‘
        
        # å¯åŠ¨æ¢é’ˆç¡®ä¿æœåŠ¡å®Œå…¨å°±ç»ª
        startupProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -u
            - root
            - -p$(MYSQL_ROOT_PASSWORD)
            - -e
            - "SELECT 1"
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
        
        # å°±ç»ªæ¢é’ˆç¡®ä¿æµé‡åˆ‡æ¢å®‰å…¨
        readinessProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -u
            - root
            - -p$(MYSQL_ROOT_PASSWORD)
            - -e
            - "SELECT 1"
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3

# æ»šåŠ¨æ›´æ–°è„šæœ¬
#!/bin/bash
# rolling-update.sh

NAMESPACE="database-ops"
STATEFULSET="mysql-rolling-update"

# æ£€æŸ¥å½“å‰çŠ¶æ€
check_status() {
    echo "æ£€æŸ¥StatefulSetçŠ¶æ€..."
    kubectl get statefulset $STATEFULSET -n $NAMESPACE
    kubectl get pods -l app=mysql-rolling-update -n $NAMESPACE
}

# æ‰§è¡Œæ»šåŠ¨æ›´æ–°
perform_rolling_update() {
    local new_image=$1
    local partition=${2:-0}
    
    echo "å¼€å§‹æ»šåŠ¨æ›´æ–°åˆ°é•œåƒ: $new_image"
    echo "æ›´æ–°åˆ†åŒº: $partition"
    
    # æ›´æ–°é•œåƒ
    kubectl patch statefulset $STATEFULSET -n $NAMESPACE -p \
        "{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"mysql\",\"image\":\"$new_image\"}]}}}}"
    
    # æŒ‰åºå·é€ä¸ªæ›´æ–°
    local replicas=$(kubectl get statefulset $STATEFULSET -n $NAMESPACE -o jsonpath='{.spec.replicas}')
    
    for ((i=partition; i<replicas; i++)); do
        echo "æ›´æ–°Pod: $STATEFULSET-$i"
        
        # è®¾ç½®åˆ†åŒº
        kubectl patch statefulset $STATEFULSET -n $NAMESPACE -p \
            "{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":$i}}}}"
        
        # ç­‰å¾…Podæ›´æ–°å®Œæˆ
        kubectl rollout status statefulset/$STATEFULSET -n $NAMESPACE --timeout=300s
        
        # éªŒè¯Podå¥åº·
        if ! kubectl wait --for=condition=ready pod/$STATEFULSET-$i -n $NAMESPACE --timeout=120s; then
            echo "è­¦å‘Š: Pod $STATEFULSET-$i å¥åº·æ£€æŸ¥å¤±è´¥"
            # å¯ä»¥é€‰æ‹©å›æ»šæˆ–ç»§ç»­
        fi
        
        echo "Pod $STATEFULSET-$i æ›´æ–°å®Œæˆ"
        sleep 30  # ç­‰å¾…ç¨³å®š
    done
    
    # é‡ç½®åˆ†åŒºä¸º0
    kubectl patch statefulset $STATEFULSET -n $NAMESPACE -p \
        "{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":0}}}}"
}

# å›æ»šæ“ä½œ
rollback_update() {
    echo "æ‰§è¡Œå›æ»šæ“ä½œ..."
    kubectl rollout undo statefulset/$STATEFULSET -n $NAMESPACE
    kubectl rollout status statefulset/$STATEFULSET -n $NAMESPACE --timeout=300s
}

# ä½¿ç”¨ç¤ºä¾‹
# check_status
# perform_rolling_update "mysql:8.0.36" 0
# rollback_update
```

## 4. è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·

### 4.1 æ•°æ®åº“è¿ç»´è‡ªåŠ¨åŒ–è„šæœ¬

#### æ•°æ®åº“é›†ç¾¤ç®¡ç†å·¥å…·
```python
#!/usr/bin/env python3
# database_cluster_manager.py

import argparse
import yaml
import json
import subprocess
import time
from datetime import datetime
from typing import Dict, List, Any

class DatabaseClusterManager:
    def __init__(self, kubeconfig: str = None):
        self.kubeconfig = kubeconfig
        self.context = self._get_current_context()
    
    def _get_current_context(self) -> str:
        """è·å–å½“å‰Kubernetesä¸Šä¸‹æ–‡"""
        try:
            result = subprocess.run(
                ['kubectl', 'config', 'current-context'],
                capture_output=True, text=True, check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError:
            return "unknown"
    
    def deploy_database_cluster(self, cluster_config: Dict[str, Any]) -> bool:
        """éƒ¨ç½²æ•°æ®åº“é›†ç¾¤"""
        cluster_type = cluster_config['type']
        namespace = cluster_config.get('namespace', 'database-ops')
        
        print(f"å¼€å§‹éƒ¨ç½²{cluster_type}é›†ç¾¤åˆ°å‘½åç©ºé—´{namespace}")
        
        try:
            # åˆ›å»ºå‘½åç©ºé—´
            self._create_namespace(namespace)
            
            # éƒ¨ç½²Operator
            if cluster_config.get('use_operator', True):
                self._deploy_operator(cluster_type, namespace)
            
            # éƒ¨ç½²é›†ç¾¤
            self._deploy_cluster(cluster_config)
            
            # ç­‰å¾…é›†ç¾¤å°±ç»ª
            self._wait_for_cluster_ready(cluster_config)
            
            print(f"{cluster_type}é›†ç¾¤éƒ¨ç½²æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"é›†ç¾¤éƒ¨ç½²å¤±è´¥: {str(e)}")
            return False
    
    def _create_namespace(self, namespace: str):
        """åˆ›å»ºå‘½åç©ºé—´"""
        cmd = ['kubectl', 'create', 'namespace', namespace, '--dry-run=client', '-o', 'yaml']
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            subprocess.run(['kubectl', 'apply', '-f', '-'], input=result.stdout, text=True, check=True)
            print(f"å‘½åç©ºé—´ {namespace} åˆ›å»ºå®Œæˆ")
    
    def _deploy_operator(self, cluster_type: str, namespace: str):
        """éƒ¨ç½²å¯¹åº”ç±»å‹çš„Operator"""
        operator_manifests = {
            'mysql': 'https://raw.githubusercontent.com/mysql/mysql-operator/trunk/deploy/deployment.yaml',
            'postgresql': 'https://github.com/zalando/postgres-operator/raw/master/manifests/postgres-operator.yaml',
            'mongodb': 'https://github.com/mongodb/mongodb-kubernetes-operator/raw/master/config/manager/manager.yaml'
        }
        
        if cluster_type.lower() in operator_manifests:
            manifest_url = operator_manifests[cluster_type.lower()]
            cmd = ['kubectl', 'apply', '-f', manifest_url, '-n', namespace]
            subprocess.run(cmd, check=True)
            print(f"{cluster_type} Operatoréƒ¨ç½²å®Œæˆ")
            
            # ç­‰å¾…Operatorå°±ç»ª
            self._wait_for_operator_ready(cluster_type, namespace)
    
    def _deploy_cluster(self, cluster_config: Dict[str, Any]):
        """éƒ¨ç½²æ•°æ®åº“é›†ç¾¤"""
        cluster_type = cluster_config['type']
        cluster_name = cluster_config['name']
        namespace = cluster_config.get('namespace', 'database-ops')
        
        # ç”Ÿæˆé›†ç¾¤é…ç½®
        cluster_manifest = self._generate_cluster_manifest(cluster_config)
        
        # åº”ç”¨é…ç½®
        cmd = ['kubectl', 'apply', '-f', '-', '-n', namespace]
        subprocess.run(cmd, input=yaml.dump(cluster_manifest), text=True, check=True)
        print(f"{cluster_type}é›†ç¾¤ {cluster_name} é…ç½®åº”ç”¨å®Œæˆ")
    
    def _generate_cluster_manifest(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆé›†ç¾¤é…ç½®æ¸…å•"""
        cluster_type = config['type'].lower()
        
        if cluster_type == 'mysql':
            return self._generate_mysql_manifest(config)
        elif cluster_type == 'postgresql':
            return self._generate_postgresql_manifest(config)
        elif cluster_type == 'mongodb':
            return self._generate_mongodb_manifest(config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é›†ç¾¤ç±»å‹: {cluster_type}")
    
    def _generate_mysql_manifest(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆMySQLé›†ç¾¤é…ç½®"""
        return {
            'apiVersion': 'mysql.oracle.com/v2',
            'kind': 'InnoDBCluster',
            'metadata': {
                'name': config['name'],
                'namespace': config.get('namespace', 'database-ops')
            },
            'spec': {
                'secretName': config.get('secret_name', 'mysql-secret'),
                'instances': config.get('replicas', 3),
                'tlsUseSelfSigned': True,
                'datadirVolumeClaimTemplate': {
                    'accessModes': ['ReadWriteOnce'],
                    'storageClassName': config.get('storage_class', 'database-fast-ssd'),
                    'resources': {
                        'requests': {
                            'storage': config.get('storage_size', '100Gi')
                        }
                    }
                }
            }
        }
    
    def _generate_postgresql_manifest(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆPostgreSQLé›†ç¾¤é…ç½®"""
        return {
            'apiVersion': 'acid.zalan.do/v1',
            'kind': 'postgresql',
            'metadata': {
                'name': config['name'],
                'namespace': config.get('namespace', 'database-ops')
            },
            'spec': {
                'teamId': config.get('team_id', 'production'),
                'volume': {
                    'size': config.get('storage_size', '100Gi'),
                    'storageClass': config.get('storage_class', 'database-fast-ssd')
                },
                'numberOfInstances': config.get('replicas', 3),
                'users': {
                    config.get('username', 'appuser'): ['superuser', 'createdb']
                },
                'databases': {
                    config.get('database_name', 'myapp'): config.get('username', 'appuser')
                },
                'postgresql': {
                    'version': config.get('version', '14')
                }
            }
        }
    
    def _generate_mongodb_manifest(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆMongoDBé›†ç¾¤é…ç½®"""
        return {
            'apiVersion': 'mongodbcommunity.mongodb.com/v1',
            'kind': 'MongoDBCommunity',
            'metadata': {
                'name': config['name'],
                'namespace': config.get('namespace', 'database-ops')
            },
            'spec': {
                'members': config.get('replicas', 3),
                'type': 'ReplicaSet',
                'version': config.get('version', '6.0.5'),
                'security': {
                    'authentication': {
                        'modes': ['SCRAM']
                    }
                },
                'users': [{
                    'name': config.get('username', 'appuser'),
                    'db': 'admin',
                    'passwordSecretRef': {
                        'name': config.get('secret_name', 'mongodb-secret')
                    },
                    'roles': [{
                        'name': 'clusterAdmin',
                        'db': 'admin'
                    }]
                }],
                'statefulSet': {
                    'spec': {
                        'volumeClaimTemplates': [{
                            'metadata': {
                                'name': 'data-volume'
                            },
                            'spec': {
                                'accessModes': ['ReadWriteOnce'],
                                'storageClassName': config.get('storage_class', 'database-fast-ssd'),
                                'resources': {
                                    'requests': {
                                        'storage': config.get('storage_size', '100Gi')
                                    }
                                }
                            }
                        }]
                    }
                }
            }
        }
    
    def _wait_for_operator_ready(self, cluster_type: str, namespace: str, timeout: int = 300):
        """ç­‰å¾…Operatorå°±ç»ª"""
        print(f"ç­‰å¾…{cluster_type} Operatorå°±ç»ª...")
        
        deployments = {
            'mysql': 'mysql-operator',
            'postgresql': 'postgres-operator',
            'mongodb': 'mongodb-kubernetes-operator'
        }
        
        deployment_name = deployments.get(cluster_type.lower())
        if not deployment_name:
            return
        
        cmd = [
            'kubectl', 'wait', '--for=condition=available',
            f'deployment/{deployment_name}', '-n', namespace,
            f'--timeout={timeout}s'
        ]
        
        subprocess.run(cmd, check=True)
        print(f"{cluster_type} Operatorå·²å°±ç»ª")
    
    def _wait_for_cluster_ready(self, cluster_config: Dict[str, Any], timeout: int = 600):
        """ç­‰å¾…é›†ç¾¤å°±ç»ª"""
        cluster_type = cluster_config['type'].lower()
        cluster_name = cluster_config['name']
        namespace = cluster_config.get('namespace', 'database-ops')
        
        print(f"ç­‰å¾…{cluster_type}é›†ç¾¤ {cluster_name} å°±ç»ª...")
        
        # æ ¹æ®ä¸åŒç±»å‹ç­‰å¾…å°±ç»ª
        if cluster_type == 'mysql':
            self._wait_for_mysql_cluster_ready(cluster_name, namespace, timeout)
        elif cluster_type == 'postgresql':
            self._wait_for_postgresql_cluster_ready(cluster_name, namespace, timeout)
        elif cluster_type == 'mongodb':
            self._wait_for_mongodb_cluster_ready(cluster_name, namespace, timeout)
    
    def _wait_for_mysql_cluster_ready(self, cluster_name: str, namespace: str, timeout: int):
        """ç­‰å¾…MySQLé›†ç¾¤å°±ç»ª"""
        cmd = [
            'kubectl', 'wait', '--for=condition=Ready',
            f'innodbcluster/{cluster_name}', '-n', namespace,
            f'--timeout={timeout}s'
        ]
        subprocess.run(cmd, check=True)
    
    def _wait_for_postgresql_cluster_ready(self, cluster_name: str, namespace: str, timeout: int):
        """ç­‰å¾…PostgreSQLé›†ç¾¤å°±ç»ª"""
        # PostgreSQL Operatorä½¿ç”¨ä¸åŒçš„å°±ç»ªæ¡ä»¶
        start_time = time.time()
        while time.time() - start_time < timeout:
            cmd = ['kubectl', 'get', 'postgresql', cluster_name, '-n', namespace, '-o', 'jsonpath={.status.PostgresClusterStatus}']
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip() == 'Running':
                return
            time.sleep(10)
        raise TimeoutError("PostgreSQLé›†ç¾¤å¯åŠ¨è¶…æ—¶")
    
    def _wait_for_mongodb_cluster_ready(self, cluster_name: str, namespace: str, timeout: int):
        """ç­‰å¾…MongoDBé›†ç¾¤å°±ç»ª"""
        cmd = [
            'kubectl', 'wait', '--for=condition=Ready',
            f'mongodbcommunity/{cluster_name}', '-n', namespace,
            f'--timeout={timeout}s'
        ]
        subprocess.run(cmd, check=True)
    
    def backup_database(self, cluster_config: Dict[str, Any], backup_config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œæ•°æ®åº“å¤‡ä»½"""
        try:
            cluster_type = cluster_config['type'].lower()
            cluster_name = cluster_config['name']
            namespace = cluster_config.get('namespace', 'database-ops')
            
            print(f"å¼€å§‹{cluster_type}é›†ç¾¤ {cluster_name} å¤‡ä»½...")
            
            if cluster_type == 'mysql':
                return self._backup_mysql_cluster(cluster_name, namespace, backup_config)
            elif cluster_type == 'postgresql':
                return self._backup_postgresql_cluster(cluster_name, namespace, backup_config)
            elif cluster_type == 'mongodb':
                return self._backup_mongodb_cluster(cluster_name, namespace, backup_config)
            
        except Exception as e:
            print(f"å¤‡ä»½å¤±è´¥: {str(e)}")
            return False
    
    def _backup_mysql_cluster(self, cluster_name: str, namespace: str, backup_config: Dict[str, Any]) -> bool:
        """MySQLé›†ç¾¤å¤‡ä»½"""
        # ä½¿ç”¨mysqldumpè¿›è¡Œé€»è¾‘å¤‡ä»½
        backup_name = backup_config.get('name', f'mysql-backup-{int(time.time())}')
        storage_path = backup_config.get('storage_path', '/backups')
        
        # åˆ›å»ºå¤‡ä»½Job
        backup_job = {
            'apiVersion': 'batch/v1',
            'kind': 'Job',
            'metadata': {
                'name': f'{cluster_name}-backup-{int(time.time())}',
                'namespace': namespace
            },
            'spec': {
                'template': {
                    'spec': {
                        'containers': [{
                            'name': 'mysql-backup',
                            'image': 'mysql:8.0.35',
                            'command': [
                                'sh', '-c',
                                f'mysqldump -h {cluster_name}-0.{cluster_name}-instances -u root -p$MYSQL_ROOT_PASSWORD --all-databases > {storage_path}/{backup_name}.sql'
                            ],
                            'env': [{
                                'name': 'MYSQL_ROOT_PASSWORD',
                                'valueFrom': {
                                    'secretKeyRef': {
                                        'name': 'mysql-secret',
                                        'key': 'root-password'
                                    }
                                }
                            }]
                        }],
                        'restartPolicy': 'Never'
                    }
                }
            }
        }
        
        cmd = ['kubectl', 'apply', '-f', '-', '-n', namespace]
        subprocess.run(cmd, input=yaml.dump(backup_job), text=True, check=True)
        return True
    
    def get_cluster_status(self, cluster_config: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–é›†ç¾¤çŠ¶æ€"""
        cluster_type = cluster_config['type'].lower()
        cluster_name = cluster_config['name']
        namespace = cluster_config.get('namespace', 'database-ops')
        
        status = {
            'cluster_name': cluster_name,
            'type': cluster_type,
            'namespace': namespace,
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            if cluster_type == 'mysql':
                status.update(self._get_mysql_cluster_status(cluster_name, namespace))
            elif cluster_type == 'postgresql':
                status.update(self._get_postgresql_cluster_status(cluster_name, namespace))
            elif cluster_type == 'mongodb':
                status.update(self._get_mongodb_cluster_status(cluster_name, namespace))
        except Exception as e:
            status['error'] = str(e)
        
        return status
    
    def _get_mysql_cluster_status(self, cluster_name: str, namespace: str) -> Dict[str, Any]:
        """è·å–MySQLé›†ç¾¤çŠ¶æ€"""
        cmd = ['kubectl', 'get', 'innodbcluster', cluster_name, '-n', namespace, '-o', 'json']
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        cluster_info = json.loads(result.stdout)
        
        return {
            'status': cluster_info.get('status', {}),
            'instances': cluster_info.get('spec', {}).get('instances', 0),
            'ready_instances': len([s for s in cluster_info.get('status', {}).get('instances', []) 
                                  if s.get('status') == 'Online'])
        }

def main():
    parser = argparse.ArgumentParser(description='æ•°æ®åº“é›†ç¾¤ç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['deploy', 'backup', 'status'], help='æ“ä½œç±»å‹')
    parser.add_argument('--config', required=True, help='é›†ç¾¤é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--backup-config', help='å¤‡ä»½é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # è¯»å–é…ç½®æ–‡ä»¶
    with open(args.config, 'r') as f:
        cluster_config = yaml.safe_load(f)
    
    manager = DatabaseClusterManager()
    
    if args.action == 'deploy':
        success = manager.deploy_database_cluster(cluster_config)
        exit(0 if success else 1)
    
    elif args.action == 'backup':
        if not args.backup_config:
            print("é”™è¯¯: å¤‡ä»½æ“ä½œéœ€è¦æŒ‡å®š--backup-configå‚æ•°")
            exit(1)
        
        with open(args.backup_config, 'r') as f:
            backup_config = yaml.safe_load(f)
        
        success = manager.backup_database(cluster_config, backup_config)
        exit(0 if success else 1)
    
    elif args.action == 'status':
        status = manager.get_cluster_status(cluster_config)
        print(json.dumps(status, indent=2, ensure_ascii=False))

if __name__ == '__main__':
    main()
```

### 4.2 ç›‘æ§é›†æˆå·¥å…·

#### æ•°æ®åº“ç›‘æ§é…ç½®ç®¡ç†å™¨
```python
# monitoring_config_manager.py
import json
import yaml
from typing import Dict, List, Any
import subprocess

class MonitoringConfigManager:
    def __init__(self, namespace: str = "monitoring"):
        self.namespace = namespace
    
    def setup_database_monitoring(self, database_configs: List[Dict[str, Any]]) -> bool:
        """ä¸ºæ•°æ®åº“è®¾ç½®ç›‘æ§"""
        try:
            # éƒ¨ç½²ServiceMonitor
            for db_config in database_configs:
                self._create_servicemonitor(db_config)
            
            # éƒ¨ç½²Grafanaä»ªè¡¨æ¿
            self._deploy_grafana_dashboards(database_configs)
            
            # é…ç½®å‘Šè­¦è§„åˆ™
            self._configure_alerting_rules(database_configs)
            
            return True
        except Exception as e:
            print(f"ç›‘æ§è®¾ç½®å¤±è´¥: {str(e)}")
            return False
    
    def _create_servicemonitor(self, db_config: Dict[str, Any]):
        """åˆ›å»ºServiceMonitor"""
        servicemonitor = {
            'apiVersion': 'monitoring.coreos.com/v1',
            'kind': 'ServiceMonitor',
            'metadata': {
                'name': f"{db_config['name']}-monitor",
                'namespace': self.namespace,
                'labels': {
                    'app': db_config['name'],
                    'release': 'prometheus'
                }
            },
            'spec': {
                'selector': {
                    'matchLabels': {
                        'app': db_config['name']
                    }
                },
                'endpoints': [{
                    'port': 'metrics',
                    'interval': '30s',
                    'path': '/metrics'
                }],
                'namespaceSelector': {
                    'matchNames': [db_config.get('namespace', 'database-ops')]
                }
            }
        }
        
        cmd = ['kubectl', 'apply', '-f', '-', '-n', self.namespace]
        subprocess.run(cmd, input=yaml.dump(servicemonitor), text=True, check=True)
    
    def _deploy_grafana_dashboards(self, database_configs: List[Dict[str, Any]]):
        """éƒ¨ç½²Grafanaä»ªè¡¨æ¿"""
        for db_config in database_configs:
            dashboard = self._generate_dashboard_config(db_config)
            self._apply_dashboard(dashboard)
    
    def _generate_dashboard_config(self, db_config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä»ªè¡¨æ¿é…ç½®"""
        db_type = db_config['type'].lower()
        
        if db_type == 'mysql':
            return self._mysql_dashboard_template(db_config)
        elif db_type == 'postgresql':
            return self._postgresql_dashboard_template(db_config)
        elif db_type == 'mongodb':
            return self._mongodb_dashboard_template(db_config)
    
    def _mysql_dashboard_template(self, db_config: Dict[str, Any]) -> Dict[str, Any]:
        """MySQLä»ªè¡¨æ¿æ¨¡æ¿"""
        return {
            'apiVersion': 'v1',
            'kind': 'ConfigMap',
            'metadata': {
                'name': f"grafana-dashboard-{db_config['name']}",
                'namespace': self.namespace,
                'labels': {
                    'grafana_dashboard': '1'
                }
            },
            'data': {
                f"{db_config['name']}-dashboard.json": json.dumps({
                    "dashboard": {
                        "title": f"MySQL {db_config['name']} ç›‘æ§",
                        "panels": [
                            {
                                "title": "è¿æ¥æ•°",
                                "type": "graph",
                                "targets": [{
                                    "expr": f"mysql_global_status_threads_connected{{instance=\"{db_config['name']}-0\"}}",
                                    "legendFormat": "è¿æ¥æ•°"
                                }]
                            },
                            {
                                "title": "æŸ¥è¯¢QPS",
                                "type": "graph",
                                "targets": [{
                                    "expr": f"rate(mysql_global_status_questions{{instance=\"{db_config['name']}-0\"}}[5m])",
                                    "legendFormat": "QPS"
                                }]
                            }
                        ]
                    }
                })
            }
        }
    
    def _apply_dashboard(self, dashboard_config: Dict[str, Any]):
        """åº”ç”¨ä»ªè¡¨æ¿é…ç½®"""
        cmd = ['kubectl', 'apply', '-f', '-', '-n', self.namespace]
        subprocess.run(cmd, input=yaml.dump(dashboard_config), text=True, check=True)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = MonitoringConfigManager()
    
    databases = [
        {
            'name': 'mysql-production',
            'type': 'mysql',
            'namespace': 'database-ops'
        },
        {
            'name': 'postgres-analytics',
            'type': 'postgresql',
            'namespace': 'database-ops'
        }
    ]
    
    manager.setup_database_monitoring(databases)
```

## 5. ç›‘æ§å‘Šè­¦ä½“ç³»

### 5.1 Prometheusç›‘æ§é…ç½®

#### æ•°æ®åº“ç›‘æ§æŒ‡æ ‡é…ç½®
```yaml
# database-prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: database-rules
  namespace: monitoring
  labels:
    app: prometheus
    release: prometheus
spec:
  groups:
  - name: mysql.rules
    rules:
    # è¿æ¥æ•°å‘Šè­¦
    - alert: MySQLHighConnections
      expr: mysql_global_status_threads_connected > 1000
      for: 5m
      labels:
        severity: warning
        database: mysql
      annotations:
        summary: "MySQLè¿æ¥æ•°è¿‡é«˜"
        description: "MySQLå®ä¾‹ {{ $labels.instance }} è¿æ¥æ•°è¾¾åˆ° {{ $value }}"
    
    # æ…¢æŸ¥è¯¢å‘Šè­¦
    - alert: MySQLSlowQueries
      expr: rate(mysql_global_status_slow_queries[5m]) > 10
      for: 2m
      labels:
        severity: warning
        database: mysql
      annotations:
        summary: "MySQLæ…¢æŸ¥è¯¢å¢å¤š"
        description: "MySQLå®ä¾‹ {{ $labels.instance }} æ…¢æŸ¥è¯¢ç‡ {{ $value }}/s"
    
    # ä¸»ä»å»¶è¿Ÿå‘Šè­¦
    - alert: MySQLReplicationLag
      expr: mysql_slave_status_seconds_behind_master > 30
      for: 3m
      labels:
        severity: critical
        database: mysql
      annotations:
        summary: "MySQLä¸»ä»å»¶è¿Ÿä¸¥é‡"
        description: "MySQLä»åº“ {{ $labels.instance }} å»¶è¿Ÿ {{ $value }} ç§’"
  
  - name: postgresql.rules
    rules:
    # è¿æ¥æ•°å‘Šè­¦
    - alert: PostgreSQLHighConnections
      expr: pg_stat_activity_count > 200
      for: 5m
      labels:
        severity: warning
        database: postgresql
      annotations:
        summary: "PostgreSQLè¿æ¥æ•°è¿‡é«˜"
        description: "PostgreSQLå®ä¾‹ {{ $labels.instance }} è¿æ¥æ•°è¾¾åˆ° {{ $value }}"
    
    # æ­»é”å‘Šè­¦
    - alert: PostgreSQLDeadlocks
      expr: rate(pg_stat_database_deadlocks[5m]) > 1
      for: 2m
      labels:
        severity: critical
        database: postgresql
      annotations:
        summary: "PostgreSQLå‡ºç°æ­»é”"
        description: "PostgreSQLå®ä¾‹ {{ $labels.instance }} æ­»é”ç‡ {{ $value }}/s"
    
    # å¤åˆ¶å»¶è¿Ÿå‘Šè­¦
    - alert: PostgreSQLReplicationLag
      expr: pg_replication_lag > 30
      for: 3m
      labels:
        severity: critical
        database: postgresql
      annotations:
        summary: "PostgreSQLå¤åˆ¶å»¶è¿Ÿ"
        description: "PostgreSQLä»åº“ {{ $labels.instance }} å»¶è¿Ÿ {{ $value }} ç§’"
  
  - name: mongodb.rules
    rules:
    # è¿æ¥æ•°å‘Šè­¦
    - alert: MongoDBHighConnections
      expr: mongodb_connections_current > 10000
      for: 5m
      labels:
        severity: warning
        database: mongodb
      annotations:
        summary: "MongoDBè¿æ¥æ•°è¿‡é«˜"
        description: "MongoDBå®ä¾‹ {{ $labels.instance }} è¿æ¥æ•°è¾¾åˆ° {{ $value }}"
    
    # ä¸»ä»çŠ¶æ€å‘Šè­¦
    - alert: MongoDBReplicaSetNotHealthy
      expr: mongodb_replset_member_state != 1
      for: 3m
      labels:
        severity: critical
        database: mongodb
      annotations:
        summary: "MongoDBå‰¯æœ¬é›†ä¸å¥åº·"
        description: "MongoDBå‰¯æœ¬é›†æˆå‘˜ {{ $labels.instance }} çŠ¶æ€å¼‚å¸¸"
```

### 5.2 å‘Šè­¦é€šçŸ¥é…ç½®

#### AlertManageré…ç½®
```yaml
# alertmanager-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-config
  namespace: monitoring
type: Opaque
data:
  alertmanager.yml: |-
    global:
      resolve_timeout: 5m
      smtp_smarthost: 'smtp.company.com:587'
      smtp_from: 'alert@company.com'
      smtp_auth_username: 'alert@company.com'
      smtp_auth_password: "${DB_PASSWORD}"
    
    route:
      group_by: ['alertname', 'database']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 3h
      receiver: 'default-receiver'
      
      routes:
      - match:
          severity: 'critical'
        receiver: 'critical-team'
        group_wait: 10s
        repeat_interval: 1h
      
      - match:
          severity: 'warning'
        receiver: 'ops-team'
        group_wait: 1m
        repeat_interval: 2h
    
    receivers:
    - name: 'default-receiver'
      email_configs:
      - to: 'database-ops@company.com'
        send_resolved: true
    
    - name: 'critical-team'
      email_configs:
      - to: 'critical-database@company.com'
        send_resolved: true
      webhook_configs:
      - url: 'https://pagerduty.company.com/alert'
        send_resolved: true
    
    - name: 'ops-team'
      email_configs:
      - to: '${OPS_EMAIL}'
        send_resolved: true
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#database-alerts'
        send_resolved: true
        title: '{{ template "slack.title" . }}'
        text: '{{ template "slack.text" . }}'
```

## 6. å¤‡ä»½æ¢å¤ç­–ç•¥

### 6.1 è‡ªåŠ¨åŒ–å¤‡ä»½æ–¹æ¡ˆ

#### æ•°æ®åº“å¤‡ä»½æ§åˆ¶å™¨
```python
# database_backup_controller.py
import time
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Any
import yaml
import json

class DatabaseBackupController:
    def __init__(self, namespace: str = "database-ops"):
        self.namespace = namespace
        self.backup_jobs = {}
    
    def schedule_backups(self, backup_configs: List[Dict[str, Any]]):
        """è°ƒåº¦å¤‡ä»½ä»»åŠ¡"""
        for config in backup_configs:
            self._create_backup_cronjob(config)
    
    def _create_backup_cronjob(self, config: Dict[str, Any]):
        """åˆ›å»ºå¤‡ä»½CronJob"""
        cronjob = {
            'apiVersion': 'batch/v1',
            'kind': 'CronJob',
            'metadata': {
                'name': f"{config['database_name']}-backup",
                'namespace': self.namespace
            },
            'spec': {
                'schedule': config['schedule'],
                'jobTemplate': {
                    'spec': {
                        'template': {
                            'spec': {
                                'containers': [{
                                    'name': 'backup',
                                    'image': self._get_backup_image(config['database_type']),
                                    'command': self._get_backup_command(config),
                                    'env': self._get_backup_env(config),
                                    'volumeMounts': [{
                                        'name': 'backup-storage',
                                        'mountPath': '/backups'
                                    }]
                                }],
                                'volumes': [{
                                    'name': 'backup-storage',
                                    'persistentVolumeClaim': {
                                        'claimName': config.get('pvc_name', 'backup-storage')
                                    }
                                }],
                                'restartPolicy': 'OnFailure'
                            }
                        }
                    }
                }
            }
        }
        
        cmd = ['kubectl', 'apply', '-f', '-', '-n', self.namespace]
        subprocess.run(cmd, input=yaml.dump(cronjob), text=True, check=True)
    
    def _get_backup_image(self, db_type: str) -> str:
        """è·å–å¤‡ä»½é•œåƒ"""
        images = {
            'mysql': 'mysql:8.0.35',
            'postgresql': 'postgres:15.4',
            'mongodb': 'mongo:7.0.2'
        }
        return images.get(db_type.lower(), 'busybox')
    
    def _get_backup_command(self, config: Dict[str, Any]) -> List[str]:
        """è·å–å¤‡ä»½å‘½ä»¤"""
        db_type = config['database_type'].lower()
        db_name = config['database_name']
        
        if db_type == 'mysql':
            return [
                'sh', '-c',
                f'mysqldump -h {db_name}-0.{db_name} -u root -p$MYSQL_ROOT_PASSWORD --all-databases '
                f'> /backups/{db_name}-backup-$(date +%Y%m%d-%H%M%S).sql'
            ]
        elif db_type == 'postgresql':
            return [
                'sh', '-c',
                f'pg_dump -h {db_name}-0.{db_name} -U postgres -d postgres '
                f'> /backups/{db_name}-backup-$(date +%Y%m%d-%H%M%S).sql'
            ]
        elif db_type == 'mongodb':
            return [
                'sh', '-c',
                f'mongodump --host {db_name}-0.{db_name} --username root --password $MONGODB_ROOT_PASSWORD '
                f'--out /backups/{db_name}-backup-$(date +%Y%m%d-%H%M%S)'
            ]
    
    def _get_backup_env(self, config: Dict[str, Any]) -> List[Dict[str, str]]:
        """è·å–å¤‡ä»½ç¯å¢ƒå˜é‡"""
        db_type = config['database_type'].lower()
        
        if db_type == 'mysql':
            return [{
                'name': 'MYSQL_ROOT_PASSWORD',
                'valueFrom': {
                    'secretKeyRef': {
                        'name': 'mysql-secret',
                        'key': 'root-password'
                    }
                }
            }]
        elif db_type == 'postgresql':
            return [{
                'name': 'PGPASSWORD',
                'valueFrom': {
                    'secretKeyRef': {
                        'name': 'postgresql-secret',
                        'key': 'password'
                    }
                }
            }]
        elif db_type == 'mongodb':
            return [{
                'name': 'MONGODB_ROOT_PASSWORD',
                'valueFrom': {
                    'secretKeyRef': {
                        'name': 'mongodb-secret',
                        'key': 'password'
                    }
                }
            }]
        return []
    
    def cleanup_old_backups(self, retention_days: int = 7):
        """æ¸…ç†æ—§å¤‡ä»½"""
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        cutoff_timestamp = int(cutoff_date.timestamp())
        
        # æŸ¥æ‰¾æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
        cmd = ['kubectl', 'exec', '-n', self.namespace, 'backup-manager-pod', '--',
               'find', '/backups', '-name', '*.sql', '-o', '-name', '*', '-type', 'f']
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            backup_files = result.stdout.strip().split('\n')
            for file_path in backup_files:
                # æ£€æŸ¥æ–‡ä»¶æ—¶é—´å¹¶åˆ é™¤æ—§æ–‡ä»¶
                stat_cmd = ['kubectl', 'exec', '-n', self.namespace, 'backup-manager-pod', '--',
                           'stat', '-c', '%Y', file_path]
                stat_result = subprocess.run(stat_cmd, capture_output=True, text=True)
                if stat_result.returncode == 0:
                    file_timestamp = int(stat_result.stdout.strip())
                    if file_timestamp < cutoff_timestamp:
                        delete_cmd = ['kubectl', 'exec', '-n', self.namespace, 'backup-manager-pod', '--',
                                     'rm', '-f', file_path]
                        subprocess.run(delete_cmd)

# å¤‡ä»½é…ç½®ç¤ºä¾‹
backup_configs = [
    {
        'database_name': 'mysql-production',
        'database_type': 'mysql',
        'schedule': '0 2 * * *',  # æ¯å¤©å‡Œæ™¨2ç‚¹
        'retention_days': 7
    },
    {
        'database_name': 'postgres-analytics',
        'database_type': 'postgresql',
        'schedule': '0 3 * * *',  # æ¯å¤©å‡Œæ™¨3ç‚¹
        'retention_days': 14
    }
]

controller = DatabaseBackupController()
controller.schedule_backups(backup_configs)
```

### 6.2 ç¾éš¾æ¢å¤æ¼”ç»ƒ

#### æ¢å¤éªŒè¯è„šæœ¬
```bash
#!/bin/bash
# disaster_recovery_test.sh

NAMESPACE="database-ops"
TEST_NAMESPACE="dr-test"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]$(date '+%Y-%m-%d %H:%M:%S') $1${NC}"
}

log_warn() {
    echo -e "${YELLOW}[WARN]$(date '+%Y-%m-%d %H:%M:%S') $1${NC}"
}

log_error() {
    echo -e "${RED}[ERROR]$(date '+%Y-%m-%d %H:%M:%S') $1${NC}"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]$(date '+%Y-%m-%d %H:%M:%S') $1${NC}"
}

# åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
setup_test_environment() {
    log_info "åˆ›å»ºç¾éš¾æ¢å¤æµ‹è¯•ç¯å¢ƒ"
    
    # åˆ›å»ºæµ‹è¯•å‘½åç©ºé—´
    kubectl create namespace $TEST_NAMESPACE 2>/dev/null || true
    
    # å¤åˆ¶å¿…è¦çš„é…ç½®
    kubectl get secret -n $NAMESPACE mysql-secret -o yaml | \
        sed 's/namespace: .*/namespace: '"$TEST_NAMESPACE"'/' | \
        kubectl apply -f -
    
    log_success "æµ‹è¯•ç¯å¢ƒåˆ›å»ºå®Œæˆ"
}

# æ‰§è¡Œæ¢å¤æµ‹è¯•
perform_recovery_test() {
    local backup_file=$1
    local database_name=$2
    
    log_info "å¼€å§‹æ¢å¤æµ‹è¯•: $database_name ä» $backup_file"
    
    # åˆ›å»ºæ¢å¤Job
    cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: ${database_name}-recovery-test
  namespace: $TEST_NAMESPACE
spec:
  template:
    spec:
      containers:
      - name: recovery-test
        image: mysql:8.0.35
        command:
        - sh
        - -c
        - |
          echo "å¼€å§‹æ¢å¤æµ‹è¯•..."
          # æ¢å¤æ•°æ®
          mysql -h mysql-test-0.mysql-test -u root -p\$MYSQL_ROOT_PASSWORD < /backups/$backup_file
          
          # éªŒè¯æ•°æ®å®Œæ•´æ€§
          mysql -h mysql-test-0.mysql-test -u root -p\$MYSQL_ROOT_PASSWORD -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema NOT IN ('information_schema', 'performance_schema', 'mysql', 'sys');"
          
          echo "æ¢å¤æµ‹è¯•å®Œæˆ"
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: root-password
        volumeMounts:
        - name: backup-storage
          mountPath: /backups
      volumes:
      - name: backup-storage
        persistentVolumeClaim:
          claimName: backup-storage
      restartPolicy: Never
EOF
    
    # ç­‰å¾…Jobå®Œæˆ
    kubectl wait --for=condition=complete job/${database_name}-recovery-test -n $TEST_NAMESPACE --timeout=300s
    
    # æ£€æŸ¥JobçŠ¶æ€
    job_status=$(kubectl get job ${database_name}-recovery-test -n $TEST_NAMESPACE -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}')
    
    if [ "$job_status" = "True" ]; then
        log_success "æ¢å¤æµ‹è¯•æˆåŠŸ: $database_name"
        return 0
    else
        log_error "æ¢å¤æµ‹è¯•å¤±è´¥: $database_name"
        return 1
    fi
}

# æ¸…ç†æµ‹è¯•ç¯å¢ƒ
cleanup_test_environment() {
    log_info "æ¸…ç†æµ‹è¯•ç¯å¢ƒ"
    kubectl delete namespace $TEST_NAMESPACE --timeout=300s
    log_success "æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ"
}

# ä¸»æµ‹è¯•æµç¨‹
main() {
    log_info "å¼€å§‹ç¾éš¾æ¢å¤æ¼”ç»ƒ"
    
    setup_test_environment
    
    # è·å–æœ€æ–°çš„å¤‡ä»½æ–‡ä»¶
    latest_backup=$(kubectl exec -n $NAMESPACE backup-manager-pod -- \
        ls -t /backups/*.sql | head -1 | xargs basename)
    
    if [ -z "$latest_backup" ]; then
        log_error "æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶"
        cleanup_test_environment
        exit 1
    fi
    
    log_info "ä½¿ç”¨å¤‡ä»½æ–‡ä»¶: $latest_backup"
    
    # æ‰§è¡Œæ¢å¤æµ‹è¯•
    if perform_recovery_test "$latest_backup" "mysql-dr-test"; then
        log_success "ç¾éš¾æ¢å¤æ¼”ç»ƒå®Œæˆ"
        TEST_RESULT=0
    else
        log_error "ç¾éš¾æ¢å¤æ¼”ç»ƒå¤±è´¥"
        TEST_RESULT=1
    fi
    
    # æ¸…ç†ç¯å¢ƒ
    cleanup_test_environment
    
    exit $TEST_RESULT
}

# æ‰§è¡Œä¸»æµç¨‹
main "$@"
```

---

## ğŸ” å…³é”®è¦ç‚¹æ€»ç»“

### âœ… Kubernetesæ•°æ®åº“è¿ç»´æˆåŠŸè¦ç´ 
- **é€‰æ‹©åˆé€‚çš„è¿ç»´æ¨¡å¼**ï¼šæ ¹æ®ç¯å¢ƒè§„æ¨¡å’Œå›¢é˜ŸæŠ€èƒ½é€‰æ‹©Manual/Helm/Operator/GitOpsæ¨¡å¼
- **å®Œå–„çš„ç›‘æ§å‘Šè­¦ä½“ç³»**ï¼šå»ºç«‹å…¨é¢çš„æŒ‡æ ‡ç›‘æ§å’Œè‡ªåŠ¨åŒ–å‘Šè­¦æœºåˆ¶
- **æ ‡å‡†åŒ–çš„å¤‡ä»½æ¢å¤**ï¼šåˆ¶å®šå¯é çš„å¤‡ä»½ç­–ç•¥å’Œç¾éš¾æ¢å¤æ¼”ç»ƒæµç¨‹
- **è‡ªåŠ¨åŒ–çš„è¿ç»´å·¥å…·**ï¼šå¼€å‘å’Œä½¿ç”¨è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬æå‡æ•ˆç‡

### âš ï¸ å¸¸è§é£é™©æé†’
- **å¤æ‚æ€§ç®¡ç†**ï¼šKubernetesæ•°æ®åº“è¿ç»´ç›¸æ¯”ä¼ ç»Ÿæ–¹å¼å¤æ‚åº¦æ˜¾è‘—å¢åŠ 
- **ç½‘ç»œå’Œå­˜å‚¨ä¾èµ–**ï¼šé«˜åº¦ä¾èµ–Kubernetesç½‘ç»œå’Œå­˜å‚¨åŸºç¡€è®¾æ–½çš„ç¨³å®šæ€§
- **æŠ€èƒ½è¦æ±‚æå‡**ï¼šéœ€è¦å›¢é˜Ÿå…·å¤‡Kubernetesã€æ•°æ®åº“å’Œè‡ªåŠ¨åŒ–è¿ç»´çš„å¤åˆæŠ€èƒ½
- **æ•…éšœæ’æŸ¥éš¾åº¦**ï¼šå®¹å™¨åŒ–ç¯å¢ƒä¸‹çš„æ•…éšœæ’æŸ¥æ¯”ä¼ ç»Ÿç¯å¢ƒæ›´åŠ å¤æ‚

### ğŸ¯ æœ€ä½³å®è·µå»ºè®®
1. **æ¸è¿›å¼å®æ–½**ï¼šä»ç®€å•åœºæ™¯å¼€å§‹ï¼Œé€æ­¥æ‰©å±•åˆ°å¤æ‚ç”Ÿäº§ç¯å¢ƒ
2. **å……åˆ†çš„æµ‹è¯•éªŒè¯**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰è¿›è¡Œå……åˆ†çš„åŠŸèƒ½å’Œæ€§èƒ½æµ‹è¯•
3. **å®Œå–„çš„æ–‡æ¡£è®°å½•**ï¼šè¯¦ç»†è®°å½•æ‰€æœ‰é…ç½®å‚æ•°ã€å˜æ›´å†å²å’Œæ“ä½œæ‰‹å†Œ
4. **å®šæœŸçš„èƒ½åŠ›è¯„ä¼°**ï¼šæŒç»­è¯„ä¼°å’Œæå‡å›¢é˜Ÿçš„Kubernetesæ•°æ®åº“è¿ç»´èƒ½åŠ›
5. **å»ºç«‹åº”æ€¥å“åº”æœºåˆ¶**ï¼šåˆ¶å®šå®Œå–„çš„æ•…éšœåº”æ€¥å“åº”æµç¨‹å’Œé¢„æ¡ˆ

é€šè¿‡ä¸“ä¸šçš„Kubernetesæ•°æ®åº“è¿ç»´å®è·µï¼Œå¯ä»¥å®ç°æ•°æ®åº“éƒ¨ç½²ã€ç®¡ç†ã€ç›‘æ§å’Œç»´æŠ¤çš„å…¨é¢è‡ªåŠ¨åŒ–ï¼Œå¤§å¹…æå‡è¿ç»´æ•ˆç‡å’Œç³»ç»Ÿå¯é æ€§ã€‚
# æ•°æ®åº“æ€§èƒ½ç›‘æ§ä½“ç³»å®æˆ˜æ¼”ç¤º

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬æ¡ˆä¾‹ä½ å°†æŒæ¡ä¼ä¸šçº§æ•°æ®åº“æ€§èƒ½ç›‘æ§çš„æ ¸å¿ƒæŠ€èƒ½ï¼š

- æ„å»ºå…¨æ–¹ä½çš„æ•°æ®åº“æ€§èƒ½ç›‘æ§ä½“ç³»
- å®æ–½å®æ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†å’Œåˆ†æ
- å»ºç«‹æ™ºèƒ½å‘Šè­¦å’Œå¼‚å¸¸æ£€æµ‹æœºåˆ¶
- è®¾è®¡å¯è§†åŒ–çš„ç›‘æ§ä»ªè¡¨æ¿
- å®ç°æ€§èƒ½ç“¶é¢ˆçš„è‡ªåŠ¨è¯†åˆ«å’Œè¯Šæ–­
- æ»¡è¶³ç”Ÿäº§ç¯å¢ƒçš„SLAç›‘æ§è¦æ±‚

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- å·²å®Œæˆæ•°æ®åº“å®‰è£…é…ç½®ç¯å¢ƒ
- å…·å¤‡åŸºç¡€ç›‘æ§æ¦‚å¿µç†è§£
- å‡†å¤‡ç›‘æ§åŸºç¡€è®¾æ–½ï¼ˆPrometheusã€Grafanaç­‰ï¼‰
- ç½‘ç»œå¯è¾¾æ€§ç¡®ä¿ç›‘æ§æ•°æ®æ”¶é›†

### å‰ç½®æ¡ä»¶éªŒè¯
```bash
# éªŒè¯æ•°æ®åº“æœåŠ¡çŠ¶æ€
systemctl is-active mysqld postgresql-14 mongod redis

# éªŒè¯ç›‘æ§åŸºç¡€è®¾æ–½
systemctl is-active prometheus grafana-server

# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
ping prometheus-server.example.com
telnet grafana-server.example.com 3000
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
performance-monitoring-demo/
â”œâ”€â”€ README.md                           # æœ¬è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ metadata.json                       # å…ƒæ•°æ®é…ç½®
â”œâ”€â”€ scripts/                           # ç›‘æ§è„šæœ¬
â”‚   â”œâ”€â”€ mysql_monitoring_setup.sh      # MySQLç›‘æ§é…ç½®è„šæœ¬
â”‚   â”œâ”€â”€ postgresql_monitoring_setup.sh # PostgreSQLç›‘æ§é…ç½®è„šæœ¬
â”‚   â”œâ”€â”€ mongodb_monitoring_setup.sh    # MongoDBç›‘æ§é…ç½®è„šæœ¬
â”‚   â”œâ”€â”€ redis_monitoring_setup.sh      # Redisç›‘æ§é…ç½®è„šæœ¬
â”‚   â”œâ”€â”€ prometheus_config_generator.py # Prometheusé…ç½®ç”Ÿæˆå™¨
â”‚   â””â”€â”€ grafana_dashboard_importer.py  # Grafanaä»ªè¡¨æ¿å¯¼å…¥å™¨
â”œâ”€â”€ configs/                           # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ prometheus/                    # Prometheusé…ç½®
â”‚   â”œâ”€â”€ grafana/                       # Grafanaé…ç½®
â”‚   â”œâ”€â”€ alertmanager/                  # å‘Šè­¦ç®¡ç†é…ç½®
â”‚   â””â”€â”€ exporters/                     # å„ç§exporteré…ç½®
â”œâ”€â”€ dashboards/                        # ç›‘æ§ä»ªè¡¨æ¿
â”‚   â”œâ”€â”€ mysql_performance.json         # MySQLæ€§èƒ½ä»ªè¡¨æ¿
â”‚   â”œâ”€â”€ postgresql_health.json         # PostgreSQLå¥åº·ä»ªè¡¨æ¿
â”‚   â”œâ”€â”€ mongodb_cluster.json           # MongoDBé›†ç¾¤ä»ªè¡¨æ¿
â”‚   â”œâ”€â”€ redis_metrics.json             # RedisæŒ‡æ ‡ä»ªè¡¨æ¿
â”‚   â””â”€â”€ unified_overview.json          # ç»Ÿä¸€æ¦‚è§ˆä»ªè¡¨æ¿
â”œâ”€â”€ alerts/                            # å‘Šè­¦è§„åˆ™
â”‚   â”œâ”€â”€ critical_alerts.yaml           # å…³é”®å‘Šè­¦è§„åˆ™
â”‚   â”œâ”€â”€ warning_alerts.yaml            # è­¦å‘Šå‘Šè­¦è§„åˆ™
â”‚   â”œâ”€â”€ performance_alerts.yaml        # æ€§èƒ½å‘Šè­¦è§„åˆ™
â”‚   â””â”€â”€ custom_business_alerts.yaml    # ä¸šåŠ¡å®šåˆ¶å‘Šè­¦
â”œâ”€â”€ examples/                          # å®é™…æ¡ˆä¾‹
â”‚   â”œâ”€â”€ performance_baselines/         # æ€§èƒ½åŸºçº¿æ¡ˆä¾‹
â”‚   â”œâ”€â”€ anomaly_detection/             # å¼‚å¸¸æ£€æµ‹æ¡ˆä¾‹
â”‚   â”œâ”€â”€ capacity_planning/             # å®¹é‡è§„åˆ’æ¡ˆä¾‹
â”‚   â””â”€â”€ troubleshooting_guides/        # æ•…éšœæ’æŸ¥æŒ‡å—
â””â”€â”€ docs/                              # è¯¦ç»†æ–‡æ¡£
    â”œâ”€â”€ monitoring_architecture.md     # ç›‘æ§æ¶æ„è®¾è®¡
    â”œâ”€â”€ metric_definitions.md          # æŒ‡æ ‡å®šä¹‰æ–‡æ¡£
    â”œâ”€â”€ alert_design_principles.md     # å‘Šè­¦è®¾è®¡åŸåˆ™
    â””â”€â”€ best_practices.md              # æœ€ä½³å®è·µæŒ‡å—
```

## ğŸ“Š ä¼ä¸šçº§ç›‘æ§ä½“ç³»æ¶æ„

### ç›‘æ§æ¶æ„è®¾è®¡
```yaml
# ä¼ä¸šçº§æ•°æ®åº“ç›‘æ§ä½“ç³»æ¶æ„
monitoring_architecture:
  layers:
    - data_collection:     # æ•°æ®æ”¶é›†å±‚
        components:
          - database_exporters:    # æ•°æ®åº“exporter
            - mysqld_exporter
            - postgres_exporter
            - mongodb_exporter
            - redis_exporter
          - custom_exporters:      # è‡ªå®šä¹‰exporter
            - business_metric_exporter
            - application_exporter
          - log_collectors:        # æ—¥å¿—æ”¶é›†å™¨
            - filebeat
            - fluentd
            - promtail
    
    - data_processing:     # æ•°æ®å¤„ç†å±‚
        components:
          - prometheus:            # æŒ‡æ ‡å­˜å‚¨å’ŒæŸ¥è¯¢
            - tsdb_storage
            - rule_evaluation
            - alert_generation
          - loki:                  # æ—¥å¿—å­˜å‚¨å’ŒæŸ¥è¯¢
            - log_aggregation
            - log_parsing
          - alertmanager:          # å‘Šè­¦ç®¡ç†
            - routing
            - deduplication
            - notification
    
    - visualization:       # å¯è§†åŒ–å±‚
        components:
          - grafana:               # ä»ªè¡¨æ¿å±•ç¤º
            - dashboard_templates
            - alert_visualization
            - drill_down_analysis
          - custom_ui:             # å®šåˆ¶ç•Œé¢
            - business_dashboards
            - executive_reports
    
    - integration:         # é›†æˆå±‚
        components:
          - notification_channels: # é€šçŸ¥æ¸ é“
            - email
            - slack
            - webhook
            - sms
          - automation_tools:      # è‡ªåŠ¨åŒ–å·¥å…·
            - ansible_integration
            - terraform_modules
            - ci_cd_pipelines
```

## ğŸ”§ æ ¸å¿ƒç›‘æ§æŠ€æœ¯å®ç°

### 1. MySQLæ€§èƒ½ç›‘æ§ä½“ç³»

```bash
#!/bin/bash
# MySQLä¼ä¸šçº§æ€§èƒ½ç›‘æ§é…ç½®è„šæœ¬

MONITORING_DIR="/opt/monitoring/mysql"
GRAFANA_DASHBOARD_ID=7362  # MySQL Overview dashboard

# å®‰è£…MySQL exporter
install_mysql_exporter() {
  local version="0.15.0"
  local arch=$(uname -m)
  
  echo "å®‰è£…MySQL exporter $version"
  
  # ä¸‹è½½exporter
  wget https://github.com/prometheus/mysqld_exporter/releases/download/v${version}/mysqld_exporter-${version}.linux-${arch}.tar.gz
  tar -xf mysqld_exporter-${version}.linux-${arch}.tar.gz
  
  # ç§»åŠ¨åˆ°ç³»ç»Ÿç›®å½•
  sudo mv mysqld_exporter-${version}.linux-${arch}/mysqld_exporter /usr/local/bin/
  sudo chmod +x /usr/local/bin/mysqld_exporter
  
  # åˆ›å»ºç›‘æ§ç”¨æˆ·
  mysql -u root -p << EOF
CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'ExporterPass123!' WITH MAX_USER_CONNECTIONS 3;
GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost';
FLUSH PRIVILEGES;
EOF
}

# é…ç½®MySQL exporter
configure_mysql_exporter() {
  echo "é…ç½®MySQL exporter"
  
  # åˆ›å»ºé…ç½®æ–‡ä»¶
  sudo mkdir -p $MONITORING_DIR/config
  sudo tee $MONITORING_DIR/config/my.cnf > /dev/null << EOF
[client]
user=exporter
password=ExporterPass123!
host=localhost
port=3306
EOF
  
  # åˆ›å»ºsystemdæœåŠ¡
  sudo tee /etc/systemd/system/mysqld_exporter.service > /dev/null << EOF
[Unit]
Description=MySQL Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
ExecStart=/usr/local/bin/mysqld_exporter \
  --config.my-cnf=$MONITORING_DIR/config/my.cnf \
  --collect.global_status \
  --collect.global_variables \
  --collect.slave_status \
  --collect.info_schema.innodb_metrics \
  --collect.info_schema.processlist \
  --collect.info_schema.tables \
  --collect.perf_schema.tablelocks \
  --collect.perf_schema.eventsstatements \
  --collect.perf_schema.indexiowaits \
  --collect.perf_schema.tableiowaits

[Install]
WantedBy=default.target
EOF
  
  sudo systemctl daemon-reload
  sudo systemctl enable mysqld_exporter
  sudo systemctl start mysqld_exporter
}

# é…ç½®PrometheusæŠ“å–
configure_prometheus_scraping() {
  echo "é…ç½®PrometheusæŠ“å–MySQLæŒ‡æ ‡"
  
  # æ·»åŠ æŠ“å–é…ç½®åˆ°prometheus.yml
  sudo tee -a /etc/prometheus/prometheus.yml > /dev/null << EOF

  - job_name: 'mysql'
    static_configs:
      - targets: ['localhost:9104']
    scrape_interval: 15s
    scrape_timeout: 10s
EOF
  
  sudo systemctl restart prometheus
}

# å¯¼å…¥Grafanaä»ªè¡¨æ¿
import_grafana_dashboard() {
  echo "å¯¼å…¥MySQL Grafanaä»ªè¡¨æ¿"
  
  # ä½¿ç”¨Grafana APIå¯¼å…¥ä»ªè¡¨æ¿
  curl -X POST \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer ${GRAFANA_API_KEY}" \
    -d @- http://localhost:3000/api/dashboards/db << EOF
{
  "dashboard": {
    "id": null,
    "title": "MySQL Performance Overview",
    "tags": ["mysql", "database", "performance"],
    "timezone": "browser",
    "panels": [
      {
        "title": "Connection Statistics",
        "type": "graph",
        "targets": [
          {
            "expr": "mysql_global_status_threads_connected",
            "legendFormat": "Current Connections"
          },
          {
            "expr": "mysql_global_status_max_used_connections",
            "legendFormat": "Max Used Connections"
          }
        ]
      },
      {
        "title": "Query Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(mysql_global_status_questions[5m])",
            "legendFormat": "Queries per Second"
          },
          {
            "expr": "rate(mysql_global_status_slow_queries[5m])",
            "legendFormat": "Slow Queries per Second"
          }
        ]
      },
      {
        "title": "Buffer Pool Usage",
        "type": "gauge",
        "targets": [
          {
            "expr": "mysql_global_status_innodb_buffer_pool_pages_free / mysql_global_status_innodb_buffer_pool_pages_total * 100",
            "legendFormat": "Buffer Pool Free %"
          }
        ]
      }
    ]
  },
  "overwrite": true
}
EOF
}

# é…ç½®å‘Šè­¦è§„åˆ™
configure_alerting_rules() {
  echo "é…ç½®MySQLå‘Šè­¦è§„åˆ™"
  
  sudo tee /etc/prometheus/rules/mysql_alerts.yml > /dev/null << EOF
groups:
- name: mysql.rules
  rules:
  - alert: MySQLDown
    expr: mysql_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "MySQL instance is down"
      description: "MySQL instance {{ \$labels.instance }} is not responding"

  - alert: HighConnectionUsage
    expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High MySQL connection usage"
      description: "MySQL connection usage is {{ \$value }}% on {{ \$labels.instance }}"

  - alert: SlowQueryRateHigh
    expr: rate(mysql_global_status_slow_queries[5m]) > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High slow query rate"
      description: "Slow query rate is {{ \$value }} queries/sec on {{ \$labels.instance }}"
      
  - alert: BufferPoolHitRatioLow
    expr: mysql_global_status_innodb_buffer_pool_read_requests > 0 and
          (1 - mysql_global_status_innodb_buffer_pool_reads / mysql_global_status_innodb_buffer_pool_read_requests) < 0.95
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Low buffer pool hit ratio"
      description: "Buffer pool hit ratio is {{ \$value }} on {{ \$labels.instance }}"
EOF
  
  sudo systemctl restart prometheus
}

# æ€§èƒ½åŸºçº¿æ”¶é›†
collect_performance_baselines() {
  echo "æ”¶é›†ç¾¤æ€§èƒ½åŸºçº¿æ•°æ®"
  
  local baseline_dir="/var/lib/mysql/baselines"
  mkdir -p $baseline_dir
  
  # æ”¶é›†å…³é”®æ€§èƒ½æŒ‡æ ‡
  mysql -u exporter -pExporterPass123! << EOF > $baseline_dir/performance_baseline_$(date +%Y%m%d).sql
-- æ€§èƒ½åŸºçº¿æ•°æ®æ”¶é›†
SELECT 
  'connection_stats' as metric_type,
  VARIABLE_VALUE as current_connections
FROM INFORMATION_SCHEMA.GLOBAL_STATUS 
WHERE VARIABLE_NAME = 'Threads_connected';

SELECT 
  'query_stats' as metric_type,
  VARIABLE_VALUE as questions_per_second
FROM INFORMATION_SCHEMA.GLOBAL_STATUS 
WHERE VARIABLE_NAME = 'Questions';

SELECT 
  'buffer_pool_stats' as metric_type,
  VARIABLE_VALUE as buffer_pool_pages_free
FROM INFORMATION_SCHEMA.GLOBAL_STATUS 
WHERE VARIABLE_NAME = 'Innodb_buffer_pool_pages_free';
EOF
}

# ä¸»æ‰§è¡Œå‡½æ•°
main() {
  case "$1" in
    install)
      install_mysql_exporter
      configure_mysql_exporter
      configure_prometheus_scraping
      import_grafana_dashboard
      configure_alerting_rules
      collect_performance_baselines
      echo "MySQLç›‘æ§é…ç½®å®Œæˆ"
      ;;
    update-baselines)
      collect_performance_baselines
      echo "æ€§èƒ½åŸºçº¿æ›´æ–°å®Œæˆ"
      ;;
    *)
      echo "Usage: $0 {install|update-baselines}"
      exit 1
      ;;
  esac
}

main "$@"
```

### 2. PostgreSQLç›‘æ§ä½“ç³»

```python
#!/usr/bin/env python3
"""
PostgreSQLä¼ä¸šçº§ç›‘æ§é…ç½®ç®¡ç†å™¨
"""

import yaml
import json
import requests
import subprocess
from datetime import datetime
from typing import Dict, List, Optional

class PostgreSQLMonitor:
    """PostgreSQLç›‘æ§ç®¡ç†å™¨"""
    
    def __init__(self, config_file: str = "/etc/postgresql_monitor.yaml"):
        self.config_file = config_file
        self.config = self.load_config()
        self.exporter_port = 9187
    
    def load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            'database_connections': ['localhost:5432'],
            'monitoring_user': 'pg_monitor',
            'grafana_dashboard_id': 9628,
            'alert_thresholds': {
                'connections': 80,  # è¿æ¥ä½¿ç”¨ç‡é˜ˆå€¼
                'slow_queries': 5,   # æ…¢æŸ¥è¯¢é˜ˆå€¼
                'cache_hit_ratio': 95 # ç¼“å­˜å‘½ä¸­ç‡é˜ˆå€¼
            }
        }
        
        try:
            with open(self.config_file, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            return default_config
    
    def install_postgres_exporter(self):
        """å®‰è£…PostgreSQL exporter"""
        print("å®‰è£…PostgreSQL exporter...")
        
        # åˆ›å»ºç›‘æ§ç”¨æˆ·å’Œæƒé™
        setup_sql = """
        CREATE USER pg_monitor WITH PASSWORD 'MonitorPass123!';
        
        -- æˆäºˆå¿…è¦çš„ç›‘æ§æƒé™
        GRANT pg_monitor TO pg_monitor;
        GRANT SELECT ON pg_stat_database TO pg_monitor;
        GRANT SELECT ON pg_stat_user_tables TO pg_monitor;
        GRANT SELECT ON pg_stat_user_indexes TO pg_monitor;
        GRANT SELECT ON pg_statio_user_tables TO pg_monitor;
        
        -- åˆ›å»ºæ‰©å±•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
        """
        
        subprocess.run([
            'psql', '-U', 'postgres', '-c', setup_sql
        ], check=True)
        
        # ä¸‹è½½å¹¶å®‰è£…exporter
        subprocess.run([
            'wget', 'https://github.com/prometheus-community/postgres_exporter/releases/download/v0.12.0/postgres_exporter-0.12.0.linux-amd64.tar.gz'
        ])
        subprocess.run(['tar', '-xf', 'postgres_exporter-0.12.0.linux-amd64.tar.gz'])
        subprocess.run(['sudo', 'mv', 'postgres_exporter-0.12.0.linux-amd64/postgres_exporter', '/usr/local/bin/'])
        
        # é…ç½®ç¯å¢ƒå˜é‡
        env_content = f"DATA_SOURCE_NAME=postgresql://pg_monitor:MonitorPass123!@localhost:5432/postgres?sslmode=disable"
        with open('/etc/postgres_exporter.env', 'w') as f:
            f.write(env_content)
    
    def configure_prometheus(self):
        """é…ç½®PrometheusæŠ“å–"""
        prometheus_config = {
            'scrape_configs': [{
                'job_name': 'postgresql',
                'static_configs': [{
                    'targets': [f'localhost:{self.exporter_port}']
                }],
                'scrape_interval': '15s',
                'scrape_timeout': '10s'
            }]
        }
        
        # æ›´æ–°Prometheusé…ç½®
        config_path = '/etc/prometheus/prometheus.yml'
        with open(config_path, 'r') as f:
            current_config = yaml.safe_load(f)
        
        current_config['scrape_configs'].append(prometheus_config['scrape_configs'][0])
        
        with open(config_path, 'w') as f:
            yaml.dump(current_config, f)
        
        subprocess.run(['systemctl', 'restart', 'prometheus'])
    
    def create_grafana_dashboard(self):
        """åˆ›å»ºGrafanaä»ªè¡¨æ¿"""
        dashboard_config = {
            'dashboard': {
                'title': 'PostgreSQL Performance Dashboard',
                'tags': ['postgresql', 'database', 'performance'],
                'panels': [
                    {
                        'title': 'Connection Statistics',
                        'type': 'graph',
                        'targets': [
                            {'expr': 'pg_stat_database_numbackends', 'legendFormat': '{{datname}} connections'},
                            {'expr': 'pg_settings_max_connections', 'legendFormat': 'Max connections'}
                        ]
                    },
                    {
                        'title': 'Cache Hit Ratio',
                        'type': 'gauge',
                        'targets': [
                            {'expr': 'pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read) * 100'}
                        ]
                    },
                    {
                        'title': 'Slow Queries',
                        'type': 'graph',
                        'targets': [
                            {'expr': 'rate(pg_stat_statements_mean_time_seconds[5m])', 'legendFormat': 'Avg query time'},
                            {'expr': 'rate(pg_stat_statements_calls[5m])', 'legendFormat': 'Query rate'}
                        ]
                    }
                ]
            }
        }
        
        # è°ƒç”¨Grafana API
        response = requests.post(
            'http://localhost:3000/api/dashboards/db',
            headers={
                'Authorization': f'Bearer {self.config.get("grafana_api_key")}',
                'Content-Type': 'application/json'
            },
            json=dashboard_config
        )
        
        return response.status_code == 200
    
    def setup_alerting_rules(self):
        """é…ç½®å‘Šè­¦è§„åˆ™"""
        alert_rules = {
            'groups': [{
                'name': 'postgresql.rules',
                'rules': [
                    {
                        'alert': 'PostgreSQLDown',
                        'expr': 'pg_up == 0',
                        'for': '1m',
                        'labels': {'severity': 'critical'},
                        'annotations': {
                            'summary': 'PostgreSQL instance is down',
                            'description': 'PostgreSQL instance {{ $labels.instance }} is not responding'
                        }
                    },
                    {
                        'alert': 'HighConnectionUsage',
                        'expr': 'pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80',
                        'for': '2m',
                        'labels': {'severity': 'warning'},
                        'annotations': {
                            'summary': 'High PostgreSQL connection usage',
                            'description': 'Connection usage is {{ $value }}% on {{ $labels.instance }}'
                        }
                    }
                ]
            }]
        }
        
        with open('/etc/prometheus/rules/postgresql_alerts.yml', 'w') as f:
            yaml.dump(alert_rules, f)
        
        subprocess.run(['systemctl', 'restart', 'prometheus'])

# ä½¿ç”¨ç¤ºä¾‹
def main():
    monitor = PostgreSQLMonitor()
    monitor.install_postgres_exporter()
    monitor.configure_prometheus()
    monitor.create_grafana_dashboard()
    monitor.setup_alerting_rules()
    print("PostgreSQLç›‘æ§é…ç½®å®Œæˆ")

if __name__ == "__main__":
    main()
```

### 3. MongoDBç›‘æ§ä½“ç³»

```javascript
// MongoDBä¼ä¸šçº§ç›‘æ§é…ç½®è„šæœ¬

// ç›‘æ§é…ç½®å‚æ•°
const MONITORING_CONFIG = {
  exporterPort: 9216,
  grafanaDashboardId: 2583,
  alertThresholds: {
    connections: 80,
    memoryUsage: 85,
    replicationLag: 10, // seconds
    queryLatency: 100   // milliseconds
  }
};

// å®‰è£…MongoDB exporter
function installMongoDBExporter() {
  console.log("å®‰è£…MongoDB exporter...");
  
  // åˆ›å»ºç›‘æ§ç”¨æˆ·
  db.getSiblingDB("admin").createUser({
    user: "monitor",
    pwd: "${DB_PASSWORD}",
    roles: [
      { role: "clusterMonitor", db: "admin" },
      { role: "read", db: "local" }
    ]
  });
  
  // ä¸‹è½½å¹¶å®‰è£…exporter
  const installCmd = `
    wget https://github.com/percona/mongodb_exporter/releases/download/v0.37.0/mongodb_exporter-0.37.0.linux-amd64.tar.gz
    tar -xf mongodb_exporter-0.37.0.linux-amd64.tar.gz
    sudo mv mongodb_exporter-0.37.0.linux-amd64/mongodb_exporter /usr/local/bin/
    sudo chmod +x /usr/local/bin/mongodb_exporter
  `;
  
  exec(installCmd);
}

// é…ç½®MongoDB exporteræœåŠ¡
function configureExporterService() {
  console.log("é…ç½®MongoDB exporteræœåŠ¡...");
  
  const serviceConfig = `
[Unit]
Description=MongoDB Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Environment="MONGODB_URI=mongodb://monitor:MonitorPass456!@localhost:27017/admin"
ExecStart=/usr/local/bin/mongodb_exporter --collect.collection --collect.database --collect.indexusage --collect.topmetrics

[Install]
WantedBy=default.target
  `;
  
  fs.writeFileSync('/etc/systemd/system/mongodb_exporter.service', serviceConfig);
  
  // å¯åŠ¨æœåŠ¡
  exec('systemctl daemon-reload');
  exec('systemctl enable mongodb_exporter');
  exec('systemctl start mongodb_exporter');
}

// é…ç½®PrometheusæŠ“å–
function configurePrometheusScraping() {
  console.log("é…ç½®PrometheusæŠ“å–MongoDBæŒ‡æ ‡...");
  
  const prometheusConfig = {
    scrape_configs: [{
      job_name: 'mongodb',
      static_configs: [{
        targets: [`localhost:${MONITORING_CONFIG.exporterPort}`]
      }],
      scrape_interval: '15s',
      scrape_timeout: '10s'
    }]
  };
  
  // æ›´æ–°Prometheusé…ç½®æ–‡ä»¶
  const currentConfig = yaml.load(fs.readFileSync('/etc/prometheus/prometheus.yml'));
  currentConfig.scrape_configs.push(prometheusConfig.scrape_configs[0]);
  fs.writeFileSync('/etc/prometheus/prometheus.yml', yaml.dump(currentConfig));
  
  exec('systemctl restart prometheus');
}

// åˆ›å»ºGrafanaä»ªè¡¨æ¿
function createGrafanaDashboard() {
  console.log("åˆ›å»ºMongoDB Grafanaä»ªè¡¨æ¿...");
  
  const dashboard = {
    dashboard: {
      title: "MongoDB Cluster Performance",
      tags: ["mongodb", "database", "cluster"],
      panels: [
        {
          title: "Cluster Status",
          type: "stat",
          targets: [
            { expr: "mongodb_up", legendFormat: "Cluster Status" }
          ]
        },
        {
          title: "Operations Rate",
          type: "graph",
          targets: [
            { expr: "rate(mongodb_ss_opcounters_insert[5m])", legendFormat: "Inserts" },
            { expr: "rate(mongodb_ss_opcounters_query[5m])", legendFormat: "Queries" },
            { expr: "rate(mongodb_ss_opcounters_update[5m])", legendFormat: "Updates" }
          ]
        },
        {
          title: "Memory Usage",
          type: "gauge",
          targets: [
            { expr: "mongodb_ss_mem_resident / 1024 / 1024", legendFormat: "Resident Memory (MB)" }
          ]
        }
      ]
    }
  };
  
  // è°ƒç”¨Grafana API
  const response = http.post('http://localhost:3000/api/dashboards/db', {
    headers: {
      'Authorization': `Bearer ${process.env.GRAFANA_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(dashboard)
  });
  
  return response.statusCode === 200;
}

// é…ç½®å‘Šè­¦è§„åˆ™
function setupAlertingRules() {
  console.log("é…ç½®MongoDBå‘Šè­¦è§„åˆ™...");
  
  const alertRules = {
    groups: [{
      name: "mongodb.rules",
      rules: [
        {
          alert: "MongoDBDown",
          expr: "mongodb_up == 0",
          for: "1m",
          labels: { severity: "critical" },
          annotations: {
            summary: "MongoDB instance is down",
            description: "MongoDB instance {{ $labels.instance }} is not responding"
          }
        },
        {
          alert: "HighConnectionUsage",
          expr: "mongodb_ss_connections_current / mongodb_ss_connections_available * 100 > 80",
          for: "2m",
          labels: { severity: "warning" },
          annotations: {
            summary: "High MongoDB connection usage",
            description: "Connection usage is {{ $value }}% on {{ $labels.instance }}"
          }
        }
      ]
    }]
  };
  
  fs.writeFileSync('/etc/prometheus/rules/mongodb_alerts.yml', yaml.dump(alertRules));
  exec('systemctl restart prometheus');
}

// æ‰§è¡Œç›‘æ§é…ç½®
function setupMongoDBMonitoring() {
  installMongoDBExporter();
  configureExporterService();
  configurePrometheusScraping();
  createGrafanaDashboard();
  setupAlertingRules();
  
  console.log("MongoDBç›‘æ§é…ç½®å®Œæˆ");
}

// è¿è¡Œé…ç½®
setupMongoDBMonitoring();
```

### 4. Redisç›‘æ§ä½“ç³»

```bash
#!/bin/bash
# Redisä¼ä¸šçº§ç›‘æ§é…ç½®è„šæœ¬

REDIS_EXPORTER_VERSION="1.52.0"
EXPORTER_PORT=9121
GRAFANA_DASHBOARD_ID=763

# å®‰è£…Redis exporter
install_redis_exporter() {
  echo "å®‰è£…Redis exporter $REDIS_EXPORTER_VERSION"
  
  wget https://github.com/oliver006/redis_exporter/releases/download/v${REDIS_EXPORTER_VERSION}/redis_exporter-v${REDIS_EXPORTER_VERSION}.linux-amd64.tar.gz
  tar -xf redis_exporter-v${REDIS_EXPORTER_VERSION}.linux-amd64.tar.gz
  
  sudo mv redis_exporter-v${REDIS_EXPORTER_VERSION}.linux-amd64/redis_exporter /usr/local/bin/
  sudo chmod +x /usr/local/bin/redis_exporter
}

# é…ç½®Redis exporteræœåŠ¡
configure_redis_exporter() {
  echo "é…ç½®Redis exporteræœåŠ¡"
  
  sudo tee /etc/systemd/system/redis_exporter.service > /dev/null << EOF
[Unit]
Description=Redis Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Environment="REDIS_ADDR=redis://localhost:6379"
Environment="redis_password: "${DB_PASSWORD}"é…ç½®PrometheusæŠ“å–RedisæŒ‡æ ‡"
  
  sudo tee -a /etc/prometheus/prometheus.yml > /dev/null << EOF

  - job_name: 'redis'
    static_configs:
      - targets: ['localhost:${EXPORTER_PORT}']
    scrape_interval: 15s
    scrape_timeout: 10s
EOF
  
  sudo systemctl restart prometheus
}

# åˆ›å»ºRedisç›‘æ§ä»ªè¡¨æ¿
create_redis_dashboard() {
  echo "åˆ›å»ºRedis Grafanaä»ªè¡¨æ¿"
  
  local dashboard_json=$(cat << EOF
{
  "dashboard": {
    "title": "Redis Performance Dashboard",
    "tags": ["redis", "cache", "performance"],
    "panels": [
      {
        "title": "Redis Status",
        "type": "stat",
        "targets": [
          { "expr": "redis_up", "legendFormat": "Redis Status" }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "gauge",
        "targets": [
          { "expr": "redis_memory_used_bytes / redis_memory_max_bytes * 100", "legendFormat": "Memory Usage %" }
        ]
      },
      {
        "title": "Commands Processed",
        "type": "graph",
        "targets": [
          { "expr": "rate(redis_commands_processed_total[5m])", "legendFormat": "Commands/sec" }
        ]
      },
      {
        "title": "Connected Clients",
        "type": "graph",
        "targets": [
          { "expr": "redis_connected_clients", "legendFormat": "Connected Clients" }
        ]
      },
      {
        "title": "Hit Ratio",
        "type": "gauge",
        "targets": [
          { "expr": "redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) * 100", "legendFormat": "Hit Ratio %" }
        ]
      }
    ]
  }
}
EOF
)
  
  curl -X POST \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer ${GRAFANA_API_KEY}" \
    -d "$dashboard_json" \
    http://localhost:3000/api/dashboards/db
}

# é…ç½®Rediså‘Šè­¦è§„åˆ™
configure_redis_alerts() {
  echo "é…ç½®Rediså‘Šè­¦è§„åˆ™"
  
  sudo tee /etc/prometheus/rules/redis_alerts.yml > /dev/null << EOF
groups:
- name: redis.rules
  rules:
  - alert: RedisDown
    expr: redis_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Redis instance is down"
      description: "Redis instance {{ \$labels.instance }} is not responding"

  - alert: HighMemoryUsage
    expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High Redis memory usage"
      description: "Redis memory usage is {{ \$value }}% on {{ \$labels.instance }}"

  - alert: LowHitRatio
    expr: redis_keyspace_hits_total > 0 and 
          redis_keyspace_misses_total > 0 and
          (redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)) < 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Low Redis hit ratio"
      description: "Redis hit ratio is {{ \$value }} on {{ \$labels.instance }}"
      
  - alert: HighConnectedClients
    expr: redis_connected_clients > 1000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "High Redis connected clients"
      description: "Redis has {{ \$value }} connected clients on {{ \$labels.instance }}"
EOF
  
  sudo systemctl restart prometheus
}

# Redisæ€§èƒ½åŸºå‡†æµ‹è¯•
run_redis_benchmark() {
  echo "æ‰§è¡ŒRedisæ€§èƒ½åŸºå‡†æµ‹è¯•"
  
  local benchmark_results="/var/log/redis/benchmark_$(date +%Y%m%d_%H%M%S).txt"
  
  # æ‰§è¡ŒåŸºå‡†æµ‹è¯•
  redis-benchmark -h localhost -p 6379 -n 100000 -c 50 -t get,set,lpush,lpop -q > "$benchmark_results"
  
  echo "åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜: $benchmark_results"
  
  # è§£æç»“æœå¹¶è®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
  local get_ops=$(grep "GET" "$benchmark_results" | awk '{print $2}')
  local set_ops=$(grep "SET" "$benchmark_results" | awk '{print $2}')
  
  echo "GETæ“ä½œæ€§èƒ½: $get_ops ops/sec"
  echo "SETæ“ä½œæ€§èƒ½: $set_ops ops/sec"
}

# ä¸»æ‰§è¡Œå‡½æ•°
main() {
  case "$1" in
    install)
      install_redis_exporter
      configure_redis_exporter
      configure_prometheus_redis
      create_redis_dashboard
      configure_redis_alerts
      run_redis_benchmark
      echo "Redisç›‘æ§é…ç½®å®Œæˆ"
      ;;
    benchmark)
      run_redis_benchmark
      ;;
    *)
      echo "Usage: $0 {install|benchmark}"
      exit 1
      ;;
  esac
}

main "$@"
```

## ğŸ¯ ç»Ÿä¸€ç›‘æ§å¹³å°

### ç›‘æ§ç¼–æ’ç®¡ç†å™¨
```python
#!/usr/bin/env python3
"""
ä¼ä¸šçº§ç»Ÿä¸€ç›‘æ§å¹³å°ç¼–æ’å™¨
æ”¯æŒå¤šæ•°æ®åº“ç›‘æ§çš„ä¸€ä½“åŒ–ç®¡ç†
"""

import asyncio
import json
import yaml
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class DatabaseMonitorConfig:
    """æ•°æ®åº“ç›‘æ§é…ç½®"""
    database_type: str
    host: str
    port: int
    exporter_port: int
    dashboard_id: int
    enabled: bool = True

class UnifiedMonitoringPlatform:
    """ç»Ÿä¸€ç›‘æ§å¹³å°ç®¡ç†å™¨"""
    
    def __init__(self, config_file: str = "/etc/unified_monitoring.yaml"):
        self.config_file = config_file
        self.databases = []
        self.load_configuration()
    
    def load_configuration(self):
        """åŠ è½½ç›‘æ§é…ç½®"""
        default_config = {
            'databases': [
                {
                    'database_type': 'mysql',
                    'host': 'localhost',
                    'port': 3306,
                    'exporter_port': 9104,
                    'dashboard_id': 7362,
                    'enabled': True
                },
                {
                    'database_type': 'postgresql',
                    'host': 'localhost',
                    'port': 5432,
                    'exporter_port': 9187,
                    'dashboard_id': 9628,
                    'enabled': True
                },
                {
                    'database_type': 'mongodb',
                    'host': 'localhost',
                    'port': 27017,
                    'exporter_port': 9216,
                    'dashboard_id': 2583,
                    'enabled': True
                },
                {
                    'database_type': 'redis',
                    'host': 'localhost',
                    'port': 6379,
                    'exporter_port': 9121,
                    'dashboard_id': 763,
                    'enabled': True
                }
            ]
        }
        
        try:
            with open(self.config_file, 'r') as f:
                config = yaml.safe_load(f)
                self.databases = [DatabaseMonitorConfig(**db) for db in config.get('databases', [])]
        except FileNotFoundError:
            self.databases = [DatabaseMonitorConfig(**db) for db in default_config['databases']]
    
    async def deploy_monitoring_stack(self):
        """éƒ¨ç½²ç›‘æ§æ ˆ"""
        print("å¼€å§‹éƒ¨ç½²ç»Ÿä¸€ç›‘æ§æ ˆ...")
        
        tasks = []
        for db_config in self.databases:
            if db_config.enabled:
                task = self.deploy_database_monitoring(db_config)
                tasks.append(task)
        
        await asyncio.gather(*tasks)
        print("ç›‘æ§æ ˆéƒ¨ç½²å®Œæˆ")
    
    async def deploy_database_monitoring(self, config: DatabaseMonitorConfig):
        """éƒ¨ç½²å•ä¸ªæ•°æ®åº“ç›‘æ§"""
        print(f"éƒ¨ç½²{config.database_type}ç›‘æ§...")
        
        # æ ¹æ®æ•°æ®åº“ç±»å‹æ‰§è¡Œç›¸åº”è„šæœ¬
        script_map = {
            'mysql': './scripts/mysql_monitoring_setup.sh',
            'postgresql': './scripts/postgresql_monitoring_setup.sh',
            'mongodb': './scripts/mongodb_monitoring_setup.sh',
            'redis': './scripts/redis_monitoring_setup.sh'
        }
        
        script_path = script_map.get(config.database_type)
        if script_path:
            import subprocess
            result = subprocess.run([script_path, 'install'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"{config.database_type}ç›‘æ§éƒ¨ç½²æˆåŠŸ")
            else:
                print(f"{config.database_type}ç›‘æ§éƒ¨ç½²å¤±è´¥: {result.stderr}")
    
    def generate_unified_dashboard(self):
        """ç”Ÿæˆç»Ÿä¸€ç›‘æ§ä»ªè¡¨æ¿"""
        print("ç”Ÿæˆç»Ÿä¸€ç›‘æ§ä»ªè¡¨æ¿...")
        
        unified_dashboard = {
            'dashboard': {
                'title': 'Unified Database Performance Overview',
                'tags': ['unified', 'database', 'performance'],
                'panels': []
            }
        }
        
        # ä¸ºæ¯ä¸ªæ•°æ®åº“æ·»åŠ æ¦‚è§ˆé¢æ¿
        panel_id = 1
        for db_config in self.databases:
            if db_config.enabled:
                panel = {
                    'id': panel_id,
                    'title': f'{db_config.database_type.upper()} Overview',
                    'type': 'graph',
                    'gridPos': {'x': ((panel_id-1) % 2) * 12, 'y': ((panel_id-1) // 2) * 8, 'w': 12, 'h': 8},
                    'targets': [
                        {
                            'expr': f'{db_config.database_type}_up',
                            'legendFormat': f'{db_config.database_type} Status'
                        }
                    ]
                }
                unified_dashboard['dashboard']['panels'].append(panel)
                panel_id += 1
        
        # è°ƒç”¨Grafana APIåˆ›å»ºä»ªè¡¨æ¿
        import requests
        response = requests.post(
            'http://localhost:3000/api/dashboards/db',
            headers={
                'Authorization': f'Bearer {self.get_grafana_api_key()}',
                'Content-Type': 'application/json'
            },
            json=unified_dashboard
        )
        
        return response.status_code == 200
    
    def get_grafana_api_key(self) -> str:
        """è·å–Grafana APIå¯†é’¥"""
        # ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        return "your_grafana_api_key_here"
    
    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        print("æ‰§è¡Œç›‘æ§ç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        
        import subprocess
        services = ['prometheus', 'grafana-server', 'alertmanager']
        
        for service in services:
            result = subprocess.run(['systemctl', 'is-active', service], capture_output=True, text=True)
            if result.stdout.strip() == 'active':
                print(f"âœ… {service} è¿è¡Œæ­£å¸¸")
            else:
                print(f"âŒ {service} è¿è¡Œå¼‚å¸¸")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    platform = UnifiedMonitoringPlatform()
    await platform.deploy_monitoring_stack()
    platform.generate_unified_dashboard()
    platform.health_check()

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ§ª ç›‘æ§éªŒè¯æµ‹è¯•

### è‡ªåŠ¨åŒ–ç›‘æ§æµ‹è¯•å¥—ä»¶
```bash
#!/bin/bash
# æ•°æ®åº“ç›‘æ§éªŒè¯æµ‹è¯•å¥—ä»¶

TEST_RESULTS=()

# Prometheusè¿æ¥æµ‹è¯•
test_prometheus_connection() {
  echo "=== Prometheusè¿æ¥æµ‹è¯• ==="
  
  local prometheus_url="http://localhost:9090"
  local response=$(curl -s -o /dev/null -w "%{http_code}" $prometheus_url/-/healthy)
  
  if [ "$response" = "200" ]; then
    TEST_RESULTS+=("Prometheusè¿æ¥æµ‹è¯•: é€šè¿‡")
    echo "âœ… PrometheusæœåŠ¡æ­£å¸¸"
  else
    TEST_RESULTS+=("Prometheusè¿æ¥æµ‹è¯•: å¤±è´¥")
    echo "âŒ PrometheusæœåŠ¡å¼‚å¸¸"
  fi
}

# Grafanaè¿æ¥æµ‹è¯•
test_grafana_connection() {
  echo "=== Grafanaè¿æ¥æµ‹è¯• ==="
  
  local grafana_url="http://localhost:3000"
  local response=$(curl -s -o /dev/null -w "%{http_code}" $grafana_url/api/health)
  
  if [ "$response" = "200" ]; then
    TEST_RESULTS+=("Grafanaè¿æ¥æµ‹è¯•: é€šè¿‡")
    echo "âœ… GrafanaæœåŠ¡æ­£å¸¸"
  else
    TEST_RESULTS+=("Grafanaè¿æ¥æµ‹è¯•: å¤±è´¥")
    echo "âŒ GrafanaæœåŠ¡å¼‚å¸¸"
  fi
}

# æ•°æ®åº“Exporteræµ‹è¯•
test_database_exporters() {
  echo "=== æ•°æ®åº“Exporteræµ‹è¯• ==="
  
  local exporters=(
    "mysql:http://localhost:9104/metrics"
    "postgresql:http://localhost:9187/metrics"
    "mongodb:http://localhost:9216/metrics"
    "redis:http://localhost:9121/metrics"
  )
  
  for exporter in "${exporters[@]}"; do
    local name=$(echo $exporter | cut -d: -f1)
    local url=$(echo $exporter | cut -d: -f2-)
    
    local response=$(curl -s -o /dev/null -w "%{http_code}" $url)
    if [ "$response" = "200" ]; then
      TEST_RESULTS+=("${name} Exporteræµ‹è¯•: é€šè¿‡")
      echo "âœ… ${name} Exporteræ­£å¸¸"
    else
      TEST_RESULTS+=("${name} Exporteræµ‹è¯•: å¤±è´¥")
      echo "âŒ ${name} Exporterå¼‚å¸¸"
    fi
  done
}

# å‘Šè­¦è§„åˆ™æµ‹è¯•
test_alerting_rules() {
  echo "=== å‘Šè­¦è§„åˆ™æµ‹è¯• ==="
  
  # æ£€æŸ¥å‘Šè­¦è§„åˆ™æ–‡ä»¶
  local rule_files=(
    "/etc/prometheus/rules/mysql_alerts.yml"
    "/etc/prometheus/rules/postgresql_alerts.yml"
    "/etc/prometheus/rules/mongodb_alerts.yml"
    "/etc/prometheus/rules/redis_alerts.yml"
  )
  
  for rule_file in "${rule_files[@]}"; do
    if [ -f "$rule_file" ]; then
      TEST_RESULTS+=("$(basename $rule_file) å­˜åœ¨æ€§æµ‹è¯•: é€šè¿‡")
      echo "âœ… $(basename $rule_file) å­˜åœ¨"
    else
      TEST_RESULTS+=("$(basename $rule_file) å­˜åœ¨æ€§æµ‹è¯•: å¤±è´¥")
      echo "âŒ $(basename $rule_file) ä¸å­˜åœ¨"
    fi
  done
}

# ä»ªè¡¨æ¿æµ‹è¯•
test_grafana_dashboards() {
  echo "=== Grafanaä»ªè¡¨æ¿æµ‹è¯• ==="
  
  # æ£€æŸ¥é»˜è®¤ä»ªè¡¨æ¿æ˜¯å¦å­˜åœ¨
  local dashboard_check=$(curl -s -H "Authorization: Bearer ${GRAFANA_API_KEY}" \
    "http://localhost:3000/api/search?query=MySQL" | jq '. | length')
  
  if [ "$dashboard_check" -gt 0 ]; then
    TEST_RESULTS+=("Grafanaä»ªè¡¨æ¿æµ‹è¯•: é€šè¿‡")
    echo "âœ… Grafanaä»ªè¡¨æ¿å­˜åœ¨"
  else
    TEST_RESULTS+=("Grafanaä»ªè¡¨æ¿æµ‹è¯•: å¤±è´¥")
    echo "âŒ Grafanaä»ªè¡¨æ¿ä¸å­˜åœ¨"
  fi
}

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
generate_monitoring_test_report() {
  echo "=== ç›‘æ§ç³»ç»Ÿæµ‹è¯•ç»¼åˆæŠ¥å‘Š ==="
  
  local total_tests=${#TEST_RESULTS[@]}
  local passed_tests=0
  
  for result in "${TEST_RESULTS[@]}"; do
    echo "$result"
    if [[ $result == *"é€šè¿‡"* ]]; then
      ((passed_tests++))
    fi
  done
  
  echo ""
  echo "æµ‹è¯•æ€»ç»“:"
  echo "æ€»æµ‹è¯•é¡¹: $total_tests"
  echo "é€šè¿‡é¡¹: $passed_tests"
  echo "é€šè¿‡ç‡: $((passed_tests * 100 / total_tests))%"
  
  # ä¿å­˜æŠ¥å‘Š
  local report_file="/tmp/monitoring_test_report_$(date +%Y%m%d_%H%M%S).txt"
  printf "%s\n" "${TEST_RESULTS[@]}" > "$report_file"
  echo "è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: $report_file"
}

# æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
test_prometheus_connection
test_grafana_connection
test_database_exporters
test_alerting_rules
test_grafana_dashboards
generate_monitoring_test_report
```

## ğŸ“š æœ€ä½³å®è·µæ€»ç»“

### ç›‘æ§ä½“ç³»è®¾è®¡åŸåˆ™
1. **å…¨é¢è¦†ç›–**: ç›‘æ§æ‰€æœ‰å…³é”®ç»„ä»¶å’ŒæŒ‡æ ‡
2. **åˆ†å±‚å‘Šè­¦**: è®¾ç½®ä¸åŒçº§åˆ«çš„å‘Šè­¦é˜ˆå€¼
3. **å¯è§†åŒ–å‹å¥½**: æä¾›ç›´è§‚çš„ä»ªè¡¨æ¿å’Œå›¾è¡¨
4. **è‡ªåŠ¨åŒ–å“åº”**: é…ç½®è‡ªåŠ¨åŒ–çš„æ•…éšœå“åº”æœºåˆ¶
5. **å†å²è¿½æº¯**: ä¿ç•™è¶³å¤Ÿçš„å†å²æ•°æ®ç”¨äºåˆ†æ
6. **æ€§èƒ½å½±å“æœ€å°**: ç›‘æ§ç³»ç»Ÿæœ¬èº«ä¸åº”å½±å“è¢«ç›‘æ§ç³»ç»Ÿæ€§èƒ½

### å…³é”®ç›‘æ§æŒ‡æ ‡
- **å¯ç”¨æ€§æŒ‡æ ‡**: uptimeã€è¿æ¥çŠ¶æ€ã€æœåŠ¡å¥åº·æ£€æŸ¥
- **æ€§èƒ½æŒ‡æ ‡**: å“åº”æ—¶é—´ã€ååé‡ã€èµ„æºåˆ©ç”¨ç‡
- **å®¹é‡æŒ‡æ ‡**: å­˜å‚¨ä½¿ç”¨ç‡ã€è¿æ¥æ•°ã€ç¼“å­˜å‘½ä¸­ç‡
- **ä¸šåŠ¡æŒ‡æ ‡**: äº¤æ˜“æˆåŠŸç‡ã€ç”¨æˆ·å“åº”æ—¶é—´ã€é”™è¯¯ç‡

### å‘Šè­¦è®¾è®¡åŸåˆ™
- **é¿å…å‘Šè­¦ç–²åŠ³**: åˆç†è®¾ç½®å‘Šè­¦é˜ˆå€¼å’Œé¢‘ç‡
- **åˆ†çº§å¤„ç†**: critical/warning/infoä¸‰çº§å‘Šè­¦
- **ä¸Šä¸‹æ–‡ä¿¡æ¯**: æä¾›è¶³å¤Ÿçš„æ•…éšœè¯Šæ–­ä¿¡æ¯
- **è‡ªåŠ¨åŒ–å¤„ç†**: å¯è‡ªåŠ¨æ¢å¤çš„é—®é¢˜é…ç½®è‡ªåŠ¨å¤„ç†

---
> **ğŸ’¡ æç¤º**: ç›‘æ§ä¸æ˜¯ä¸€æ¬¡æ€§å·¥ä½œï¼Œéœ€è¦æ ¹æ®ä¸šåŠ¡å‘å±•å’Œç³»ç»Ÿå˜åŒ–æŒç»­ä¼˜åŒ–è°ƒæ•´ç›‘æ§ç­–ç•¥å’Œå‘Šè­¦è§„åˆ™ã€‚
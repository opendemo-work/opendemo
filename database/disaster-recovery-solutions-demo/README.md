# æ•°æ®åº“å®¹ç¾è§£å†³æ–¹æ¡ˆå®Œæ•´æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æ•°æ®åº“å®¹ç¾è§£å†³æ–¹æ¡ˆæ˜¯ä¿éšœä¸šåŠ¡è¿ç»­æ€§çš„ç»ˆæé˜²çº¿ï¼Œé€šè¿‡åœ¨ä¸åŒåœ°ç†ä½ç½®éƒ¨ç½²å†—ä½™ç³»ç»Ÿï¼Œç¡®ä¿åœ¨å‘ç”Ÿé‡å¤§ç¾éš¾æ—¶èƒ½å¤Ÿå¿«é€Ÿæ¢å¤ä¸šåŠ¡è¿è¥ã€‚æœ¬æŒ‡å—æä¾›ä»æˆ˜ç•¥è§„åˆ’åˆ°æŠ€æœ¯å®æ–½çš„å®Œæ•´å®¹ç¾è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

1. [å®¹ç¾åŸºç¡€ç†è®º](#1-å®¹ç¾åŸºç¡€ç†è®º)
2. [å®¹ç¾ç­–ç•¥åˆ¶å®š](#2-å®¹ç¾ç­–ç•¥åˆ¶å®š)
3. [å¤šåœ°åŸŸéƒ¨ç½²æ¶æ„](#3-å¤šåœ°åŸŸéƒ¨ç½²æ¶æ„)
4. [æ•°æ®åŒæ­¥ä¸å¤åˆ¶](#4-æ•°æ®åŒæ­¥ä¸å¤åˆ¶)
5. [å®¹ç¾æ¼”ç»ƒä¸æµ‹è¯•](#5-å®¹ç¾æ¼”ç»ƒä¸æµ‹è¯•)
6. [æ•…éšœæ¢å¤æµç¨‹](#6-æ•…éšœæ¢å¤æµç¨‹)

---

## 1. å®¹ç¾åŸºç¡€ç†è®º

### 1.1 å®¹ç¾æ ¸å¿ƒæ¦‚å¿µ

#### å®¹ç¾ç­‰çº§å®šä¹‰
```mermaid
graph TD
    A[å®¹ç¾ç­‰çº§] --> B[Tier 0 - æ— å®¹ç¾]
    A --> C[Tier 1 - å¤‡ç”¨ç«™ç‚¹]
    A --> D[Tier 2 - çƒ­å¤‡ç«™ç‚¹]
    A --> E[Tier 3 - æ´»åŠ¨ç«™ç‚¹]
    A --> F[Tier 4 - å¤šæ´»æ¶æ„]
    
    B --> B1[æ— å¤‡ç”¨ç³»ç»Ÿ]
    B --> B2[æœ€é•¿æ¢å¤æ—¶é—´]
    
    C --> C1[å†·å¤‡ç«™ç‚¹]
    C --> C2[è¾ƒé•¿æ¢å¤æ—¶é—´]
    
    D --> D1[çƒ­å¤‡ç«™ç‚¹]
    D --> D2[è¾ƒçŸ­æ¢å¤æ—¶é—´]
    
    E --> E1[å‡†å®æ—¶åŒæ­¥]
    E --> E2[åˆ†é’Ÿçº§æ¢å¤]
    
    F --> F1[å®æ—¶åŒæ­¥]
    F --> F2[ç§’çº§æ¢å¤]
```

#### å…³é”®å®¹ç¾æŒ‡æ ‡
```yaml
disaster_recovery_metrics:
  rto:
    description: "æ¢å¤æ—¶é—´ç›®æ ‡ (Recovery Time Objective)"
    definition: "ç³»ç»Ÿä»æ•…éšœåˆ°æ¢å¤æ­£å¸¸è¿è¡Œçš„æœ€å¤§å¯æ¥å—æ—¶é—´"
    examples:
      - "Tier 1: 24-72å°æ—¶"
      - "Tier 2: 4-24å°æ—¶"
      - "Tier 3: 1-4å°æ—¶"
      - "Tier 4: 0-60åˆ†é’Ÿ"
  
  rpo:
    description: "æ¢å¤ç‚¹ç›®æ ‡ (Recovery Point Objective)"
    definition: "å¯æ¥å—çš„æœ€å¤§æ•°æ®ä¸¢å¤±é‡"
    examples:
      - "Tier 1: æ•°å°æ—¶åˆ°æ•°å¤©"
      - "Tier 2: æ•°ååˆ†é’Ÿåˆ°æ•°å°æ—¶"
      - "Tier 3: æ•°åˆ†é’Ÿ"
      - "Tier 4: æ¥è¿‘é›¶æ•°æ®ä¸¢å¤±"
  
  slr:
    description: "æœåŠ¡æ°´å¹³æ¢å¤ (Service Level Recovery)"
    definition: "æ¢å¤åçš„æœåŠ¡æ°´å¹³è¦æ±‚"
    examples:
      - "Tier 1: åŸºç¡€åŠŸèƒ½"
      - "Tier 2: æ ¸å¿ƒåŠŸèƒ½"
      - "Tier 3: å®Œæ•´åŠŸèƒ½"
      - "Tier 4: å…¨éƒ¨åŠŸèƒ½"
```

### 1.2 å®¹ç¾æ¶æ„æ¨¡å¼

#### å®¹ç¾æ¶æ„åˆ†ç±»
```python
# å®¹ç¾æ¶æ„æ¨¡å¼åˆ†æ
class DisasterRecoveryArchitectures:
    def __init__(self):
        self.architectures = {
            'cold_standby': {
                'description': 'å†·å¤‡æ¶æ„',
                'characteristics': {
                    'infrastructure': 'åŸºç¡€è®¾å¤‡å°±ç»ªï¼Œè½¯ä»¶æœªéƒ¨ç½²',
                    'activation_time': 'æ•°å¤©åˆ°æ•°å‘¨',
                    'cost': 'ä½',
                    'complexity': 'ç®€å•'
                },
                'use_cases': ['éå…³é”®ä¸šåŠ¡', 'é¢„ç®—æœ‰é™åœºæ™¯', 'åˆè§„è¦æ±‚æœ€ä½åœºæ™¯']
            },
            
            'warm_standby': {
                'description': 'æ¸©å¤‡æ¶æ„',
                'characteristics': {
                    'infrastructure': 'åŸºç¡€è®¾æ–½å’Œè½¯ä»¶å°±ç»ª',
                    'activation_time': 'æ•°å°æ—¶åˆ°ä¸€å¤©',
                    'cost': 'ä¸­ç­‰',
                    'complexity': 'ä¸­ç­‰'
                },
                'use_cases': ['é‡è¦ä¸šåŠ¡ç³»ç»Ÿ', 'ä¸­ç­‰RTOè¦æ±‚', 'æˆæœ¬æ•æ„Ÿåœºæ™¯']
            },
            
            'hot_standby': {
                'description': 'çƒ­å¤‡æ¶æ„',
                'characteristics': {
                    'infrastructure': 'å®Œå…¨å°±ç»ªçš„å¤‡ç”¨ç³»ç»Ÿ',
                    'activation_time': 'æ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶',
                    'cost': 'è¾ƒé«˜',
                    'complexity': 'å¤æ‚'
                },
                'use_cases': ['å…³é”®ä¸šåŠ¡ç³»ç»Ÿ', 'ä¸¥æ ¼RTOè¦æ±‚', 'é‡‘èæœåŠ¡åœºæ™¯']
            },
            
            'active_active': {
                'description': 'åŒæ´»æ¶æ„',
                'characteristics': {
                    'infrastructure': 'ä¸¤ä¸ªæ´»åŠ¨ç«™ç‚¹åŒæ—¶æœåŠ¡',
                    'activation_time': 'å‡ ä¹å³æ—¶',
                    'cost': 'æœ€é«˜',
                    'complexity': 'éå¸¸å¤æ‚'
                },
                'use_cases': ['æ ¸å¿ƒä¸šåŠ¡ç³»ç»Ÿ', 'é›¶å®¹å¿åœæœº', 'å¤§å‹äº’è”ç½‘å…¬å¸']
            }
        }
    
    def evaluate_architecture_fit(self, business_requirements):
        """è¯„ä¼°é€‚åˆçš„æ¶æ„"""
        scores = {}
        
        for arch_name, arch_info in self.architectures.items():
            score = 0
            
            # RTOåŒ¹é…åº¦è¯„åˆ†
            rto_requirement = business_requirements.get('rto_hours', 24)
            arch_activation_time = self._parse_activation_time(arch_info['characteristics']['activation_time'])
            
            if rto_requirement >= arch_activation_time:
                score += 40
            
            # æˆæœ¬é¢„ç®—è¯„åˆ†
            budget_constraint = business_requirements.get('budget_constraint', 'medium')
            arch_cost = arch_info['characteristics']['cost']
            
            cost_mapping = {'low': 1, 'medium': 2, 'high': 3, 'highest': 4}
            if cost_mapping[budget_constraint] >= cost_mapping[arch_cost]:
                score += 30
            
            # ä¸šåŠ¡é‡è¦æ€§è¯„åˆ†
            business_criticality = business_requirements.get('criticality', 'medium')
            criticality_mapping = {'low': 1, 'medium': 2, 'high': 3, 'critical': 4}
            
            if criticality_mapping[business_criticality] <= cost_mapping[arch_cost]:
                score += 30
            
            scores[arch_name] = score
        
        best_architecture = max(scores, key=scores.get)
        return {
            'recommended': best_architecture,
            'score': scores[best_architecture],
            'details': self.architectures[best_architecture],
            'alternatives': sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]
        }
    
    def _parse_activation_time(self, time_string):
        """è§£ææ¿€æ´»æ—¶é—´å­—ç¬¦ä¸²"""
        import re
        numbers = re.findall(r'\d+', time_string)
        if 'åˆ†é’Ÿ' in time_string:
            return int(numbers[0]) / 60 if numbers else 1
        elif 'å°æ—¶' in time_string:
            return int(numbers[0]) if numbers else 24
        elif 'å¤©' in time_string:
            return int(numbers[0]) * 24 if numbers else 72
        else:
            return 24  # é»˜è®¤24å°æ—¶

# ä½¿ç”¨ç¤ºä¾‹
dr_architectures = DisasterRecoveryArchitectures()

requirements = {
    'rto_hours': 2,
    'budget_constraint': 'high',
    'criticality': 'critical'
}

recommendation = dr_architectures.evaluate_architecture_fit(requirements)
print(f"æ¨èæ¶æ„: {recommendation['recommended']}")
print(f"è¯¦ç»†ä¿¡æ¯: {recommendation['details']}")
```

## 2. å®¹ç¾ç­–ç•¥åˆ¶å®š

### 2.1 ä¸šåŠ¡å½±å“åˆ†æ

#### BIA (Business Impact Analysis) æ¨¡æ¿
```python
# ä¸šåŠ¡å½±å“åˆ†æå·¥å…·
class BusinessImpactAnalyzer:
    def __init__(self):
        self.business_functions = []
        self.dependencies = {}
        self.recovery_requirements = {}
    
    def add_business_function(self, function_name, criticality, dependencies=None):
        """æ·»åŠ ä¸šåŠ¡åŠŸèƒ½"""
        self.business_functions.append({
            'name': function_name,
            'criticality': criticality,  # critical, high, medium, low
            'dependencies': dependencies or []
        })
        
        if dependencies:
            self.dependencies[function_name] = dependencies
    
    def analyze_impact(self, disruption_scenario):
        """åˆ†æä¸­æ–­å½±å“"""
        impact_analysis = {
            'immediate_impact': [],
            'cascading_impact': [],
            'financial_impact': {},
            'recovery_priorities': []
        }
        
        # ç›´æ¥å½±å“åˆ†æ
        for function in self.business_functions:
            if function['name'] in disruption_scenario['affected_systems']:
                impact_analysis['immediate_impact'].append({
                    'function': function['name'],
                    'criticality': function['criticality'],
                    'impact_severity': self._assess_impact_severity(function['criticality'])
                })
        
        # çº§è”å½±å“åˆ†æ
        cascading_functions = self._find_cascading_impacts(disruption_scenario['affected_systems'])
        for func in cascading_functions:
            impact_analysis['cascading_impact'].append({
                'function': func,
                'reason': f"ä¾èµ–äº{self.dependencies[func]}",
                'impact_severity': self._assess_impact_severity(
                    self._get_function_criticality(func)
                )
            })
        
        # è´¢åŠ¡å½±å“è®¡ç®—
        impact_analysis['financial_impact'] = self._calculate_financial_impact(
            impact_analysis['immediate_impact'],
            disruption_scenario['duration_hours']
        )
        
        # æ¢å¤ä¼˜å…ˆçº§æ’åº
        impact_analysis['recovery_priorities'] = self._prioritize_recovery(
            impact_analysis['immediate_impact'] + impact_analysis['cascading_impact']
        )
        
        return impact_analysis
    
    def _assess_impact_severity(self, criticality):
        """è¯„ä¼°å½±å“ä¸¥é‡ç¨‹åº¦"""
        severity_mapping = {
            'critical': 'severe',
            'high': 'high',
            'medium': 'moderate',
            'low': 'low'
        }
        return severity_mapping[criticality]
    
    def _find_cascading_impacts(self, affected_systems):
        """æŸ¥æ‰¾çº§è”å½±å“"""
        cascading = set()
        for function, deps in self.dependencies.items():
            if any(dep in affected_systems for dep in deps):
                cascading.add(function)
        return list(cascading)
    
    def _get_function_criticality(self, function_name):
        """è·å–åŠŸèƒ½é‡è¦æ€§"""
        for func in self.business_functions:
            if func['name'] == function_name:
                return func['criticality']
        return 'low'
    
    def _calculate_financial_impact(self, impacts, duration_hours):
        """è®¡ç®—è´¢åŠ¡å½±å“"""
        hourly_costs = {
            'severe': 100000,  # æ¯å°æ—¶æŸå¤±
            'high': 50000,
            'moderate': 10000,
            'low': 1000
        }
        
        total_cost = 0
        cost_breakdown = {}
        
        for impact in impacts:
            severity = impact['impact_severity']
            cost = hourly_costs[severity] * duration_hours
            total_cost += cost
            cost_breakdown[impact['function']] = cost
        
        return {
            'total_cost': total_cost,
            'cost_breakdown': cost_breakdown,
            'cost_per_hour': total_cost / duration_hours if duration_hours > 0 else 0
        }
    
    def _prioritize_recovery(self, impacts):
        """ç¡®å®šæ¢å¤ä¼˜å…ˆçº§"""
        priority_mapping = {
            'severe': 1,
            'high': 2,
            'moderate': 3,
            'low': 4
        }
        
        return sorted(impacts, key=lambda x: priority_mapping[x['impact_severity']])

# ä½¿ç”¨ç¤ºä¾‹
bia = BusinessImpactAnalyzer()

# å®šä¹‰ä¸šåŠ¡åŠŸèƒ½åŠå…¶ä¾èµ–å…³ç³»
bia.add_business_function('è®¢å•å¤„ç†', 'critical', ['æ”¯ä»˜ç³»ç»Ÿ', 'åº“å­˜ç®¡ç†'])
bia.add_business_function('æ”¯ä»˜ç³»ç»Ÿ', 'critical', ['é“¶è¡Œæ¥å£'])
bia.add_business_function('åº“å­˜ç®¡ç†', 'high', ['ä¾›åº”å•†ç³»ç»Ÿ'])
bia.add_business_function('å®¢æˆ·æœåŠ¡', 'medium', ['CRMç³»ç»Ÿ'])
bia.add_business_function('æŠ¥è¡¨ç³»ç»Ÿ', 'low', ['æ•°æ®ä»“åº“'])

# åˆ†ææ•°æ®ä¸­å¿ƒç«ç¾åœºæ™¯
fire_scenario = {
    'affected_systems': ['è®¢å•å¤„ç†', 'æ”¯ä»˜ç³»ç»Ÿ'],
    'duration_hours': 4
}

impact_result = bia.analyze_impact(fire_scenario)
print("å½±å“åˆ†æç»“æœ:")
print(f"ç›´æ¥å†²å‡»: {[i['function'] for i in impact_result['immediate_impact']]}")
print(f"çº§è”å†²å‡»: {[i['function'] for i in impact_result['cascading_impact']]}")
print(f"æ€»è´¢åŠ¡æŸå¤±: ${impact_result['financial_impact']['total_cost']:,}")
```

### 2.2 å®¹ç¾ç­–ç•¥çŸ©é˜µ

#### DRç­–ç•¥å†³ç­–çŸ©é˜µ
```python
# å®¹ç¾ç­–ç•¥å†³ç­–çŸ©é˜µ
class DRStrategyMatrix:
    def __init__(self):
        self.strategies = {
            'backup_restore': {
                'rto_range': '24-72å°æ—¶',
                'rpo_range': '1å°æ—¶-1å¤©',
                'cost_level': 'ä½',
                'complexity': 'ç®€å•',
                'suitable_for': ['å½’æ¡£æ•°æ®', 'éå…³é”®ç³»ç»Ÿ', 'åˆè§„è¦æ±‚']
            },
            
            'pilot_light': {
                'rto_range': '4-24å°æ—¶',
                'rpo_range': 'å‡ åˆ†é’Ÿ-1å°æ—¶',
                'cost_level': 'ä¸­ç­‰',
                'complexity': 'ä¸­ç­‰',
                'suitable_for': ['é‡è¦ä¸šåŠ¡ç³»ç»Ÿ', 'ä¸­ç­‰RTOè¦æ±‚']
            },
            
            'warm_standby': {
                'rto_range': '1-4å°æ—¶',
                'rpo_range': 'å‡ åˆ†é’Ÿ',
                'cost_level': 'è¾ƒé«˜',
                'complexity': 'å¤æ‚',
                'suitable_for': ['å…³é”®ä¸šåŠ¡ç³»ç»Ÿ', 'é‡‘èæœåŠ¡']
            },
            
            'multi_site_active': {
                'rto_range': '0-30åˆ†é’Ÿ',
                'rpo_range': 'æ¥è¿‘é›¶',
                'cost_level': 'æœ€é«˜',
                'complexity': 'éå¸¸å¤æ‚',
                'suitable_for': ['æ ¸å¿ƒä¸šåŠ¡', 'é›¶å®¹å¿åœæœº']
            }
        }
    
    def recommend_strategy(self, requirements):
        """æ¨èå®¹ç¾ç­–ç•¥"""
        scores = {}
        
        for strategy_name, strategy_info in self.strategies.items():
            score = self._calculate_strategy_score(strategy_name, requirements)
            scores[strategy_name] = score
        
        best_strategy = max(scores, key=scores.get)
        
        return {
            'recommended': best_strategy,
            'score': scores[best_strategy],
            'details': self.strategies[best_strategy],
            'ranking': sorted(scores.items(), key=lambda x: x[1], reverse=True)
        }
    
    def _calculate_strategy_score(self, strategy_name, requirements):
        """è®¡ç®—ç­–ç•¥å¾—åˆ†"""
        strategy = self.strategies[strategy_name]
        score = 0
        
        # RTOåŒ¹é…åº¦ (40åˆ†)
        required_rto = requirements.get('max_rto_hours', 24)
        strategy_rto_max = self._parse_time_range_max(strategy['rto_range'])
        if required_rto >= strategy_rto_max:
            score += 40
        
        # RPOåŒ¹é…åº¦ (30åˆ†)
        required_rpo = requirements.get('max_rpo_minutes', 60)
        strategy_rpo_max = self._parse_time_range_max(strategy['rpo_range'], unit='minutes')
        if required_rpo >= strategy_rpo_max:
            score += 30
        
        # æˆæœ¬è€ƒè™‘ (20åˆ†)
        budget_level = requirements.get('budget_level', 'medium')
        cost_levels = {'low': 1, 'medium': 2, 'high': 3, 'highest': 4}
        if cost_levels[budget_level] >= cost_levels[strategy['cost_level']]:
            score += 20
        
        # å¤æ‚åº¦å®¹å¿åº¦ (10åˆ†)
        complexity_tolerance = requirements.get('complexity_tolerance', 'medium')
        complexity_levels = {'simple': 1, 'medium': 2, 'complex': 3, 'very_complex': 4}
        if complexity_levels[complexity_tolerance] >= complexity_levels[strategy['complexity']]:
            score += 10
        
        return score
    
    def _parse_time_range_max(self, time_range, unit='hours'):
        """è§£ææ—¶é—´èŒƒå›´æœ€å¤§å€¼"""
        import re
        numbers = re.findall(r'\d+', time_range)
        if not numbers:
            return 24  # é»˜è®¤å€¼
        
        max_value = max(int(n) for n in numbers)
        
        if unit == 'minutes' and 'å°æ—¶' in time_range:
            max_value *= 60
        elif unit == 'hours' and 'åˆ†é’Ÿ' in time_range:
            max_value /= 60
        
        return max_value

# ä½¿ç”¨ç¤ºä¾‹
dr_matrix = DRStrategyMatrix()

requirements = {
    'max_rto_hours': 2,
    'max_rpo_minutes': 15,
    'budget_level': 'high',
    'complexity_tolerance': 'complex'
}

recommendation = dr_matrix.recommend_strategy(requirements)
print(f"æ¨èç­–ç•¥: {recommendation['recommended']}")
print(f"ç­–ç•¥è¯¦æƒ…: {recommendation['details']}")
print(f"å¾—åˆ†æ’å: {recommendation['ranking']}")
```

## 3. å¤šåœ°åŸŸéƒ¨ç½²æ¶æ„

### 3.1 åœ°åŸŸé€‰æ‹©ç­–ç•¥

#### åœ°åŸŸè·ç¦»è®¡ç®—å™¨
```python
# åœ°åŸŸè·ç¦»å’Œé£é™©è¯„ä¼°
import math
from datetime import datetime

class GeographicRiskAssessor:
    def __init__(self):
        self.disaster_zones = {
            'åœ°éœ‡å¸¦': [(35.6762, 139.6503), (34.0522, -118.2437)],  # ä¸œäº¬ã€æ´›æ‰çŸ¶
            'é£“é£åŒº': [(25.7617, -80.1918), (29.7604, -95.3698)],   # è¿ˆé˜¿å¯†ã€ä¼‘æ–¯é¡¿
            'æ´ªæ°´åŒº': [(40.7128, -74.0060), (32.7157, -117.1611)],  # çº½çº¦ã€åœ£åœ°äºšå“¥
            'ç«å±±å¸¦': [(19.4326, -99.1332), (-6.2088, 106.8456)]    # å¢¨è¥¿å“¥åŸã€é›…åŠ è¾¾
        }
    
    def calculate_distance(self, lat1, lon1, lat2, lon2):
        """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»ï¼ˆå…¬é‡Œï¼‰"""
        R = 6371  # åœ°çƒåŠå¾„ï¼ˆå…¬é‡Œï¼‰
        
        lat1_rad = math.radians(lat1)
        lat2_rad = math.radians(lat2)
        delta_lat = math.radians(lat2 - lat1)
        delta_lon = math.radians(lon2 - lon1)
        
        a = (math.sin(delta_lat/2) ** 2 + 
             math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon/2) ** 2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c
    
    def assess_geographic_risk(self, primary_location, backup_location):
        """è¯„ä¼°åœ°ç†é£é™©"""
        lat1, lon1 = primary_location
        lat2, lon2 = backup_location
        
        distance = self.calculate_distance(lat1, lon1, lat2, lon2)
        
        risk_assessment = {
            'distance_km': round(distance, 2),
            'disaster_zone_risks': {},
            'risk_level': 'low',
            'recommendation': ''
        }
        
        # æ£€æŸ¥å„ç§ç¾å®³é£é™©
        for disaster_type, zones in self.disaster_zones.items():
            min_distance_to_zone = float('inf')
            
            for zone_lat, zone_lon in zones:
                zone_distance = self.calculate_distance(lat1, lon1, zone_lat, zone_lon)
                min_distance_to_zone = min(min_distance_to_zone, zone_distance)
            
            risk_assessment['disaster_zone_risks'][disaster_type] = {
                'distance_to_nearest_zone': round(min_distance_to_zone, 2),
                'risk_category': self._categorize_risk(min_distance_to_zone)
            }
        
        # ç»¼åˆé£é™©è¯„ä¼°
        risk_assessment['risk_level'] = self._calculate_overall_risk(risk_assessment)
        risk_assessment['recommendation'] = self._generate_recommendation(risk_assessment)
        
        return risk_assessment
    
    def _categorize_risk(self, distance_km):
        """é£é™©åˆ†ç±»"""
        if distance_km < 100:
            return 'high'
        elif distance_km < 500:
            return 'medium'
        else:
            return 'low'
    
    def _calculate_overall_risk(self, assessment):
        """è®¡ç®—ç»¼åˆé£é™©ç­‰çº§"""
        high_risks = sum(1 for risk in assessment['disaster_zone_risks'].values() 
                        if risk['risk_category'] == 'high')
        
        if high_risks >= 2:
            return 'high'
        elif high_risks >= 1:
            return 'medium'
        else:
            return 'low'
    
    def _generate_recommendation(self, assessment):
        """ç”Ÿæˆå»ºè®®"""
        if assessment['risk_level'] == 'high':
            return f"è·ç¦»å¤ªè¿‘({assessment['distance_km']}km)ï¼Œå»ºè®®é€‰æ‹©æ›´è¿œçš„åœ°ç†ä½ç½®"
        elif assessment['distance_km'] < 300:
            return f"è·ç¦»é€‚ä¸­({assessment['distance_km']}km)ï¼Œä½†éœ€è€ƒè™‘å…·ä½“ç¾å®³é£é™©"
        else:
            return f"è·ç¦»è‰¯å¥½({assessment['distance_km']}km)ï¼Œåœ°ç†éš”ç¦»æ•ˆæœä½³"

# ä½¿ç”¨ç¤ºä¾‹
assessor = GeographicRiskAssessor()

# åŒ—äº¬æ•°æ®ä¸­å¿ƒé€‰å€è¯„ä¼°
beijing_coords = (39.9042, 116.4074)
shanghai_coords = (31.2304, 121.4737)
guangzhou_coords = (23.1291, 113.2644)

# è¯„ä¼°åŒ—äº¬-ä¸Šæµ·çš„å®¹ç¾è·ç¦»
risk_assessment = assessor.assess_geographic_risk(beijing_coords, shanghai_coords)
print(f"åŒ—äº¬-ä¸Šæµ·é£é™©è¯„ä¼°: {risk_assessment}")

# è¯„ä¼°åŒ—äº¬-å¹¿å·çš„å®¹ç¾è·ç¦»
risk_assessment2 = assessor.assess_geographic_risk(beijing_coords, guangzhou_coords)
print(f"åŒ—äº¬-å¹¿å·é£é™©è¯„ä¼°: {risk_assessment2}")
```

### 3.2 ç½‘ç»œæ¶æ„è®¾è®¡

#### å¤šåœ°åŸŸç½‘ç»œæ‹“æ‰‘
```python
# å¤šåœ°åŸŸç½‘ç»œæ¶æ„è®¾è®¡
class MultiRegionNetworkDesigner:
    def __init__(self):
        self.regions = {}
        self.network_links = []
    
    def add_region(self, region_name, coordinates, network_specs):
        """æ·»åŠ åœ°åŸŸ"""
        self.regions[region_name] = {
            'coordinates': coordinates,
            'specs': network_specs,
            'connected_regions': []
        }
    
    def design_network_topology(self, primary_region, backup_regions, requirements):
        """è®¾è®¡ç½‘ç»œæ‹“æ‰‘"""
        topology = {
            'primary_region': primary_region,
            'backup_regions': backup_regions,
            'links': [],
            'bandwidth_allocation': {},
            'latency_matrix': {}
        }
        
        # è®¾è®¡ä¸»å¤‡è¿æ¥
        for backup_region in backup_regions:
            link_spec = self._design_link(primary_region, backup_region, requirements)
            topology['links'].append(link_spec)
            self.regions[primary_region]['connected_regions'].append(backup_region)
        
        # è®¾è®¡å¤‡å¤‡è¿æ¥ï¼ˆå¯é€‰ï¼‰
        if requirements.get('inter_backup_connectivity', False):
            for i, region1 in enumerate(backup_regions):
                for region2 in backup_regions[i+1:]:
                    link_spec = self._design_link(region1, region2, requirements)
                    topology['links'].append(link_spec)
                    self.regions[region1]['connected_regions'].append(region2)
                    self.regions[region2]['connected_regions'].append(region1)
        
        # è®¡ç®—å¸¦å®½åˆ†é…
        topology['bandwidth_allocation'] = self._calculate_bandwidth_allocation(topology)
        
        # è®¡ç®—å»¶è¿ŸçŸ©é˜µ
        topology['latency_matrix'] = self._calculate_latency_matrix()
        
        return topology
    
    def _design_link(self, region1, region2, requirements):
        """è®¾è®¡åœ°åŸŸé—´è¿æ¥"""
        coords1 = self.regions[region1]['coordinates']
        coords2 = self.regions[region2]['coordinates']
        
        distance = self._calculate_distance(coords1, coords2)
        latency = self._estimate_latency(distance)
        
        # æ ¹æ®è¦æ±‚ç¡®å®šé“¾è·¯è§„æ ¼
        bandwidth = requirements.get('minimum_bandwidth_gbps', 1)
        redundancy = requirements.get('link_redundancy', 2)  # é»˜è®¤åŒé“¾è·¯
        
        return {
            'source': region1,
            'destination': region2,
            'distance_km': round(distance, 2),
            'latency_ms': round(latency, 2),
            'bandwidth_gbps': bandwidth,
            'redundancy': redundancy,
            'technology': self._select_technology(distance),
            'cost_estimate': self._estimate_cost(distance, bandwidth, redundancy)
        }
    
    def _calculate_distance(self, coords1, coords2):
        """è®¡ç®—åœ°ç†è·ç¦»"""
        lat1, lon1 = coords1
        lat2, lon2 = coords2
        
        R = 6371  # åœ°çƒåŠå¾„å…¬é‡Œ
        lat1_rad = math.radians(lat1)
        lat2_rad = math.radians(lat2)
        delta_lat = math.radians(lat2 - lat1)
        delta_lon = math.radians(lon2 - lon1)
        
        a = (math.sin(delta_lat/2) ** 2 + 
             math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon/2) ** 2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c
    
    def _estimate_latency(self, distance_km):
        """ä¼°ç®—ç½‘ç»œå»¶è¿Ÿ"""
        # å…‰çº¤é€Ÿåº¦çº¦200,000 km/sï¼Œè€ƒè™‘è·¯ç”±å¼€é”€ä¹˜ä»¥1.5
        speed_of_light_factor = 1.5
        return (distance_km / 200000) * 1000 * speed_of_light_factor
    
    def _select_technology(self, distance):
        """é€‰æ‹©ä¼ è¾“æŠ€æœ¯"""
        if distance < 500:
            return 'ä¸“çº¿ç›´è¿'
        elif distance < 2000:
            return 'MPLS VPN'
        else:
            return 'SD-WAN + å…¬ç½‘åŠ å¯†'
    
    def _estimate_cost(self, distance, bandwidth, redundancy):
        """ä¼°ç®—æˆæœ¬"""
        base_cost_per_km = 100  # æ¯å…¬é‡ŒåŸºç¡€è´¹ç”¨
        bandwidth_cost_per_gbps = 5000  # æ¯Gbpsæœˆè´¹
        
        distance_cost = distance * base_cost_per_km * redundancy
        bandwidth_cost = bandwidth * bandwidth_cost_per_gbps * redundancy
        
        return {
            'setup_cost': distance_cost,
            'monthly_cost': bandwidth_cost,
            'annual_cost': bandwidth_cost * 12
        }
    
    def _calculate_bandwidth_allocation(self, topology):
        """è®¡ç®—å¸¦å®½åˆ†é…"""
        allocation = {}
        
        # ä¸»å¤‡é“¾è·¯å¸¦å®½åˆ†é…
        for link in topology['links']:
            source = link['source']
            dest = link['destination']
            
            if source not in allocation:
                allocation[source] = {}
            allocation[source][dest] = {
                'allocated_bandwidth': link['bandwidth_gbps'],
                'utilization_target': 0.7,  # ç›®æ ‡åˆ©ç”¨ç‡70%
                'peak_utilization': 0.9    # å³°å€¼åˆ©ç”¨ç‡90%
            }
        
        return allocation
    
    def _calculate_latency_matrix(self):
        """è®¡ç®—å»¶è¿ŸçŸ©é˜µ"""
        matrix = {}
        
        for region1 in self.regions:
            matrix[region1] = {}
            coords1 = self.regions[region1]['coordinates']
            
            for region2 in self.regions:
                if region1 == region2:
                    matrix[region1][region2] = 0
                else:
                    coords2 = self.regions[region2]['coordinates']
                    distance = self._calculate_distance(coords1, coords2)
                    latency = self._estimate_latency(distance)
                    matrix[region1][region2] = round(latency, 2)
        
        return matrix

# ä½¿ç”¨ç¤ºä¾‹
network_designer = MultiRegionNetworkDesigner()

# æ·»åŠ åœ°åŸŸä¿¡æ¯
network_designer.add_region('åŒ—äº¬', (39.9042, 116.4074), {'capacity': 'large'})
network_designer.add_region('ä¸Šæµ·', (31.2304, 121.4737), {'capacity': 'medium'})
network_designer.add_region('å¹¿å·', (23.1291, 113.2644), {'capacity': 'medium'})
network_designer.add_region('è¥¿å®‰', (34.3416, 108.9398), {'capacity': 'small'})

# è®¾è®¡ç½‘ç»œæ‹“æ‰‘
requirements = {
    'minimum_bandwidth_gbps': 10,
    'link_redundancy': 2,
    'inter_backup_connectivity': True
}

topology = network_designer.design_network_topology('åŒ—äº¬', ['ä¸Šæµ·', 'å¹¿å·', 'è¥¿å®‰'], requirements)

print("ç½‘ç»œæ‹“æ‰‘è®¾è®¡:")
for link in topology['links']:
    print(f"{link['source']} -> {link['destination']}: "
          f"{link['bandwidth_gbps']}Gbps, {link['latency_ms']}mså»¶è¿Ÿ")
```

## 4. æ•°æ®åŒæ­¥ä¸å¤åˆ¶

### 4.1 å¼‚åœ°æ•°æ®åŒæ­¥ç­–ç•¥

#### æ•°æ®åŒæ­¥æ–¹æ¡ˆå¯¹æ¯”
```python
# æ•°æ®åŒæ­¥æ–¹æ¡ˆè¯„ä¼°
class DataSyncStrategies:
    def __init__(self):
        self.strategies = {
            'log_shipping': {
                'description': 'æ—¥å¿—ä¼ é€',
                'sync_method': 'å¼‚æ­¥',
                'rpo': 'åˆ†é’Ÿåˆ°å°æ—¶çº§',
                'network_bandwidth': 'ä½',
                'implementation_complexity': 'ä¸­ç­‰',
                'recovery_time': 'è¾ƒé•¿'
            },
            
            'real_time_replication': {
                'description': 'å®æ—¶å¤åˆ¶',
                'sync_method': 'åŒæ­¥/åŠåŒæ­¥',
                'rpo': 'ç§’çº§',
                'network_bandwidth': 'é«˜',
                'implementation_complexity': 'å¤æ‚',
                'recovery_time': 'è¾ƒçŸ­'
            },
            
            'block_level_sync': {
                'description': 'å—çº§åˆ«åŒæ­¥',
                'sync_method': 'åŒæ­¥',
                'rpo': 'æ¥è¿‘é›¶',
                'network_bandwidth': 'å¾ˆé«˜',
                'implementation_complexity': 'å¾ˆå¤æ‚',
                'recovery_time': 'æœ€çŸ­'
            },
            
            'file_level_sync': {
                'description': 'æ–‡ä»¶çº§åˆ«åŒæ­¥',
                'sync_method': 'å¼‚æ­¥',
                'rpo': 'åˆ†é’Ÿçº§',
                'network_bandwidth': 'ä¸­ç­‰',
                'implementation_complexity': 'ç®€å•',
                'recovery_time': 'ä¸­ç­‰'
            }
        }
    
    def evaluate_sync_strategy(self, requirements):
        """è¯„ä¼°åŒæ­¥ç­–ç•¥"""
        scores = {}
        
        for strategy_name, strategy_info in self.strategies.items():
            score = self._calculate_strategy_score(strategy_name, requirements)
            scores[strategy_name] = score
        
        best_strategy = max(scores, key=scores.get)
        
        return {
            'recommended': best_strategy,
            'score': scores[best_strategy],
            'details': self.strategies[best_strategy],
            'comparison': self._generate_comparison_matrix(scores)
        }
    
    def _calculate_strategy_score(self, strategy_name, requirements):
        """è®¡ç®—ç­–ç•¥å¾—åˆ†"""
        strategy = self.strategies[strategy_name]
        score = 0
        
        # RPOè¦æ±‚åŒ¹é… (30åˆ†)
        required_rpo = requirements.get('max_rpo_seconds', 300)
        strategy_rpo = self._parse_rpo(strategy['rpo'])
        if required_rpo >= strategy_rpo:
            score += 30
        
        # ç½‘ç»œå¸¦å®½è€ƒè™‘ (25åˆ†)
        available_bandwidth = requirements.get('available_bandwidth_gbps', 1)
        bandwidth_requirement = self._get_bandwidth_requirement(strategy['network_bandwidth'])
        if available_bandwidth >= bandwidth_requirement:
            score += 25
        
        # å®æ–½å¤æ‚åº¦å®¹å¿åº¦ (20åˆ†)
        complexity_tolerance = requirements.get('complexity_tolerance', 'medium')
        complexity_levels = {'simple': 1, 'medium': 2, 'complex': 3, 'very_complex': 4}
        strategy_complexity = complexity_levels[strategy['implementation_complexity']]
        if complexity_levels[complexity_tolerance] >= strategy_complexity:
            score += 20
        
        # æ¢å¤æ—¶é—´è¦æ±‚ (15åˆ†)
        max_recovery_hours = requirements.get('max_recovery_hours', 4)
        recovery_time_rating = self._rate_recovery_time(strategy['recovery_time'])
        if max_recovery_hours >= recovery_time_rating:
            score += 15
        
        # æˆæœ¬è€ƒè™‘ (10åˆ†)
        budget_level = requirements.get('budget_level', 'medium')
        cost_levels = {'low': 1, 'medium': 2, 'high': 3, 'highest': 4}
        # å‡è®¾å¸¦å®½è¦æ±‚é«˜çš„æ–¹æ¡ˆæˆæœ¬ä¹Ÿé«˜
        if cost_levels[budget_level] >= bandwidth_requirement:
            score += 10
        
        return score
    
    def _parse_rpo(self, rpo_string):
        """è§£æRPOæ—¶é—´"""
        import re
        numbers = re.findall(r'\d+', rpo_string)
        if not numbers:
            return 3600  # é»˜è®¤1å°æ—¶
        
        value = int(numbers[0])
        if 'ç§’' in rpo_string:
            return value
        elif 'åˆ†é’Ÿ' in rpo_string:
            return value * 60
        else:
            return value * 3600  # å°æ—¶
    
    def _get_bandwidth_requirement(self, bandwidth_level):
        """è·å–å¸¦å®½è¦æ±‚"""
        bandwidth_mapping = {
            'å¾ˆä½': 0.1,
            'ä½': 0.5,
            'ä¸­ç­‰': 2,
            'é«˜': 5,
            'å¾ˆé«˜': 10
        }
        return bandwidth_mapping.get(bandwidth_level, 2)
    
    def _rate_recovery_time(self, time_description):
        """è¯„çº§æ¢å¤æ—¶é—´"""
        time_mapping = {
            'æœ€çŸ­': 0.5,
            'è¾ƒçŸ­': 2,
            'ä¸­ç­‰': 4,
            'è¾ƒé•¿': 12
        }
        return time_mapping.get(time_description, 4)
    
    def _generate_comparison_matrix(self, scores):
        """ç”Ÿæˆå¯¹æ¯”çŸ©é˜µ"""
        matrix = []
        for strategy, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):
            matrix.append({
                'strategy': strategy,
                'score': score,
                'details': self.strategies[strategy]
            })
        return matrix

# ä½¿ç”¨ç¤ºä¾‹
sync_strategies = DataSyncStrategies()

requirements = {
    'max_rpo_seconds': 60,
    'available_bandwidth_gbps': 5,
    'complexity_tolerance': 'complex',
    'max_recovery_hours': 2,
    'budget_level': 'high'
}

evaluation = sync_strategies.evaluate_sync_strategy(requirements)
print(f"æ¨èåŒæ­¥ç­–ç•¥: {evaluation['recommended']}")
print("ç­–ç•¥å¯¹æ¯”:")
for item in evaluation['comparison']:
    print(f"- {item['strategy']}: {item['score']}åˆ†")
```

### 4.2 æ•°æ®ä¸€è‡´æ€§ä¿éšœ

#### åˆ†å¸ƒå¼ä¸€è‡´æ€§åè®®
```python
# åˆ†å¸ƒå¼ä¸€è‡´æ€§ä¿éšœæœºåˆ¶
import time
import hashlib
from typing import Dict, List, Any

class DataConsistencyManager:
    def __init__(self, regions: List[str]):
        self.regions = regions
        self.consistency_tokens = {}  # region -> {token: timestamp}
        self.data_checksums = {}      # region -> {table: checksum}
        self.sync_sequences = {}      # region -> sequence_number
    
    def generate_consistency_token(self, region: str, data_snapshot: Dict) -> str:
        """ç”Ÿæˆä¸€è‡´æ€§ä»¤ç‰Œ"""
        timestamp = int(time.time() * 1000)  # æ¯«ç§’çº§æ—¶é—´æˆ³
        data_hash = self._calculate_data_hash(data_snapshot)
        
        token = f"{region}_{timestamp}_{data_hash}"
        
        if region not in self.consistency_tokens:
            self.consistency_tokens[region] = {}
        
        self.consistency_tokens[region][token] = timestamp
        return token
    
    def verify_consistency(self, tokens: Dict[str, str]) -> Dict[str, Any]:
        """éªŒè¯è·¨åœ°åŸŸä¸€è‡´æ€§"""
        results = {
            'consistent': True,
            'inconsistent_regions': [],
            'timestamp_drift': {},
            'verification_time': time.time()
        }
        
        if len(tokens) < 2:
            results['consistent'] = False
            results['error'] = 'è‡³å°‘éœ€è¦ä¸¤ä¸ªåœ°åŸŸè¿›è¡Œä¸€è‡´æ€§éªŒè¯'
            return results
        
        # æå–æ—¶é—´æˆ³å¹¶æ£€æŸ¥æ¼‚ç§»
        timestamps = {}
        for region, token in tokens.items():
            if '_' in token:
                parts = token.split('_')
                if len(parts) >= 2:
                    try:
                        timestamp = int(parts[1])
                        timestamps[region] = timestamp
                    except ValueError:
                        results['inconsistent_regions'].append(region)
        
        # æ£€æŸ¥æ—¶é—´æˆ³æ¼‚ç§»
        if len(timestamps) > 1:
            max_ts = max(timestamps.values())
            min_ts = min(timestamps.values())
            drift_ms = max_ts - min_ts
            
            results['timestamp_drift'] = {
                'max_drift_ms': drift_ms,
                'within_tolerance': drift_ms <= 1000  # 1ç§’å®¹å¿åº¦
            }
            
            if drift_ms > 1000:
                results['consistent'] = False
        
        # éªŒè¯æ•°æ®å“ˆå¸Œä¸€è‡´æ€§
        data_hashes = {}
        for region, token in tokens.items():
            if '_' in token:
                parts = token.split('_')
                if len(parts) >= 3:
                    data_hashes[region] = parts[2]
        
        if len(set(data_hashes.values())) > 1:
            results['consistent'] = False
            results['inconsistent_regions'] = list(data_hashes.keys())
            results['hash_mismatch'] = data_hashes
        
        return results
    
    def calculate_data_checksum(self, region: str, table_name: str, data: List[Dict]) -> str:
        """è®¡ç®—æ•°æ®æ ¡éªŒå’Œ"""
        if region not in self.data_checksums:
            self.data_checksums[region] = {}
        
        # å¯¹æ•°æ®è¿›è¡Œæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
        sorted_data = sorted(data, key=lambda x: str(x))
        
        # è®¡ç®—MD5æ ¡éªŒå’Œ
        data_str = str(sorted_data)
        checksum = hashlib.md5(data_str.encode()).hexdigest()
        
        self.data_checksums[region][table_name] = checksum
        return checksum
    
    def verify_data_integrity(self, region_data_map: Dict[str, Dict[str, List[Dict]]]) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        results = {
            'integrity_verified': True,
            'checksum_mismatches': {},
            'verified_tables': []
        }
        
        # è®¡ç®—æ‰€æœ‰åœ°åŸŸçš„æ ¡éªŒå’Œ
        checksums = {}
        for region, tables_data in region_data_map.items():
            checksums[region] = {}
            for table_name, table_data in tables_data.items():
                checksum = self.calculate_data_checksum(region, table_name, table_data)
                checksums[region][table_name] = checksum
        
        # æ¯”è¾ƒä¸åŒåœ°åŸŸé—´çš„æ ¡éªŒå’Œ
        if len(checksums) < 2:
            results['integrity_verified'] = False
            results['error'] = 'è‡³å°‘éœ€è¦ä¸¤ä¸ªåœ°åŸŸè¿›è¡Œå®Œæ•´æ€§éªŒè¯'
            return results
        
        # é€‰æ‹©ä¸€ä¸ªå‚è€ƒåœ°åŸŸ
        reference_region = list(checksums.keys())[0]
        reference_checksums = checksums[reference_region]
        
        for table_name in reference_checksums:
            reference_checksum = reference_checksums[table_name]
            results['verified_tables'].append(table_name)
            
            # æ£€æŸ¥å…¶ä»–åœ°åŸŸ
            for region in checksums:
                if region != reference_region:
                    region_checksum = checksums[region].get(table_name)
                    if region_checksum and region_checksum != reference_checksum:
                        if table_name not in results['checksum_mismatches']:
                            results['checksum_mismatches'][table_name] = {}
                        results['checksum_mismatches'][table_name][region] = region_checksum
                        results['integrity_verified'] = False
        
        return results
    
    def assign_sequence_number(self, region: str) -> int:
        """åˆ†é…åºåˆ—å·ç”¨äºé¡ºåºä¿è¯"""
        if region not in self.sync_sequences:
            self.sync_sequences[region] = 0
        
        self.sync_sequences[region] += 1
        return self.sync_sequences[region]
    
    def validate_sequence_order(self, region_sequences: Dict[str, int]) -> Dict[str, Any]:
        """éªŒè¯åºåˆ—å·é¡ºåº"""
        results = {
            'sequences_valid': True,
            'sequence_gaps': {},
            'latest_sequences': region_sequences
        }
        
        if len(region_sequences) < 2:
            return results
        
        # æ£€æŸ¥åºåˆ—å·å·®è·
        sequences = list(region_sequences.values())
        max_seq = max(sequences)
        min_seq = min(sequences)
        
        if max_seq - min_seq > 10:  # å…è®¸æœ€å¤§10ä¸ªåºåˆ—å·å·®è·
            results['sequences_valid'] = False
            results['sequence_gaps'] = {
                'max_difference': max_seq - min_seq,
                'regions': region_sequences
            }
        
        return results
    
    def _calculate_data_hash(self, data: Dict) -> str:
        """è®¡ç®—æ•°æ®å“ˆå¸Œ"""
        # å¯¹å­—å…¸æŒ‰é”®æ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
        sorted_items = sorted(data.items())
        data_string = str(sorted_items)
        return hashlib.md5(data_string.encode()).hexdigest()

# ä½¿ç”¨ç¤ºä¾‹
consistency_manager = DataConsistencyManager(['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·'])

# æ¨¡æ‹Ÿæ•°æ®åŒæ­¥åœºæ™¯
data_snapshot = {
    'users': [{'id': 1, 'name': 'å¼ ä¸‰'}, {'id': 2, 'name': 'æå››'}],
    'orders': [{'id': 101, 'user_id': 1, 'amount': 100}]
}

# ç”Ÿæˆå„åœ°åŸŸçš„ä¸€è‡´æ€§ä»¤ç‰Œ
tokens = {}
for region in ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·']:
    token = consistency_manager.generate_consistency_token(region, data_snapshot)
    tokens[region] = token
    print(f"{region} ä»¤ç‰Œ: {token}")

# éªŒè¯ä¸€è‡´æ€§
consistency_result = consistency_manager.verify_consistency(tokens)
print(f"ä¸€è‡´æ€§éªŒè¯ç»“æœ: {consistency_result}")

# éªŒè¯æ•°æ®å®Œæ•´æ€§
region_data = {
    'åŒ—äº¬': data_snapshot,
    'ä¸Šæµ·': data_snapshot,
    'å¹¿å·': data_snapshot  # å‡è®¾å¹¿å·çš„æ•°æ®ç•¥æœ‰ä¸åŒ
}

# ä¿®æ”¹å¹¿å·çš„æ•°æ®æ¥æ¨¡æ‹Ÿä¸ä¸€è‡´
guangzhou_data = {
    'users': [{'id': 1, 'name': 'å¼ ä¸‰'}, {'id': 2, 'name': 'ç‹äº”'}],  # æå››æ”¹ä¸ºç‹äº”
    'orders': data_snapshot['orders']
}

region_data['å¹¿å·'] = guangzhou_data

integrity_result = consistency_manager.verify_data_integrity(region_data)
print(f"æ•°æ®å®Œæ•´æ€§éªŒè¯: {integrity_result}")
```

## 5. å®¹ç¾æ¼”ç»ƒä¸æµ‹è¯•

### 5.1 æ¼”ç»ƒè®¡åˆ’åˆ¶å®š

#### å®¹ç¾æ¼”ç»ƒè§„åˆ’å·¥å…·
```python
# å®¹ç¾æ¼”ç»ƒè§„åˆ’ç³»ç»Ÿ
from datetime import datetime, timedelta
from enum import Enum
import random

class DrillType(Enum):
    TABLETOP = "æ¡Œé¢æ¼”ç»ƒ"
    FUNCTIONAL = "åŠŸèƒ½æ€§æ¼”ç»ƒ"
    FULL_INTERUPTION = "å®Œå…¨ä¸­æ–­æ¼”ç»ƒ"
    APPLICATION_LEVEL = "åº”ç”¨çº§æ¼”ç»ƒ"

class DrillPlanner:
    def __init__(self):
        self.drills_history = []
        self.upcoming_drills = []
        self.risk_assessments = []
    
    def plan_annual_drill_schedule(self, business_calendar, system_inventory):
        """åˆ¶å®šå¹´åº¦æ¼”ç»ƒè®¡åˆ’"""
        schedule = {
            'year': datetime.now().year,
            'drills': [],
            'quarterly_goals': {},
            'resource_allocation': {}
        }
        
        # ç¡®å®šæ¼”ç»ƒé¢‘ç‡
        drill_frequency = {
            'critical_systems': 4,  # æ¯å­£åº¦ä¸€æ¬¡
            'important_systems': 2,  # æ¯åŠå¹´ä¸€æ¬¡
            'standard_systems': 1   # æ¯å¹´ä¸€æ¬¡
        }
        
        # ä¸ºæ¯ä¸ªç³»ç»Ÿå®‰æ’æ¼”ç»ƒ
        for system in system_inventory:
            system_type = system['criticality']
            frequency = drill_frequency.get(system_type, 1)
            
            system_drills = self._schedule_system_drills(
                system, frequency, business_calendar
            )
            schedule['drills'].extend(system_drills)
        
        # æŒ‰å­£åº¦ç»„ç»‡ç›®æ ‡
        schedule['quarterly_goals'] = self._organize_quarterly_goals(schedule['drills'])
        
        # èµ„æºåˆ†é…è§„åˆ’
        schedule['resource_allocation'] = self._plan_resource_allocation(schedule['drills'])
        
        return schedule
    
    def _schedule_system_drills(self, system, frequency, business_calendar):
        """ä¸ºç³»ç»Ÿå®‰æ’æ¼”ç»ƒ"""
        drills = []
        system_name = system['name']
        
        # ç¡®å®šåˆé€‚çš„æ¼”ç»ƒæœˆä»½ï¼ˆé¿å¼€ä¸šåŠ¡é«˜å³°æœŸï¼‰
        available_months = self._get_non_peak_months(business_calendar, system['business_cycle'])
        
        for i in range(frequency):
            # éšæœºé€‰æ‹©æœˆä»½
            month = random.choice(available_months)
            drill_date = self._calculate_drill_date(month, business_calendar)
            
            # ç¡®å®šæ¼”ç»ƒç±»å‹
            drill_type = self._determine_drill_type(system, i, frequency)
            
            drill = {
                'system': system_name,
                'type': drill_type,
                'scheduled_date': drill_date,
                'duration_hours': self._estimate_drill_duration(drill_type),
                'participants': self._identify_participants(system, drill_type),
                'success_criteria': self._define_success_criteria(system, drill_type),
                'rollback_plan': self._create_rollback_plan(system),
                'communication_plan': self._create_communication_plan(system, drill_date)
            }
            
            drills.append(drill)
        
        return drills
    
    def _get_non_peak_months(self, business_calendar, business_cycle):
        """è·å–éé«˜å³°æœŸæœˆä»½"""
        peak_seasons = business_calendar.get('peak_seasons', [])
        all_months = list(range(1, 13))
        
        non_peak_months = [month for month in all_months if month not in peak_seasons]
        return non_peak_months if non_peak_months else [3, 6, 9, 12]  # é»˜è®¤å­£åº¦æœ«
    
    def _calculate_drill_date(self, month, business_calendar):
        """è®¡ç®—æ¼”ç»ƒæ—¥æœŸ"""
        year = datetime.now().year
        # é€‰æ‹©æœˆä¸­çš„ä¸€å¤©ï¼Œé¿å¼€å‘¨æœ«
        target_date = datetime(year, month, 15)
        
        # å¦‚æœæ˜¯å‘¨æœ«ï¼Œè°ƒæ•´åˆ°å·¥ä½œæ—¥
        while target_date.weekday() >= 5:  # 5=Saturday, 6=Sunday
            target_date += timedelta(days=1)
        
        return target_date.strftime('%Y-%m-%d')
    
    def _determine_drill_type(self, system, drill_number, total_drills):
        """ç¡®å®šæ¼”ç»ƒç±»å‹"""
        criticality = system['criticality']
        
        if criticality == 'critical':
            # å…³é”®ç³»ç»Ÿï¼šä»æ¡Œé¢æ¼”ç»ƒå¼€å§‹ï¼Œé€æ¸å‡çº§
            if drill_number == 0:
                return DrillType.TABLETOP
            elif drill_number == 1:
                return DrillType.FUNCTIONAL
            elif drill_number == 2:
                return DrillType.APPLICATION_LEVEL
            else:
                return DrillType.FULL_INTERUPTION
        elif criticality == 'high':
            # é‡è¦ç³»ç»Ÿï¼šåŠŸèƒ½æ€§æ¼”ç»ƒå’Œåº”ç”¨çº§æ¼”ç»ƒ
            return DrillType.FUNCTIONAL if drill_number == 0 else DrillType.APPLICATION_LEVEL
        else:
            # æ ‡å‡†ç³»ç»Ÿï¼šä¸»è¦æ˜¯æ¡Œé¢æ¼”ç»ƒ
            return DrillType.TABLETOP
    
    def _estimate_drill_duration(self, drill_type):
        """ä¼°ç®—æ¼”ç»ƒæ—¶é•¿"""
        duration_map = {
            DrillType.TABLETOP: 4,
            DrillType.FUNCTIONAL: 8,
            DrillType.APPLICATION_LEVEL: 16,
            DrillType.FULL_INTERUPTION: 24
        }
        return duration_map.get(drill_type, 8)
    
    def _identify_participants(self, system, drill_type):
        """è¯†åˆ«å‚ä¸è€…"""
        base_participants = [
            f"{system['owner']}_team_lead",
            f"{system['dba_team']}_lead",
            "dr_operations_manager"
        ]
        
        if drill_type in [DrillType.FUNCTIONAL, DrillType.FULL_INTERUPTION]:
            base_participants.extend([
                "network_engineering_team",
                "security_team",
                "business_stakeholders"
            ])
        
        if drill_type == DrillType.FULL_INTERUPTION:
            base_participants.extend([
                "senior_management",
                "customer_support_team"
            ])
        
        return base_participants
    
    def _define_success_criteria(self, system, drill_type):
        """å®šä¹‰æˆåŠŸæ ‡å‡†"""
        base_criteria = [
            f"ç³»ç»Ÿ{name}åœ¨{system['rto_hours']}å°æ—¶å†…æ¢å¤æ­£å¸¸",
            f"æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡",
            f"ä¸šåŠ¡åŠŸèƒ½éªŒè¯å®Œæˆ"
        ]
        
        if drill_type == DrillType.FULL_INTERUPTION:
            additional_criteria = [
                f"ç”¨æˆ·å½±å“æ—¶é—´ä¸è¶…è¿‡{system['rto_hours']*2}å°æ—¶",
                f"å®¢æˆ·æŠ•è¯‰ç‡ä½äº1%",
                f"åª’ä½“æ›å…‰ä¸ºé›¶"
            ]
            base_criteria.extend(additional_criteria)
        
        return base_criteria
    
    def _create_rollback_plan(self, system):
        """åˆ›å»ºå›æ»šè®¡åˆ’"""
        return {
            'trigger_conditions': [
                'æ•°æ®ä¸ä¸€è‡´è¶…è¿‡é˜ˆå€¼',
                'ä¸šåŠ¡å½±å“è¶…å‡ºé¢„æœŸ',
                'å®‰å…¨äº‹ä»¶å‘ç”Ÿ'
            ],
            'rollback_steps': [
                'ç«‹å³åœæ­¢æ¼”ç»ƒ',
                'å¯åŠ¨ç´§æ€¥æ¢å¤æµç¨‹',
                'é€šçŸ¥æ‰€æœ‰ç›¸å…³æ–¹',
                'æ‰§è¡Œæ•°æ®å›æ»š',
                'æ¢å¤ç”Ÿäº§ç¯å¢ƒ'
            ],
            'emergency_contacts': system.get('emergency_contacts', [])
        }
    
    def _create_communication_plan(self, system, drill_date):
        """åˆ›å»ºæ²Ÿé€šè®¡åˆ’"""
        return {
            'pre_drill_notification': f"æ¼”ç»ƒå‰48å°æ—¶é€šçŸ¥æ‰€æœ‰ç›¸å…³äººå‘˜",
            'during_drill_updates': f"æ¯2å°æ—¶æ›´æ–°æ¼”ç»ƒçŠ¶æ€",
            'post_drill_report': f"æ¼”ç»ƒç»“æŸå24å°æ—¶å†…æäº¤æŠ¥å‘Š",
            'stakeholders': [
                'internal_teams',
                'business_users',
                'customers_(if_applicable)',
                'regulatory_bodies_(if_required)'
            ]
        }
    
    def _organize_quarterly_goals(self, drills):
        """ç»„ç»‡å­£åº¦ç›®æ ‡"""
        quarterly_goals = {}
        
        for drill in drills:
            drill_date = datetime.strptime(drill['scheduled_date'], '%Y-%m-%d')
            quarter = (drill_date.month - 1) // 3 + 1
            
            if quarter not in quarterly_goals:
                quarterly_goals[quarter] = {
                    'systems_covered': set(),
                    'drill_types': set(),
                    'total_duration_hours': 0
                }
            
            quarterly_goals[quarter]['systems_covered'].add(drill['system'])
            quarterly_goals[quarter]['drill_types'].add(drill['type'].value)
            quarterly_goals[quarter]['total_duration_hours'] += drill['duration_hours']
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        for quarter in quarterly_goals:
            quarterly_goals[quarter]['systems_covered'] = list(quarterly_goals[quarter]['systems_covered'])
            quarterly_goals[quarter]['drill_types'] = list(quarterly_goals[quarter]['drill_types'])
        
        return quarterly_goals
    
    def _plan_resource_allocation(self, drills):
        """è§„åˆ’èµ„æºåˆ†é…"""
        resource_plan = {
            'personnel': {},
            'infrastructure': {},
            'budget': {}
        }
        
        # äººå‘˜èµ„æºç»Ÿè®¡
        for drill in drills:
            for participant in drill['participants']:
                if participant not in resource_plan['personnel']:
                    resource_plan['personnel'][participant] = 0
                resource_plan['personnel'][participant] += drill['duration_hours']
        
        # åŸºç¡€è®¾æ–½éœ€æ±‚
        resource_plan['infrastructure'] = {
            'test_environments': len(set(drill['system'] for drill in drills)),
            'backup_systems': sum(1 for drill in drills if drill['type'] != DrillType.TABLETOP),
            'monitoring_tools': 'full_suite_required'
        }
        
        # é¢„ç®—ä¼°ç®—
        hourly_rate = 100  # å‡è®¾æ¯äººæ¯å°æ—¶æˆæœ¬
        total_person_hours = sum(resource_plan['personnel'].values())
        resource_plan['budget'] = {
            'personnel_cost': total_person_hours * hourly_rate,
            'infrastructure_cost': len(drills) * 5000,  # æ¯æ¬¡æ¼”ç»ƒåŸºç¡€è®¾æ–½æˆæœ¬
            'total_estimated_cost': total_person_hours * hourly_rate + len(drills) * 5000
        }
        
        return resource_plan

# ä½¿ç”¨ç¤ºä¾‹
planner = DrillPlanner()

# ä¸šåŠ¡æ—¥å†å’Œç³»ç»Ÿæ¸…å•
business_calendar = {
    'peak_seasons': [11, 12],  # åŒåä¸€ã€åŒåäºŒ
    'holidays': ['2024-01-01', '2024-10-01']
}

system_inventory = [
    {
        'name': 'æ ¸å¿ƒäº¤æ˜“ç³»ç»Ÿ',
        'criticality': 'critical',
        'owner': 'trading',
        'dba_team': 'database_admins',
        'rto_hours': 2,
        'business_cycle': 'daily'
    },
    {
        'name': 'ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ',
        'criticality': 'high',
        'owner': 'user_services',
        'dba_team': 'database_admins',
        'rto_hours': 4,
        'business_cycle': 'weekly'
    },
    {
        'name': 'æŠ¥è¡¨åˆ†æç³»ç»Ÿ',
        'criticality': 'medium',
        'owner': 'analytics',
        'dba_team': 'database_admins',
        'rto_hours': 24,
        'business_cycle': 'monthly'
    }
]

# åˆ¶å®šå¹´åº¦æ¼”ç»ƒè®¡åˆ’
annual_schedule = planner.plan_annual_drill_schedule(business_calendar, system_inventory)

print("å¹´åº¦å®¹ç¾æ¼”ç»ƒè®¡åˆ’:")
print(f"æ€»è®¡æ¼”ç»ƒæ¬¡æ•°: {len(annual_schedule['drills'])}")
print("\nå­£åº¦ç›®æ ‡:")
for quarter, goals in annual_schedule['quarterly_goals'].items():
    print(f"Q{quarter}: è¦†ç›–{len(goals['systems_covered'])}ä¸ªç³»ç»Ÿ, "
          f"{goals['total_duration_hours']}å°æ—¶æ¼”ç»ƒæ—¶é—´")

print(f"\né¢„è®¡æ€»æˆæœ¬: ${annual_schedule['resource_allocation']['budget']['total_estimated_cost']:,}")
```

### 5.2 æ¼”ç»ƒæ‰§è¡Œç›‘æ§

#### æ¼”ç»ƒæ‰§è¡Œè·Ÿè¸ªç³»ç»Ÿ
```python
# æ¼”ç»ƒæ‰§è¡Œç›‘æ§ç³»ç»Ÿ
import time
from datetime import datetime
from typing import Dict, List, Any
import threading

class DrillExecutionMonitor:
    def __init__(self):
        self.active_drills = {}
        self.drill_metrics = {}
        self.alerts = []
        self.monitoring_thread = None
        self.is_monitoring = False
    
    def start_drill_monitoring(self, drill_config: Dict[str, Any]):
        """å¼€å§‹æ¼”ç»ƒç›‘æ§"""
        drill_id = f"drill_{int(time.time())}"
        
        self.active_drills[drill_id] = {
            'config': drill_config,
            'start_time': datetime.now(),
            'status': 'running',
            'milestones': [],
            'incidents': []
        }
        
        self.drill_metrics[drill_id] = {
            'timeline_metrics': {},
            'performance_metrics': {},
            'resource_utilization': {}
        }
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitor_drill, args=(drill_id,))
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()
        
        return drill_id
    
    def _monitor_drill(self, drill_id: str):
        """ç›‘æ§æ¼”ç»ƒæ‰§è¡Œ"""
        while self.is_monitoring and drill_id in self.active_drills:
            try:
                self._collect_metrics(drill_id)
                self._check_milestones(drill_id)
                self._evaluate_performance(drill_id)
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                self._log_alert(drill_id, 'MONITOR_ERROR', f"ç›‘æ§å¼‚å¸¸: {str(e)}")
    
    def _collect_metrics(self, drill_id: str):
        """æ”¶é›†æ¼”ç»ƒæŒ‡æ ‡"""
        drill = self.active_drills[drill_id]
        metrics = self.drill_metrics[drill_id]
        
        # æ—¶é—´çº¿æŒ‡æ ‡
        elapsed_time = (datetime.now() - drill['start_time']).total_seconds() / 3600
        metrics['timeline_metrics']['elapsed_hours'] = round(elapsed_time, 2)
        
        # æ€§èƒ½æŒ‡æ ‡ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
        metrics['performance_metrics'] = {
            'rto_achieved': self._simulate_rto_progress(elapsed_time, drill['config']),
            'data_consistency': self._simulate_consistency_check(),
            'user_impact': self._simulate_user_impact(elapsed_time)
        }
        
        # èµ„æºåˆ©ç”¨ç‡
        metrics['resource_utilization'] = {
            'personnel_engaged': len(drill['config']['participants']),
            'systems_affected': 1,
            'communication_sent': self._count_communications(drill_id)
        }
    
    def _check_milestones(self, drill_id: str):
        """æ£€æŸ¥é‡Œç¨‹ç¢‘"""
        drill = self.active_drills[drill_id]
        elapsed_hours = self.drill_metrics[drill_id]['timeline_metrics']['elapsed_hours']
        
        expected_milestones = self._get_expected_milestones(drill['config'])
        
        for milestone in expected_milestones:
            if elapsed_hours >= milestone['expected_time_hours']:
                if not self._milestone_completed(drill_id, milestone['name']):
                    self._record_milestone_completion(drill_id, milestone)
    
    def _evaluate_performance(self, drill_id: str):
        """è¯„ä¼°æ¼”ç»ƒæ€§èƒ½"""
        metrics = self.drill_metrics[drill_id]
        config = self.active_drills[drill_id]['config']
        
        # RTOè¯„ä¼°
        rto_achieved = metrics['performance_metrics']['rto_achieved']
        target_rto = config['success_criteria'][0].split(' ')[1]  # æå–ç›®æ ‡RTO
        
        try:
            target_hours = float(target_rto.replace('å°æ—¶', ''))
            if rto_achieved > target_hours * 1.2:  # è¶…è¿‡ç›®æ ‡20%
                self._log_alert(drill_id, 'RTO_WARNING', f"RTOè¶…å‡ºé¢„æœŸ: {rto_achieved}å°æ—¶")
        except:
            pass
    
    def _simulate_rto_progress(self, elapsed_hours: float, config: Dict) -> float:
        """æ¨¡æ‹ŸRTOè¿›åº¦"""
        # ç®€åŒ–çš„æ¨¡æ‹Ÿé€»è¾‘
        drill_type = config['type']
        if drill_type == 'TABLETOP':
            return min(elapsed_hours * 0.5, 2.0)
        elif drill_type == 'FUNCTIONAL':
            return min(elapsed_hours * 0.3, 4.0)
        else:
            return min(elapsed_hours * 0.2, 8.0)
    
    def _simulate_consistency_check(self) -> float:
        """æ¨¡æ‹Ÿä¸€è‡´æ€§æ£€æŸ¥ç»“æœ"""
        # è¿”å›ä¸€è‡´æ€§ç™¾åˆ†æ¯”
        return random.uniform(95.0, 99.9)
    
    def _simulate_user_impact(self, elapsed_hours: float) -> float:
        """æ¨¡æ‹Ÿç”¨æˆ·å½±å“"""
        # è¿”å›å—å½±å“ç”¨æˆ·ç™¾åˆ†æ¯”
        return min(elapsed_hours * 2.0, 15.0)
    
    def _count_communications(self, drill_id: str) -> int:
        """ç»Ÿè®¡é€šä¿¡æ¬¡æ•°"""
        drill = self.active_drills[drill_id]
        elapsed_hours = self.drill_metrics[drill_id]['timeline_metrics']['elapsed_hours']
        
        # æ ¹æ®æ²Ÿé€šè®¡åˆ’è®¡ç®—é¢„æœŸé€šä¿¡æ¬¡æ•°
        communications_per_hour = 0.5  # æ¯2å°æ—¶ä¸€æ¬¡æ›´æ–°
        return int(elapsed_hours * communications_per_hour)
    
    def _get_expected_milestones(self, config: Dict) -> List[Dict]:
        """è·å–é¢„æœŸé‡Œç¨‹ç¢‘"""
        drill_type = config['type']
        
        milestones = {
            'TABLETOP': [
                {'name': 'æ¼”ç»ƒå¯åŠ¨', 'expected_time_hours': 0.5},
                {'name': 'åœºæ™¯è®¨è®ºå®Œæˆ', 'expected_time_hours': 2.0},
                {'name': 'æ€»ç»“ä¼šè®®', 'expected_time_hours': 3.5}
            ],
            'FUNCTIONAL': [
                {'name': 'ç¯å¢ƒå‡†å¤‡å®Œæˆ', 'expected_time_hours': 1.0},
                {'name': 'æ•…éšœæ³¨å…¥', 'expected_time_hours': 2.0},
                {'name': 'æ¢å¤æ“ä½œå¼€å§‹', 'expected_time_hours': 4.0},
                {'name': 'ç³»ç»ŸéªŒè¯å®Œæˆ', 'expected_time_hours': 7.0}
            ],
            'FULL_INTERUPTION': [
                {'name': 'æ­£å¼ä¸­æ–­å¼€å§‹', 'expected_time_hours': 0.5},
                {'name': 'åˆæ­¥è¯„ä¼°å®Œæˆ', 'expected_time_hours': 2.0},
                {'name': 'æ¢å¤å›¢é˜Ÿåˆ°ä½', 'expected_time_hours': 4.0},
                {'name': 'æ ¸å¿ƒåŠŸèƒ½æ¢å¤', 'expected_time_hours': 12.0},
                {'name': 'å®Œæ•´éªŒè¯å®Œæˆ', 'expected_time_hours': 20.0}
            ]
        }
        
        return milestones.get(drill_type, milestones['FUNCTIONAL'])
    
    def _milestone_completed(self, drill_id: str, milestone_name: str) -> bool:
        """æ£€æŸ¥é‡Œç¨‹ç¢‘æ˜¯å¦å·²å®Œæˆ"""
        drill = self.active_drills[drill_id]
        return any(m['name'] == milestone_name for m in drill['milestones'])
    
    def _record_milestone_completion(self, drill_id: str, milestone: Dict):
        """è®°å½•é‡Œç¨‹ç¢‘å®Œæˆ"""
        completion_record = {
            'name': milestone['name'],
            'completed_at': datetime.now(),
            'elapsed_time_hours': self.drill_metrics[drill_id]['timeline_metrics']['elapsed_hours']
        }
        
        self.active_drills[drill_id]['milestones'].append(completion_record)
        
        # è®°å½•é‡Œç¨‹ç¢‘å‘Šè­¦
        self._log_alert(drill_id, 'MILESTONE_COMPLETED', 
                       f"é‡Œç¨‹ç¢‘å®Œæˆ: {milestone['name']}")
    
    def _log_alert(self, drill_id: str, alert_type: str, message: str):
        """è®°å½•å‘Šè­¦"""
        alert = {
            'timestamp': datetime.now(),
            'drill_id': drill_id,
            'type': alert_type,
            'message': message
        }
        self.alerts.append(alert)
        print(f"[{alert_type}] {message}")
    
    def record_incident(self, drill_id: str, incident_description: str, severity: str):
        """è®°å½•æ¼”ç»ƒæœŸé—´çš„äº‹ä»¶"""
        incident = {
            'timestamp': datetime.now(),
            'description': incident_description,
            'severity': severity,
            'resolved': False
        }
        
        self.active_drills[drill_id]['incidents'].append(incident)
        self._log_alert(drill_id, f'INCIDENT_{severity.upper()}', incident_description)
    
    def get_drill_status(self, drill_id: str) -> Dict[str, Any]:
        """è·å–æ¼”ç»ƒçŠ¶æ€"""
        if drill_id not in self.active_drills:
            return {'error': 'æ¼”ç»ƒä¸å­˜åœ¨'}
        
        drill = self.active_drills[drill_id]
        metrics = self.drill_metrics[drill_id]
        
        return {
            'drill_info': drill['config'],
            'current_status': drill['status'],
            'elapsed_time_hours': metrics['timeline_metrics'].get('elapsed_hours', 0),
            'performance': metrics['performance_metrics'],
            'milestones_completed': len(drill['milestones']),
            'total_milestones': len(self._get_expected_milestones(drill['config'])),
            'incidents': len(drill['incidents']),
            'alerts': [a for a in self.alerts if a['drill_id'] == drill_id][-10:]  # æœ€è¿‘10æ¡å‘Šè­¦
        }
    
    def stop_drill_monitoring(self, drill_id: str):
        """åœæ­¢æ¼”ç»ƒç›‘æ§"""
        if drill_id in self.active_drills:
            self.active_drills[drill_id]['status'] = 'completed'
            self.active_drills[drill_id]['end_time'] = datetime.now()
        
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)

# ä½¿ç”¨ç¤ºä¾‹
monitor = DrillExecutionMonitor()

# å¯åŠ¨æ¼”ç»ƒç›‘æ§
drill_config = {
    'type': 'FUNCTIONAL',
    'system': 'æ ¸å¿ƒäº¤æ˜“ç³»ç»Ÿ',
    'participants': ['dba_team', 'operations', 'business_analysts'],
    'success_criteria': ['ç³»ç»Ÿåœ¨2å°æ—¶å†…æ¢å¤æ­£å¸¸', 'æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡'],
    'duration_hours': 8
}

drill_id = monitor.start_drill_monitoring(drill_config)
print(f"å¼€å§‹ç›‘æ§æ¼”ç»ƒ: {drill_id}")

# æ¨¡æ‹Ÿæ¼”ç»ƒè¿‡ç¨‹ä¸­çš„æ“ä½œ
time.sleep(2)  # ç­‰å¾…ç›‘æ§å¯åŠ¨

# è®°å½•ä¸€äº›äº‹ä»¶
monitor.record_incident(drill_id, 'å‘ç°æ•°æ®åŒæ­¥å»¶è¿Ÿé—®é¢˜', 'HIGH')
monitor.record_incident(drill_id, 'ç½‘ç»œè¿æ¥ä¸ç¨³å®š', 'MEDIUM')

# è·å–å½“å‰çŠ¶æ€
status = monitor.get_drill_status(drill_id)
print(f"æ¼”ç»ƒçŠ¶æ€: {status}")

# åœæ­¢ç›‘æ§
monitor.stop_drill_monitoring(drill_id)
```

## 6. æ•…éšœæ¢å¤æµç¨‹

### 6.1 æ¢å¤å†³ç­–æµç¨‹

#### æ™ºèƒ½æ¢å¤å†³ç­–ç³»ç»Ÿ
```python
# æ™ºèƒ½æ•…éšœæ¢å¤å†³ç­–ç³»ç»Ÿ
from datetime import datetime
from typing import Dict, List, Any
import json

class IntelligentRecoveryDecision:
    def __init__(self):
        self.recovery_playbooks = {}
        self.decision_history = []
        self.system_health_cache = {}
    
    def register_recovery_playbook(self, scenario_type: str, playbook: Dict[str, Any]):
        """æ³¨å†Œæ¢å¤é¢„æ¡ˆ"""
        self.recovery_playbooks[scenario_type] = playbook
    
    def make_recovery_decision(self, failure_context: Dict[str, Any]) -> Dict[str, Any]:
        """åšå‡ºæ¢å¤å†³ç­–"""
        decision_start_time = datetime.now()
        
        # åˆ†ææ•…éšœä¸Šä¸‹æ–‡
        analysis = self._analyze_failure_context(failure_context)
        
        # é€‰æ‹©é€‚å½“çš„æ¢å¤ç­–ç•¥
        recovery_strategy = self._select_recovery_strategy(analysis)
        
        # ç”Ÿæˆè¯¦ç»†æ¢å¤è®¡åˆ’
        recovery_plan = self._generate_recovery_plan(recovery_strategy, failure_context)
        
        # è¯„ä¼°é£é™©å’Œå½±å“
        risk_assessment = self._assess_recovery_risks(recovery_plan)
        
        decision = {
            'timestamp': decision_start_time,
            'failure_analysis': analysis,
            'selected_strategy': recovery_strategy,
            'recovery_plan': recovery_plan,
            'risk_assessment': risk_assessment,
            'decision_confidence': self._calculate_confidence(analysis, recovery_strategy),
            'approval_required': risk_assessment['requires_approval']
        }
        
        self.decision_history.append(decision)
        return decision
    
    def _analyze_failure_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ•…éšœä¸Šä¸‹æ–‡"""
        analysis = {
            'failure_type': self._classify_failure(context),
            'impact_scope': self._assess_impact_scope(context),
            'root_cause_probability': self._estimate_root_cause(context),
            'business_impact': self._calculate_business_impact(context),
            'system_dependencies': self._map_dependencies(context)
        }
        return analysis
    
    def _classify_failure(self, context: Dict[str, Any]) -> str:
        """æ•…éšœåˆ†ç±»"""
        error_patterns = context.get('error_patterns', [])
        system_metrics = context.get('system_metrics', {})
        
        # åŸºäºé”™è¯¯æ¨¡å¼åˆ†ç±»
        if any('network' in pattern.lower() for pattern in error_patterns):
            return 'NETWORK_FAILURE'
        elif any('storage' in pattern.lower() for pattern in error_patterns):
            return 'STORAGE_FAILURE'
        elif any('memory' in pattern.lower() for pattern in error_patterns):
            return 'MEMORY_FAILURE'
        elif system_metrics.get('cpu_usage', 0) > 90:
            return 'RESOURCE_EXHAUSTION'
        else:
            return 'APPLICATION_FAILURE'
    
    def _assess_impact_scope(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å½±å“èŒƒå›´"""
        affected_components = context.get('affected_components', [])
        user_impact = context.get('user_impact', {})
        
        return {
            'affected_systems': len(affected_components),
            'affected_users': user_impact.get('affected_users', 0),
            'business_functions_impacted': user_impact.get('functions_impacted', []),
            'geographic_scope': context.get('geographic_impact', 'local'),
            'severity_level': self._determine_severity(user_impact)
        }
    
    def _determine_severity(self, user_impact: Dict) -> str:
        """ç¡®å®šä¸¥é‡ç¨‹åº¦"""
        affected_users = user_impact.get('affected_users', 0)
        critical_functions = len(user_impact.get('functions_impacted', []))
        
        if affected_users > 10000 or critical_functions > 3:
            return 'CRITICAL'
        elif affected_users > 1000 or critical_functions > 1:
            return 'HIGH'
        elif affected_users > 100:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _estimate_root_cause(self, context: Dict[str, Any]) -> Dict[str, float]:
        """ä¼°è®¡æ ¹æœ¬åŸå› æ¦‚ç‡"""
        # ç®€åŒ–çš„è´å¶æ–¯æ¨ç†
        evidence = context.get('diagnostic_evidence', {})
        
        causes = {
            'hardware_failure': 0.3,
            'software_bug': 0.4,
            'configuration_error': 0.2,
            'external_dependency': 0.1
        }
        
        # æ ¹æ®è¯æ®è°ƒæ•´æ¦‚ç‡
        if evidence.get('hardware_errors'):
            causes['hardware_failure'] += 0.3
            causes['software_bug'] -= 0.1
        
        if evidence.get('recent_changes'):
            causes['configuration_error'] += 0.2
            causes['software_bug'] += 0.1
        
        # å½’ä¸€åŒ–æ¦‚ç‡
        total = sum(causes.values())
        for cause in causes:
            causes[cause] /= total
        
        return causes
    
    def _calculate_business_impact(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ä¸šåŠ¡å½±å“"""
        user_impact = context.get('user_impact', {})
        financial_data = context.get('financial_impact', {})
        
        hourly_loss = financial_data.get('hourly_revenue_loss', 0)
        duration_hours = context.get('failure_duration_hours', 1)
        
        return {
            'estimated_revenue_loss': hourly_loss * duration_hours,
            'customer_satisfaction_impact': user_impact.get('satisfaction_drop', 0),
            'brand_reputation_risk': self._assess_reputation_risk(user_impact),
            'regulatory_implications': self._check_regulatory_impact(context)
        }
    
    def _assess_reputation_risk(self, user_impact: Dict) -> str:
        """è¯„ä¼°å£°èª‰é£é™©"""
        satisfaction_drop = user_impact.get('satisfaction_drop', 0)
        public_exposure = user_impact.get('public_exposure', False)
        
        if satisfaction_drop > 20 and public_exposure:
            return 'HIGH'
        elif satisfaction_drop > 10:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _check_regulatory_impact(self, context: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç›‘ç®¡å½±å“"""
        system_type = context.get('system_type', '')
        geographic_scope = context.get('geographic_impact', '')
        
        regulated_systems = ['financial', 'healthcare', 'government']
        regulated_regions = ['EU', 'US', 'China']
        
        return (any(regulated in system_type.lower() for regulated in regulated_systems) and
                any(region in geographic_scope for region in regulated_regions))
    
    def _map_dependencies(self, context: Dict[str, Any]) -> List[str]:
        """æ˜ å°„ä¾èµ–å…³ç³»"""
        dependencies = context.get('known_dependencies', [])
        # å¯ä»¥æ‰©å±•ä¸ºæ›´å¤æ‚çš„ä¾èµ–åˆ†æ
        return dependencies
    
    def _select_recovery_strategy(self, analysis: Dict[str, Any]) -> str:
        """é€‰æ‹©æ¢å¤ç­–ç•¥"""
        failure_type = analysis['failure_type']
        severity = analysis['impact_scope']['severity_level']
        
        strategy_mapping = {
            ('NETWORK_FAILURE', 'CRITICAL'): 'IMMEDIATE_FAILOVER',
            ('NETWORK_FAILURE', 'HIGH'): 'ROUTED_RECOVERY',
            ('STORAGE_FAILURE', 'CRITICAL'): 'DATA_RESTORE_PRIORITY',
            ('STORAGE_FAILURE', 'HIGH'): 'REDUNDANT_PATH_ACTIVATION',
            ('MEMORY_FAILURE', 'CRITICAL'): 'IMMEDIATE_RESTART',
            ('MEMORY_FAILURE', 'HIGH'): 'RESOURCE_REALLOCATION',
            ('RESOURCE_EXHAUSTION', 'CRITICAL'): 'SCALE_OUT_EMERGENCY',
            ('RESOURCE_EXHAUSTION', 'HIGH'): 'TRAFFIC_SHAPING',
            ('APPLICATION_FAILURE', 'CRITICAL'): 'ROLLBACK_DEPLOYMENT',
            ('APPLICATION_FAILURE', 'HIGH'): 'FEATURE_TOGGLE_DISABLE'
        }
        
        return strategy_mapping.get((failure_type, severity), 'STANDARD_RECOVERY')
    
    def _generate_recovery_plan(self, strategy: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¢å¤è®¡åˆ’"""
        playbook = self.recovery_playbooks.get(strategy, {})
        
        plan = {
            'strategy': strategy,
            'steps': playbook.get('recovery_steps', []),
            'timeline': playbook.get('expected_timeline', {}),
            'required_resources': playbook.get('resources_required', []),
            'success_criteria': playbook.get('success_indicators', []),
            'rollback_procedures': playbook.get('rollback_procedures', [])
        }
        
        # æ ¹æ®å…·ä½“ä¸Šä¸‹æ–‡å®šåˆ¶è®¡åˆ’
        plan = self._customize_plan(plan, context)
        return plan
    
    def _customize_plan(self, plan: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """å®šåˆ¶æ¢å¤è®¡åˆ’"""
        # æ ¹æ®å½±å“èŒƒå›´è°ƒæ•´æ—¶é—´çº¿
        impact_scope = context.get('user_impact', {})
        affected_users = impact_scope.get('affected_users', 0)
        
        if affected_users > 10000:
            # å¤§è§„æ¨¡å½±å“ï¼Œå‹ç¼©æ—¶é—´çº¿
            for step in plan['timeline']:
                plan['timeline'][step] = plan['timeline'][step] * 0.7
        
        return plan
    
    def _assess_recovery_risks(self, plan: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æ¢å¤é£é™©"""
        risks = {
            'data_loss_risk': self._assess_data_loss_risk(plan),
            'downtime_extension_risk': self._assess_downtime_risk(plan),
            'rollback_complexity': self._assess_rollback_complexity(plan),
            'requires_approval': self._requires_management_approval(plan)
        }
        return risks
    
    def _assess_data_loss_risk(self, plan: Dict[str, Any]) -> str:
        """è¯„ä¼°æ•°æ®ä¸¢å¤±é£é™©"""
        strategy = plan['strategy']
        if 'RESTORE' in strategy or 'ROLLBACK' in strategy:
            return 'HIGH'
        elif 'FAILOVER' in strategy:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _assess_downtime_risk(self, plan: Dict[str, Any]) -> str:
        """è¯„ä¼°åœæœºæ—¶é—´å»¶é•¿é£é™©"""
        expected_duration = sum(plan['timeline'].values())
        if expected_duration > 4:
            return 'HIGH'
        elif expected_duration > 2:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _assess_rollback_complexity(self, plan: Dict[str, Any]) -> str:
        """è¯„ä¼°å›æ»šå¤æ‚åº¦"""
        rollback_steps = plan.get('rollback_procedures', [])
        if len(rollback_steps) > 5:
            return 'HIGH'
        elif len(rollback_steps) > 2:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _requires_management_approval(self, plan: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç®¡ç†å±‚æ‰¹å‡†"""
        high_risks = [
            plan['risks']['data_loss_risk'] == 'HIGH',
            plan['risks']['downtime_extension_risk'] == 'HIGH'
        ]
        return any(high_risks)
    
    def _calculate_confidence(self, analysis: Dict, strategy: str) -> float:
        """è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        # åŸºäºå†å²æ•°æ®å’Œåˆ†æå®Œæ•´æ€§è®¡ç®—ç½®ä¿¡åº¦
        base_confidence = 0.8
        confidence_factors = [
            len(analysis['root_cause_probability']) > 0,
            analysis['impact_scope']['affected_systems'] > 0,
            strategy in self.recovery_playbooks
        ]
        
        confidence_bonus = sum(confidence_factors) * 0.05
        return min(0.95, base_confidence + confidence_bonus)

# ä½¿ç”¨ç¤ºä¾‹
decision_system = IntelligentRecoveryDecision()

# æ³¨å†Œæ¢å¤é¢„æ¡ˆ
decision_system.register_recovery_playbook('IMMEDIATE_FAILOVER', {
    'recovery_steps': [
        'æ¿€æ´»å¤‡ç”¨ç³»ç»Ÿ',
        'åˆ‡æ¢DNSè®°å½•',
        'éªŒè¯æœåŠ¡å¯ç”¨æ€§',
        'ç›‘æ§æ€§èƒ½æŒ‡æ ‡'
    ],
    'expected_timeline': {
        'activation': 5,
        'dns_switch': 2,
        'verification': 10,
        'monitoring': 15
    },
    'resources_required': ['network_team', 'dns_administrator', 'monitoring_tools'],
    'success_indicators': ['99%æœåŠ¡å¯ç”¨æ€§', 'å“åº”æ—¶é—´<100ms', 'é”™è¯¯ç‡<0.1%']
})

# æ¨¡æ‹Ÿæ•…éšœåœºæ™¯
failure_context = {
    'error_patterns': ['network timeout', 'connection refused'],
    'system_metrics': {'cpu_usage': 85, 'memory_usage': 70},
    'affected_components': ['web_server_1', 'web_server_2'],
    'user_impact': {
        'affected_users': 5000,
        'functions_impacted': ['login', 'payment'],
        'satisfaction_drop': 15
    },
    'financial_impact': {'hourly_revenue_loss': 50000},
    'failure_duration_hours': 2,
    'system_type': 'ecommerce_platform',
    'geographic_impact': 'US_EU'
}

# åšå‡ºæ¢å¤å†³ç­–
decision = decision_system.make_recovery_decision(failure_context)
print("æ¢å¤å†³ç­–:")
print(json.dumps(decision, indent=2, ensure_ascii=False, default=str))
```

### 6.2 è‡ªåŠ¨åŒ–æ¢å¤æ‰§è¡Œ

#### æ¢å¤æ‰§è¡Œè‡ªåŠ¨åŒ–æ¡†æ¶
```python
# è‡ªåŠ¨åŒ–æ¢å¤æ‰§è¡Œæ¡†æ¶
import time
import threading
from datetime import datetime
from typing import Dict, List, Any, Callable

class AutomatedRecoveryExecutor:
    def __init__(self):
        self.execution_queue = []
        self.running_executions = {}
        self.execution_history = []
        self.notification_callbacks = []
    
    def register_notification_callback(self, callback: Callable):
        """æ³¨å†Œé€šçŸ¥å›è°ƒå‡½æ•°"""
        self.notification_callbacks.append(callback)
    
    def execute_recovery_plan(self, recovery_plan: Dict[str, Any], context: Dict[str, Any]) -> str:
        """æ‰§è¡Œæ¢å¤è®¡åˆ’"""
        execution_id = f"exec_{int(time.time())}"
        
        execution = {
            'id': execution_id,
            'plan': recovery_plan,
            'context': context,
            'status': 'pending',
            'start_time': None,
            'end_time': None,
            'current_step': 0,
            'completed_steps': [],
            'failed_steps': [],
            'progress': 0.0
        }
        
        self.execution_queue.append(execution)
        self.running_executions[execution_id] = execution
        
        # å¯åŠ¨æ‰§è¡Œçº¿ç¨‹
        execution_thread = threading.Thread(
            target=self._execute_recovery_process, 
            args=(execution_id,)
        )
        execution_thread.daemon = True
        execution_thread.start()
        
        self._notify_status_change(execution, 'QUEUED')
        return execution_id
    
    def _execute_recovery_process(self, execution_id: str):
        """æ‰§è¡Œæ¢å¤è¿‡ç¨‹"""
        execution = self.running_executions[execution_id]
        execution['status'] = 'running'
        execution['start_time'] = datetime.now()
        self._notify_status_change(execution, 'STARTED')
        
        try:
            steps = execution['plan']['steps']
            total_steps = len(steps)
            
            for i, step in enumerate(steps):
                execution['current_step'] = i
                self._notify_status_change(execution, 'STEP_STARTED', {'step': step})
                
                # æ‰§è¡Œæ­¥éª¤
                step_result = self._execute_step(step, execution['context'])
                
                if step_result['success']:
                    execution['completed_steps'].append({
                        'step': step,
                        'result': step_result,
                        'completed_at': datetime.now()
                    })
                    self._notify_status_change(execution, 'STEP_COMPLETED', {'step': step})
                else:
                    execution['failed_steps'].append({
                        'step': step,
                        'error': step_result['error'],
                        'failed_at': datetime.now()
                    })
                    self._notify_status_change(execution, 'STEP_FAILED', {
                        'step': step,
                        'error': step_result['error']
                    })
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å›æ»š
                    if self._should_rollback(execution):
                        self._execute_rollback(execution)
                        break
                
                # æ›´æ–°è¿›åº¦
                execution['progress'] = (i + 1) / total_steps
                self._notify_status_change(execution, 'PROGRESS_UPDATE')
            
            # å®Œæˆæ‰§è¡Œ
            execution['status'] = 'completed' if not execution['failed_steps'] else 'failed'
            execution['end_time'] = datetime.now()
            
            final_status = 'SUCCESS' if execution['status'] == 'completed' else 'FAILED'
            self._notify_status_change(execution, final_status)
            
        except Exception as e:
            execution['status'] = 'error'
            execution['error'] = str(e)
            execution['end_time'] = datetime.now()
            self._notify_status_change(execution, 'EXECUTION_ERROR', {'error': str(e)})
        
        # æ¸…ç†
        self.execution_history.append(execution)
        if execution_id in self.running_executions:
            del self.running_executions[execution_id]
    
    def _execute_step(self, step: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        try:
            # æ¨¡æ‹Ÿæ­¥éª¤æ‰§è¡Œ
            time.sleep(2)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            
            # æ ¹æ®æ­¥éª¤ç±»å‹æ‰§è¡Œä¸åŒæ“ä½œ
            if 'activate' in step.lower():
                result = self._activate_backup_system(context)
            elif 'switch' in step.lower():
                result = self._switch_dns_records(context)
            elif 'verify' in step.lower():
                result = self._verify_service_availability(context)
            elif 'monitor' in step.lower():
                result = self._start_monitoring(context)
            else:
                result = {'success': True, 'message': f'Step "{step}" executed'}
            
            return result
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _activate_backup_system(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ¿€æ´»å¤‡ç”¨ç³»ç»Ÿ"""
        # æ¨¡æ‹Ÿå¤‡ç”¨ç³»ç»Ÿæ¿€æ´»
        time.sleep(3)
        return {'success': True, 'message': 'å¤‡ç”¨ç³»ç»Ÿæ¿€æ´»æˆåŠŸ'}
    
    def _switch_dns_records(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ‡æ¢DNSè®°å½•"""
        # æ¨¡æ‹ŸDNSåˆ‡æ¢
        time.sleep(1)
        return {'success': True, 'message': 'DNSè®°å½•åˆ‡æ¢å®Œæˆ'}
    
    def _verify_service_availability(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æœåŠ¡å¯ç”¨æ€§"""
        # æ¨¡æ‹ŸæœåŠ¡éªŒè¯
        time.sleep(2)
        # æ¨¡æ‹Ÿ95%çš„æˆåŠŸç‡
        import random
        success = random.random() > 0.05
        return {
            'success': success,
            'message': 'æœåŠ¡éªŒè¯é€šè¿‡' if success else 'æœåŠ¡éªŒè¯å¤±è´¥',
            'availability': 99.2 if success else 85.0
        }
    
    def _start_monitoring(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¯åŠ¨ç›‘æ§"""
        # æ¨¡æ‹Ÿç›‘æ§å¯åŠ¨
        return {'success': True, 'message': 'ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨'}
    
    def _should_rollback(self, execution: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å›æ»š"""
        failed_steps = execution['failed_steps']
        if not failed_steps:
            return False
        
        # å¦‚æœå…³é”®æ­¥éª¤å¤±è´¥ï¼Œåˆ™å›æ»š
        critical_steps = ['activate backup system', 'switch dns records']
        latest_failed_step = failed_steps[-1]['step'].lower()
        
        return any(critical_step in latest_failed_step for critical_step in critical_steps)
    
    def _execute_rollback(self, execution: Dict[str, Any]):
        """æ‰§è¡Œå›æ»š"""
        rollback_procedures = execution['plan'].get('rollback_procedures', [])
        
        execution['status'] = 'rolling_back'
        self._notify_status_change(execution, 'ROLLBACK_STARTED')
        
        for procedure in rollback_procedures:
            try:
                # æ‰§è¡Œå›æ»šæ­¥éª¤
                time.sleep(1)
                self._notify_status_change(execution, 'ROLLBACK_STEP', {'procedure': procedure})
            except Exception as e:
                self._notify_status_change(execution, 'ROLLBACK_ERROR', {'error': str(e)})
        
        execution['status'] = 'rolled_back'
        self._notify_status_change(execution, 'ROLLBACK_COMPLETED')
    
    def _notify_status_change(self, execution: Dict[str, Any], status: str, details: Dict = None):
        """é€šçŸ¥çŠ¶æ€å˜åŒ–"""
        notification = {
            'timestamp': datetime.now(),
            'execution_id': execution['id'],
            'status': status,
            'details': details or {},
            'progress': execution['progress']
        }
        
        for callback in self.notification_callbacks:
            try:
                callback(notification)
            except Exception as e:
                print(f"é€šçŸ¥å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    def get_execution_status(self, execution_id: str) -> Dict[str, Any]:
        """è·å–æ‰§è¡ŒçŠ¶æ€"""
        if execution_id in self.running_executions:
            return self.running_executions[execution_id]
        elif execution_id in [exec_data['id'] for exec_data in self.execution_history]:
            return next(exec_data for exec_data in self.execution_history 
                       if exec_data['id'] == execution_id)
        else:
            return {'error': 'æ‰§è¡Œä¸å­˜åœ¨'}
    
    def cancel_execution(self, execution_id: str) -> bool:
        """å–æ¶ˆæ‰§è¡Œ"""
        if execution_id in self.running_executions:
            execution = self.running_executions[execution_id]
            execution['status'] = 'cancelled'
            execution['end_time'] = datetime.now()
            self._notify_status_change(execution, 'CANCELLED')
            return True
        return False
    
    def get_queue_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        return {
            'queue_length': len(self.execution_queue),
            'running_executions': len(self.running_executions),
            'completed_today': len([e for e in self.execution_history 
                                  if e['end_time'] and e['end_time'].date() == datetime.now().date()]),
            'success_rate': self._calculate_success_rate()
        }
    
    def _calculate_success_rate(self) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        if not self.execution_history:
            return 0.0
        
        successful = sum(1 for exec_data in self.execution_history 
                        if exec_data['status'] == 'completed')
        total = len(self.execution_history)
        
        return (successful / total) * 100 if total > 0 else 0.0

# ä½¿ç”¨ç¤ºä¾‹
executor = AutomatedRecoveryExecutor()

# æ³¨å†Œé€šçŸ¥å›è°ƒ
def notification_handler(notification):
    print(f"[{notification['timestamp']}] æ‰§è¡Œ{notification['execution_id']}: "
          f"{notification['status']} - {notification['progress']:.1%}")

executor.register_notification_callback(notification_handler)

# æ‰§è¡Œæ¢å¤è®¡åˆ’
recovery_plan = {
    'strategy': 'IMMEDIATE_FAILOVER',
    'steps': [
        'Activate backup system',
        'Switch DNS records', 
        'Verify service availability',
        'Start monitoring'
    ],
    'rollback_procedures': [
        'Revert DNS changes',
        'Deactivate backup system',
        'Restart primary system'
    ]
}

context = {
    'affected_system': 'web_cluster_1',
    'backup_system': 'web_cluster_2',
    'dns_zone': 'example.com'
}

execution_id = executor.execute_recovery_plan(recovery_plan, context)
print(f"å¼€å§‹æ‰§è¡Œæ¢å¤è®¡åˆ’: {execution_id}")

# ç›‘æ§æ‰§è¡ŒçŠ¶æ€
for i in range(10):
    time.sleep(3)
    status = executor.get_execution_status(execution_id)
    if 'error' not in status:
        print(f"æ‰§è¡Œè¿›åº¦: {status['progress']:.1%}, "
              f"çŠ¶æ€: {status['status']}, "
              f"å½“å‰æ­¥éª¤: {status['current_step']}")

queue_status = executor.get_queue_status()
print(f"é˜Ÿåˆ—çŠ¶æ€: {queue_status}")
```

---

## ğŸ” å…³é”®è¦ç‚¹æ€»ç»“

### âœ… å®¹ç¾æˆåŠŸè¦ç´ 
- **å…¨é¢çš„é£é™©è¯„ä¼°**ï¼šæ·±å…¥åˆ†æä¸šåŠ¡å½±å“å’Œæ¢å¤éœ€æ±‚
- **åˆé€‚çš„æ¶æ„é€‰æ‹©**ï¼šæ ¹æ®RTO/RPOè¦æ±‚é€‰æ‹©æ°å½“çš„å®¹ç¾æ¶æ„
- **å®Œå–„çš„æ•°æ®ä¿æŠ¤**ï¼šå»ºç«‹å¯é çš„æ•°æ®åŒæ­¥å’Œå¤‡ä»½æœºåˆ¶
- **å®šæœŸçš„æ¼”ç»ƒéªŒè¯**ï¼šé€šè¿‡æ¼”ç»ƒç¡®ä¿é¢„æ¡ˆçš„æœ‰æ•ˆæ€§

### âš ï¸ å¸¸è§é£é™©æé†’
- **æˆæœ¬è¶…æ”¯é£é™©**ï¼šå®¹ç¾ç³»ç»Ÿå»ºè®¾å’Œç»´æŠ¤æˆæœ¬å¯èƒ½å¾ˆé«˜
- **å¤æ‚æ€§ç®¡ç†**ï¼šå¤æ‚çš„å®¹ç¾æ¶æ„å¯èƒ½å¼•å…¥æ–°çš„æ•…éšœç‚¹
- **äººå‘˜æŠ€èƒ½è¦æ±‚**ï¼šéœ€è¦ä¸“é—¨çš„å®¹ç¾ç®¡ç†å’Œæ“ä½œæŠ€èƒ½
- **æµ‹è¯•ä¸å……åˆ†**ï¼šç¼ºä¹å……åˆ†æµ‹è¯•å¯èƒ½å¯¼è‡´å®é™…æ•…éšœæ—¶æ¢å¤å¤±è´¥

### ğŸ¯ æœ€ä½³å®è·µå»ºè®®
1. **å¾ªåºæ¸è¿›å®æ–½**ï¼šä»ç®€å•æ–¹æ¡ˆå¼€å§‹ï¼Œé€æ­¥æå‡å®¹ç¾èƒ½åŠ›
2. **ä¸šåŠ¡é©±åŠ¨è®¾è®¡**ï¼šä»¥ä¸šåŠ¡éœ€æ±‚ä¸ºæ ¸å¿ƒåˆ¶å®šå®¹ç¾ç­–ç•¥
3. **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**ï¼šå°½å¯èƒ½å®ç°æ¢å¤è¿‡ç¨‹çš„è‡ªåŠ¨åŒ–
4. **æŒç»­æ”¹è¿›**ï¼šåŸºäºæ¼”ç»ƒå’Œå®é™…äº‹ä»¶ç»éªŒä¸æ–­ä¼˜åŒ–
5. **æ–‡æ¡£åŒ–ç®¡ç†**ï¼šå®Œæ•´è®°å½•æ‰€æœ‰å®¹ç¾ç›¸å…³çš„é…ç½®å’Œæµç¨‹

é€šè¿‡ç§‘å­¦çš„å®¹ç¾è§„åˆ’å’Œå®æ–½ï¼Œå¯ä»¥ä¸ºä¼ä¸šæ„å»ºèµ·åšå›ºçš„ä¸šåŠ¡è¿ç»­æ€§ä¿éšœä½“ç³»ï¼Œåœ¨é¢å¯¹å„ç§ç¾éš¾æ—¶éƒ½èƒ½ç¡®ä¿æ ¸å¿ƒä¸šåŠ¡çš„æŒç»­è¿è¥ã€‚
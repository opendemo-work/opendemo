# ğŸ”’ æ•°æ®åº“é”ç­‰å¾…å¤„ç†æŒ‡å—

> ä¼ä¸šçº§æ•°æ®åº“é”æœºåˆ¶åˆ†æå’Œæ­»é”å¤„ç†æ–¹æ¡ˆï¼Œæ¶µç›–é”ç±»å‹è¯†åˆ«ã€ç­‰å¾…é“¾åˆ†æã€æ­»é”é¢„é˜²ç­‰å®Œæ•´çš„é”é—®é¢˜è¯Šæ–­å’Œè§£å†³ä½“ç³»

## ğŸ“‹ æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ¡ˆä¾‹æ·±å…¥è®²è§£æ•°æ®åº“é”æœºåˆ¶çš„å·¥ä½œåŸç†å’Œå¸¸è§é—®é¢˜å¤„ç†æ–¹æ³•ï¼Œé€šè¿‡ç³»ç»Ÿæ€§çš„é”åˆ†æå·¥å…·å’Œé¢„é˜²ç­–ç•¥ï¼Œå¸®åŠ©DBAæœ‰æ•ˆè§£å†³é”ç­‰å¾…å’Œæ­»é”é—®é¢˜ï¼Œä¿éšœæ•°æ®åº“ç³»ç»Ÿçš„ç¨³å®šè¿è¡Œã€‚

### ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£å„ç§æ•°æ®åº“é”æœºåˆ¶çš„å·¥ä½œåŸç†
- æŒæ¡é”ç­‰å¾…å’Œæ­»é”çš„è¯Šæ–­æ–¹æ³•
- å­¦ä¼šä½¿ç”¨ä¸“ä¸šå·¥å…·åˆ†æé”é—®é¢˜
- å®æ–½æœ‰æ•ˆçš„é”ä¼˜åŒ–å’Œé¢„é˜²ç­–ç•¥
- å»ºç«‹é”ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶

### â±ï¸ å­¦ä¹ æ—¶é•¿

- **ç†è®ºå­¦ä¹ **: 3å°æ—¶
- **å®è·µæ“ä½œ**: 4å°æ—¶
- **æ€»è®¡**: 7å°æ—¶

---

## ğŸ”§ é”æœºåˆ¶åŸºç¡€ç†è®º

### æ•°æ®åº“é”ç±»å‹åˆ†ç±»

```
æ•°æ®åº“é”ç±»å‹
â”œâ”€â”€ æŒ‰é”å®šå¯¹è±¡åˆ†ç±»
â”‚   â”œâ”€â”€ è¡¨çº§é”(Table Lock)
â”‚   â”œâ”€â”€ è¡Œçº§é”(Row Lock)
â”‚   â”œâ”€â”€ é¡µçº§é”(Page Lock)
â”‚   â””â”€â”€ æ•°æ®åº“çº§é”(Database Lock)
â”œâ”€â”€ æŒ‰é”å®šæ¨¡å¼åˆ†ç±»
â”‚   â”œâ”€â”€ å…±äº«é”(Shared Lock, S)
â”‚   â”œâ”€â”€ æ’ä»–é”(Exclusive Lock, X)
â”‚   â”œâ”€â”€ æ„å‘å…±äº«é”(Intent Shared Lock, IS)
â”‚   â”œâ”€â”€ æ„å‘æ’ä»–é”(Intent Exclusive Lock, IX)
â”‚   â””â”€â”€ è‡ªå¢é”(Auto-Increment Lock)
â”œâ”€â”€ æŒ‰é”å®šç²’åº¦åˆ†ç±»
â”‚   â”œâ”€â”€ æ‚²è§‚é”(Pessimistic Lock)
â”‚   â””â”€â”€ ä¹è§‚é”(Optimistic Lock)
â””â”€â”€ æŒ‰é”å®šæ—¶é—´åˆ†ç±»
    â”œâ”€â”€ çŸ­æœŸé”(Short-term Lock)
    â”œâ”€â”€ é•¿æœŸé”(Long-term Lock)
    â””â”€â”€ æŒä¹…é”(Persistent Lock)
```

### é”å…¼å®¹æ€§çŸ©é˜µ

```
é”å…¼å®¹æ€§è¡¨ (MySQL InnoDB)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚         â”‚ S â”‚ X â”‚ IS â”‚ IX â”‚ AI â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚    S    â”‚ âœ“ â”‚ âœ— â”‚ âœ“  â”‚ âœ—  â”‚ âœ“  â”‚
â”‚    X    â”‚ âœ— â”‚ âœ— â”‚ âœ—  â”‚ âœ—  â”‚ âœ—  â”‚
â”‚   IS    â”‚ âœ“ â”‚ âœ— â”‚ âœ“  â”‚ âœ“  â”‚ âœ“  â”‚
â”‚   IX    â”‚ âœ— â”‚ âœ— â”‚ âœ“  â”‚ âœ“  â”‚ âœ“  â”‚
â”‚   AI    â”‚ âœ“ â”‚ âœ— â”‚ âœ“  â”‚ âœ“  â”‚ âœ—  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

âœ“ = å…¼å®¹  âœ— = å†²çª
```

### æ­»é”å½¢æˆæ¡ä»¶

```
æ­»é”å››è¦ç´ 
â”œâ”€â”€ äº’æ–¥æ¡ä»¶: èµ„æºä¸èƒ½è¢«å¤šä¸ªè¿›ç¨‹åŒæ—¶ä½¿ç”¨
â”œâ”€â”€ è¯·æ±‚å’Œä¿æŒæ¡ä»¶: è¿›ç¨‹å·²è·å¾—èµ„æºä½†åˆè¯·æ±‚æ–°èµ„æº
â”œâ”€â”€ ä¸å‰¥å¤ºæ¡ä»¶: å·²è·å¾—çš„èµ„æºä¸èƒ½è¢«å¼ºåˆ¶é‡Šæ”¾
â””â”€â”€ ç¯è·¯ç­‰å¾…æ¡ä»¶: å­˜åœ¨è¿›ç¨‹èµ„æºå¾ªç¯ç­‰å¾…é“¾

æ­»é”é¢„é˜²ç­–ç•¥
â”œâ”€â”€ ç ´åäº’æ–¥æ¡ä»¶ (é€šå¸¸ä¸å¯è¡Œ)
â”œâ”€â”€ ç ´åè¯·æ±‚å’Œä¿æŒæ¡ä»¶ (é¢„å…ˆåˆ†é…)
â”œâ”€â”€ ç ´åä¸å‰¥å¤ºæ¡ä»¶ (è¶…æ—¶æŠ¢å )
â””â”€â”€ ç ´åç¯è·¯ç­‰å¾…æ¡ä»¶ (èµ„æºæœ‰åºåˆ†é…)
```

---

## ğŸ¬ MySQLé”ç­‰å¾…åˆ†æå®è·µ

### 1. é”çŠ¶æ€ç›‘æ§

#### åŸºç¡€é”ä¿¡æ¯æŸ¥è¯¢
```sql
-- æŸ¥çœ‹å½“å‰é”ç­‰å¾…æƒ…å†µ
SELECT 
    r.trx_id waiting_trx_id,
    r.trx_mysql_thread_id waiting_thread,
    r.trx_query waiting_query,
    b.trx_id blocking_trx_id,
    b.trx_mysql_thread_id blocking_thread,
    b.trx_query blocking_query
FROM information_schema.innodb_lock_waits w
INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;

-- æŸ¥çœ‹äº‹åŠ¡å’Œé”è¯¦ç»†ä¿¡æ¯
SELECT 
    trx_id,
    trx_state,
    trx_started,
    trx_requested_lock_id,
    trx_wait_started,
    TIME_TO_SEC(TIMEDIFF(NOW(), trx_wait_started)) as wait_time_seconds,
    trx_mysql_thread_id,
    trx_query
FROM information_schema.innodb_trx 
WHERE trx_state = 'LOCK WAIT';

-- æŸ¥çœ‹é”ä¿¡æ¯
SELECT 
    lock_id,
    lock_trx_id,
    lock_mode,
    lock_type,
    lock_table,
    lock_index,
    lock_space,
    lock_page,
    lock_rec,
    lock_data
FROM information_schema.innodb_locks;
```

#### å®æ—¶é”ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# mysql_lock_monitor.sh

ALERT_EMAIL="dba@company.com"
LOG_FILE="/var/log/mysql/lock_monitor.log"
ALERT_THRESHOLD_SECONDS=30

# ç›‘æ§é”ç­‰å¾…
monitor_lock_waits() {
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # æŸ¥è¯¢é•¿æ—¶é—´ç­‰å¾…çš„äº‹åŠ¡
    local long_waits=$(mysql -e "
        SELECT 
            trx_id,
            trx_mysql_thread_id,
            trx_query,
            TIME_TO_SEC(TIMEDIFF(NOW(), trx_wait_started)) as wait_time
        FROM information_schema.innodb_trx 
        WHERE trx_state = 'LOCK WAIT' 
        AND trx_wait_started < DATE_SUB(NOW(), INTERVAL $ALERT_THRESHOLD_SECONDS SECOND);
    " --silent --raw)
    
    if [ -n "$long_waits" ]; then
        echo "[$timestamp] Long lock waits detected:" >> $LOG_FILE
        echo "$long_waits" >> $LOG_FILE
        
        # å‘é€å‘Šè­¦é‚®ä»¶
        echo "Long MySQL lock waits detected:
$long_waits" | mail -s "MySQL Lock Wait Alert" $ALERT_EMAIL
    fi
    
    # è®°å½•å½“å‰é”çŠ¶æ€
    local current_locks=$(mysql -e "
        SELECT COUNT(*) as lock_count 
        FROM information_schema.innodb_locks;
    " --silent --raw | tail -1)
    
    echo "[$timestamp] Current active locks: $current_locks" >> $LOG_FILE
}

# åˆ†æé”ç­‰å¾…é“¾
analyze_lock_chain() {
    local lock_chain_info=$(mysql -e "
        SELECT 
            CONCAT('Blocked: Thread ', r.trx_mysql_thread_id, 
                   ' waiting for ', r.trx_query) as blocked_info,
            CONCAT('Blocking: Thread ', b.trx_mysql_thread_id, 
                   ' running ', b.trx_query) as blocking_info,
            TIME_TO_SEC(TIMEDIFF(NOW(), r.trx_wait_started)) as wait_duration
        FROM information_schema.innodb_lock_waits w
        INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
        INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id
        ORDER BY wait_duration DESC;
    " --silent --raw)
    
    if [ -n "$lock_chain_info" ]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] Lock chain analysis:" >> $LOG_FILE
        echo "$lock_chain_info" >> $LOG_FILE
    fi
}

# æ‰§è¡Œç›‘æ§
monitor_lock_waits
analyze_lock_chain
```

### 2. æ­»é”è¯Šæ–­å’Œå¤„ç†

#### æ­»é”æ—¥å¿—åˆ†æ
```sql
-- å¯ç”¨æ­»é”æ—¥å¿—è®°å½•
SET GLOBAL innodb_print_all_deadlocks = ON;

-- æŸ¥çœ‹æœ€è¿‘çš„æ­»é”ä¿¡æ¯
SHOW ENGINE INNODB STATUS;

-- ä»é”™è¯¯æ—¥å¿—ä¸­æå–æ­»é”ä¿¡æ¯
-- tail -f /var/log/mysql/error.log | grep -i deadlock

-- æ­»é”å†å²è®°å½•è¡¨
CREATE TABLE deadlock_log (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    trx_id VARCHAR(20),
    trx_query TEXT,
    deadlock_info LONGTEXT,
    resolved BOOLEAN DEFAULT FALSE
);

-- è‡ªåŠ¨è®°å½•æ­»é”çš„è§¦å‘å™¨
DELIMITER //
CREATE PROCEDURE log_deadlock_info()
BEGIN
    DECLARE deadlock_info LONGTEXT;
    
    -- è·å–æœ€æ–°çš„æ­»é”ä¿¡æ¯
    SELECT ENGINE_TRANSACTION_INFO INTO deadlock_info
    FROM information_schema.ENGINES 
    WHERE ENGINE = 'InnoDB';
    
    -- è®°å½•åˆ°æ—¥å¿—è¡¨
    INSERT INTO deadlock_log (deadlock_info) VALUES (deadlock_info);
END //
DELIMITER ;
```

#### æ­»é”åˆ†æå·¥å…·
```python
#!/usr/bin/env python3
# mysql_deadlock_analyzer.py

import mysql.connector
import re
from datetime import datetime
from collections import defaultdict

class MySQLDeadlockAnalyzer:
    def __init__(self, connection_config):
        self.config = connection_config
        self.deadlocks = []
        
    def get_deadlock_info(self):
        """è·å–æ­»é”ä¿¡æ¯"""
        try:
            conn = mysql.connector.connect(**self.config)
            cursor = conn.cursor()
            
            cursor.execute("SHOW ENGINE INNODB STATUS")
            result = cursor.fetchone()
            
            if result and result[2]:
                deadlock_info = result[2]
                self.parse_deadlock_info(deadlock_info)
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            print(f"Error connecting to MySQL: {e}")
    
    def parse_deadlock_info(self, status_output):
        """è§£ææ­»é”ä¿¡æ¯"""
        # æŸ¥æ‰¾æ­»é”éƒ¨åˆ†
        deadlock_pattern = r"------------------------\nLATEST DETECTED DEADLOCK\n------------------------\n(.*?)------------\nTRANSACTIONS"
        deadlock_match = re.search(deadlock_pattern, status_output, re.DOTALL)
        
        if deadlock_match:
            deadlock_text = deadlock_match.group(1)
            deadlock_data = self.extract_deadlock_details(deadlock_text)
            self.deadlocks.append(deadlock_data)
    
    def extract_deadlock_details(self, deadlock_text):
        """æå–æ­»é”è¯¦ç»†ä¿¡æ¯"""
        deadlock_info = {
            'timestamp': None,
            'transactions': [],
            'resource_conflicts': [],
            'resolution': None
        }
        
        # æå–æ—¶é—´æˆ³
        timestamp_pattern = r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})"
        timestamp_match = re.search(timestamp_pattern, deadlock_text)
        if timestamp_match:
            deadlock_info['timestamp'] = timestamp_match.group(1)
        
        # æå–äº‹åŠ¡ä¿¡æ¯
        transaction_pattern = r"TRANSACTION (\w+), ACTIVE.*?\n(.*?)(?=TRANSACTION|\*\*\* \(1\) WAITING FOR)"
        transactions = re.findall(transaction_pattern, deadlock_text, re.DOTALL)
        
        for trx_id, trx_info in transactions:
            transaction_data = {
                'id': trx_id,
                'query': None,
                'holding_locks': [],
                'waiting_for': None
            }
            
            # æå–æŸ¥è¯¢è¯­å¥
            query_pattern = r"mysql tables in use.*?\n(.*?)\n"
            query_match = re.search(query_pattern, trx_info, re.DOTALL)
            if query_match:
                transaction_data['query'] = query_match.group(1).strip()
            
            # æå–æŒæœ‰çš„é”
            holding_pattern = r"(\w+) locks rec but not gap on .*?index (.+?) of table (.+?) trx id (\w+)"
            holding_matches = re.findall(holding_pattern, trx_info)
            transaction_data['holding_locks'] = holding_matches
            
            deadlock_info['transactions'].append(transaction_data)
        
        return deadlock_info
    
    def analyze_deadlock_patterns(self):
        """åˆ†ææ­»é”æ¨¡å¼"""
        pattern_stats = defaultdict(int)
        
        for deadlock in self.deadlocks:
            # åˆ†ææ¶‰åŠçš„è¡¨
            tables_involved = set()
            for transaction in deadlock['transactions']:
                for lock_info in transaction['holding_locks']:
                    if len(lock_info) > 2:
                        tables_involved.add(lock_info[2])
            
            pattern_key = f"tables:{len(tables_involved)}_txns:{len(deadlock['transactions'])}"
            pattern_stats[pattern_key] += 1
        
        return dict(pattern_stats)
    
    def generate_prevention_recommendations(self):
        """ç”Ÿæˆé¢„é˜²å»ºè®®"""
        recommendations = []
        
        pattern_stats = self.analyze_deadlock_patterns()
        
        # åŸºäºæ¨¡å¼çš„å»ºè®®
        for pattern, count in pattern_stats.items():
            if count > 3:  # åŒä¸€æ¨¡å¼å‡ºç°å¤šæ¬¡
                recommendations.append({
                    'type': 'PATTERN_BASED',
                    'pattern': pattern,
                    'occurrences': count,
                    'recommendation': 'åˆ†æè¯¥æ¨¡å¼çš„æŸ¥è¯¢é¡ºåºï¼Œç»Ÿä¸€è®¿é—®é¡ºåº'
                })
        
        # é€šç”¨é¢„é˜²å»ºè®®
        recommendations.extend([
            {
                'type': 'GENERAL',
                'pattern': 'all_patterns',
                'recommendation': 'å®æ–½ä¸€è‡´çš„èµ„æºè®¿é—®é¡ºåº'
            },
            {
                'type': 'GENERAL',
                'pattern': 'all_patterns',
                'recommendation': 'å‡å°‘äº‹åŠ¡æŒæœ‰é”çš„æ—¶é—´'
            },
            {
                'type': 'GENERAL',
                'pattern': 'all_patterns',
                'recommendation': 'ä½¿ç”¨è¾ƒä½çš„äº‹åŠ¡éš”ç¦»çº§åˆ«'
            }
        ])
        
        return recommendations
    
    def export_analysis_report(self, filename):
        """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
        report = {
            'generated_at': datetime.now().isoformat(),
            'total_deadlocks_analyzed': len(self.deadlocks),
            'deadlock_patterns': self.analyze_deadlock_patterns(),
            'prevention_recommendations': self.generate_prevention_recommendations(),
            'recent_deadlocks': self.deadlocks[-10:] if self.deadlocks else []
        }
        
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = MySQLDeadlockAnalyzer({
        'host': 'localhost',
        'user': 'root',
        'password: "${DB_PASSWORD}",
        'database': 'information_schema'
    })
    
    analyzer.get_deadlock_info()
    analyzer.export_analysis_report('/var/reports/mysql_deadlock_analysis.json')
```

### 3. é”ä¼˜åŒ–ç­–ç•¥

#### äº‹åŠ¡ä¼˜åŒ–
```sql
-- ä¼˜åŒ–äº‹åŠ¡éš”ç¦»çº§åˆ«
-- æŸ¥çœ‹å½“å‰éš”ç¦»çº§åˆ«
SELECT @@transaction_isolation;

-- è®¾ç½®åˆé€‚çš„éš”ç¦»çº§åˆ«
SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;
-- æˆ–è€…åœ¨åº”ç”¨å±‚è®¾ç½®
-- SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;

-- äº‹åŠ¡è¶…æ—¶è®¾ç½®
SET SESSION innodb_lock_wait_timeout = 50; -- 50ç§’è¶…æ—¶
SET SESSION deadlock_detection = ON;

-- æ‰¹é‡æ“ä½œä¼˜åŒ–
-- é¿å…å¤§äº‹åŠ¡
START TRANSACTION;
    -- åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æäº¤
    INSERT INTO large_table SELECT * FROM temp_table LIMIT 1000;
    COMMIT;
    
    START TRANSACTION;
    INSERT INTO large_table SELECT * FROM temp_table LIMIT 1000 OFFSET 1000;
    COMMIT;
-- ç»§ç»­åˆ†æ‰¹...

-- ç´¢å¼•ä¼˜åŒ–å‡å°‘é”ç«äº‰
-- æ·»åŠ è¦†ç›–ç´¢å¼•å‡å°‘å›è¡¨
CREATE INDEX idx_orders_covering ON orders(user_id, status, created_at, total_amount);

-- ä¼˜åŒ–æŸ¥è¯¢å‡å°‘é”èŒƒå›´
-- é¿å…å…¨è¡¨æ‰«æ
EXPLAIN SELECT * FROM orders WHERE user_id = 123;
-- ç¡®ä¿ä½¿ç”¨ç´¢å¼•
```

#### åº”ç”¨å±‚é”ä¼˜åŒ–
```python
# åº”ç”¨å±‚é”ä¼˜åŒ–ç¤ºä¾‹
import threading
import time
from contextlib import contextmanager

class DatabaseLockManager:
    def __init__(self, db_connection):
        self.db = db_connection
        self.lock_timeout = 30  # 30ç§’è¶…æ—¶
        
    @contextmanager
    def acquire_lock(self, lock_name, timeout=None):
        """è·å–åº”ç”¨å±‚é”"""
        timeout = timeout or self.lock_timeout
        lock_acquired = False
        
        try:
            # å°è¯•è·å–é”
            cursor = self.db.cursor()
            cursor.execute(
                "SELECT GET_LOCK(%s, %s)", 
                (lock_name, timeout)
            )
            result = cursor.fetchone()[0]
            
            if result == 1:
                lock_acquired = True
                yield True
            else:
                yield False
                
        finally:
            # é‡Šæ”¾é”
            if lock_acquired:
                cursor.execute("SELECT RELEASE_LOCK(%s)", (lock_name,))
            cursor.close()
    
    def optimize_transaction_order(self, operations):
        """ä¼˜åŒ–äº‹åŠ¡æ“ä½œé¡ºåº"""
        # æŒ‰èµ„æºIDæ’åºï¼Œé¿å…æ­»é”
        sorted_operations = sorted(operations, key=lambda x: x['resource_id'])
        return sorted_operations

# ä½¿ç”¨ç¤ºä¾‹
def transfer_money(from_account, to_account, amount):
    lock_manager = DatabaseLockManager(get_db_connection())
    
    # æŒ‰è´¦æˆ·IDæ’åºè·å–é”
    accounts = sorted([from_account, to_account])
    
    with lock_manager.acquire_lock(f"account_{accounts[0]}"):
        with lock_manager.acquire_lock(f"account_{accounts[1]}"):
            # æ‰§è¡Œè½¬è´¦æ“ä½œ
            execute_transfer(from_account, to_account, amount)

def batch_update_products(product_ids, updates):
    """æ‰¹é‡æ›´æ–°äº§å“ï¼Œé¿å…å¤§äº‹åŠ¡"""
    lock_manager = DatabaseLockManager(get_db_connection())
    
    # æŒ‰IDæ’åº
    sorted_ids = sorted(product_ids)
    
    # åˆ†æ‰¹å¤„ç†
    batch_size = 100
    for i in range(0, len(sorted_ids), batch_size):
        batch_ids = sorted_ids[i:i + batch_size]
        
        with lock_manager.acquire_lock("batch_update_lock", timeout=60):
            # æ‰§è¡Œæ‰¹é‡æ›´æ–°
            update_products_batch(batch_ids, updates)
            time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿé¿å…é”ç«äº‰
```

---

## ğŸ˜ PostgreSQLé”ç­‰å¾…åˆ†æå®è·µ

### 1. é”ç›‘æ§å’Œè¯Šæ–­

#### é”çŠ¶æ€æŸ¥è¯¢
```sql
-- æŸ¥çœ‹å½“å‰é”ä¿¡æ¯
SELECT 
    l.locktype,
    l.database,
    l.relation::regclass as relation_name,
    l.page,
    l.tuple,
    l.virtualxid,
    l.transactionid,
    l.classid::regclass as class_name,
    l.objid,
    l.objsubid,
    l.virtualtransaction,
    l.pid,
    l.mode,
    l.granted,
    a.usename,
    a.application_name,
    a.client_addr,
    a.backend_start,
    a.state,
    a.query
FROM pg_locks l
LEFT JOIN pg_stat_activity a ON l.pid = a.pid
ORDER BY l.granted DESC, l.pid;

-- æŸ¥çœ‹é˜»å¡å’Œç­‰å¾…å…³ç³»
SELECT 
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity 
    ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity 
    ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- æŸ¥çœ‹é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡
SELECT 
    pid,
    usename,
    application_name,
    client_addr,
    backend_start,
    state_change,
    state,
    query
FROM pg_stat_activity 
WHERE state = 'active' 
AND backend_start < NOW() - INTERVAL '5 minutes'
ORDER BY backend_start;
```

#### é”ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# postgres_lock_monitor.sh

PG_CONN="dbname=myapp user=postgres"
ALERT_EMAIL="dba@company.com"
LOG_FILE="/var/log/postgresql/lock_monitor.log"
ALERT_THRESHOLD_MINUTES=5

# ç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡
monitor_long_transactions() {
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    local long_transactions=$(psql $PG_CONN -t -c "
        SELECT 
            pid,
            usename,
            application_name,
            client_addr,
            EXTRACT(EPOCH FROM (NOW() - backend_start))/60 as duration_minutes,
            state,
            query
        FROM pg_stat_activity 
        WHERE state = 'active' 
        AND backend_start < NOW() - INTERVAL '${ALERT_THRESHOLD_MINUTES} minutes'
        ORDER BY backend_start;
    " 2>/dev/null)
    
    if [ -n "$long_transactions" ]; then
        echo "[$timestamp] Long running transactions detected:" >> $LOG_FILE
        echo "$long_transactions" >> $LOG_FILE
        
        echo "Long PostgreSQL transactions detected:
$long_transactions" | mail -s "PostgreSQL Long Transaction Alert" $ALERT_EMAIL
    fi
}

# ç›‘æ§é”ç­‰å¾…
monitor_lock_waits() {
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    local lock_waits=$(psql $PG_CONN -t -c "
        SELECT 
            blocked_locks.pid AS blocked_pid,
            blocked_activity.usename AS blocked_user,
            blocking_locks.pid AS blocking_pid,
            blocking_activity.usename AS blocking_user,
            EXTRACT(EPOCH FROM (NOW() - blocked_activity.state_change))/60 as wait_minutes,
            blocked_activity.query AS blocked_statement,
            blocking_activity.query AS blocking_statement
        FROM pg_catalog.pg_locks blocked_locks
        JOIN pg_catalog.pg_stat_activity blocked_activity 
            ON blocked_activity.pid = blocked_locks.pid
        JOIN pg_catalog.pg_locks blocking_locks 
            ON blocking_locks.locktype = blocked_locks.locktype
            AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
            AND blocking_locks.pid != blocked_locks.pid
        JOIN pg_catalog.pg_stat_activity blocking_activity 
            ON blocking_activity.pid = blocking_locks.pid
        WHERE NOT blocked_locks.granted
        AND blocked_activity.state_change < NOW() - INTERVAL '2 minutes'
        ORDER BY wait_minutes DESC;
    " 2>/dev/null)
    
    if [ -n "$lock_waits" ]; then
        echo "[$timestamp] Lock waits detected:" >> $LOG_FILE
        echo "$lock_waits" >> $LOG_FILE
        
        echo "PostgreSQL lock waits detected:
$lock_waits" | mail -s "PostgreSQL Lock Wait Alert" $ALERT_EMAIL
    fi
}

# æ‰§è¡Œç›‘æ§
monitor_long_transactions
monitor_lock_waits
```

### 2. æ­»é”å¤„ç†æœºåˆ¶

#### æ­»é”æ£€æµ‹å’Œå¤„ç†
```sql
-- å¯ç”¨æ­»é”æ£€æµ‹
ALTER SYSTEM SET deadlock_timeout = '1s';
SELECT pg_reload_conf();

-- æŸ¥çœ‹æ­»é”ç›¸å…³ä¿¡æ¯
SELECT 
    datname,
    usename,
    application_name,
    client_addr,
    state,
    wait_event_type,
    wait_event,
    state_change,
    query
FROM pg_stat_activity 
WHERE wait_event_type = 'Lock';

-- æ­»é”æ—¥å¿—åˆ†æ
-- åœ¨postgresql.confä¸­é…ç½®
-- log_lock_waits = on
-- log_statement = 'all'
-- log_min_duration_statement = 1000

-- åˆ›å»ºæ­»é”ç›‘æ§è§†å›¾
CREATE VIEW deadlock_analysis AS
SELECT 
    blocked.pid AS blocked_pid,
    blocked.usename AS blocked_user,
    blocked.application_name AS blocked_app,
    blocked.client_addr AS blocked_client,
    blocked.query AS blocked_query,
    blocking.pid AS blocking_pid,
    blocking.usename AS blocking_user,
    blocking.application_name AS blocking_app,
    blocking.client_addr AS blocking_client,
    blocking.query AS blocking_query,
    EXTRACT(EPOCH FROM (NOW() - blocked.state_change)) AS wait_seconds
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked 
    ON blocked.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking 
    ON blocking.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted
AND blocked.state = 'active';
```

#### æ­»é”é¢„é˜²ç­–ç•¥
```sql
-- åº”ç”¨å±‚æ­»é”é¢„é˜²
-- 1. ä¸€è‡´çš„è®¿é—®é¡ºåº
CREATE OR REPLACE FUNCTION transfer_funds_consistent(
    from_account_id INTEGER,
    to_account_id INTEGER,
    amount NUMERIC
) RETURNS VOID AS $$
BEGIN
    -- å§‹ç»ˆæŒ‰IDé¡ºåºè·å–é”
    IF from_account_id < to_account_id THEN
        PERFORM pg_advisory_lock(from_account_id);
        PERFORM pg_advisory_lock(to_account_id);
    ELSE
        PERFORM pg_advisory_lock(to_account_id);
        PERFORM pg_advisory_lock(from_account_id);
    END IF;
    
    -- æ‰§è¡Œè½¬è´¦
    UPDATE accounts SET balance = balance - amount WHERE id = from_account_id;
    UPDATE accounts SET balance = balance + amount WHERE id = to_account_id;
    
    -- é‡Šæ”¾é”
    IF from_account_id < to_account_id THEN
        PERFORM pg_advisory_unlock(from_account_id);
        PERFORM pg_advisory_unlock(to_account_id);
    ELSE
        PERFORM pg_advisory_unlock(to_account_id);
        PERFORM pg_advisory_unlock(from_account_id);
    END IF;
END;
$$ LANGUAGE plpgsql;

-- 2. ä½¿ç”¨è¾ƒä½çš„éš”ç¦»çº§åˆ«
BEGIN ISOLATION LEVEL READ COMMITTED;
    -- æ‰§è¡Œæ“ä½œ
    UPDATE inventory SET quantity = quantity - 1 WHERE product_id = 123;
    UPDATE orders SET status = 'processed' WHERE id = 456;
COMMIT;

-- 3. å‡å°‘äº‹åŠ¡æŒæœ‰æ—¶é—´
-- é¿å…åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œé•¿æ—¶é—´æ“ä½œ
BEGIN;
    -- å¿«é€Ÿæ‰§è¡Œæ•°æ®åº“æ“ä½œ
    UPDATE user_sessions SET last_activity = NOW() WHERE user_id = 789;
    -- å¤–éƒ¨APIè°ƒç”¨åº”è¯¥åœ¨äº‹åŠ¡å¤–è¿›è¡Œ
COMMIT;

-- 4. æ‰¹é‡æ“ä½œä¼˜åŒ–
CREATE OR REPLACE FUNCTION batch_update_products(
    product_updates JSONB
) RETURNS INTEGER AS $$
DECLARE
    updated_count INTEGER := 0;
    product_record JSONB;
BEGIN
    -- æŒ‰IDæ’åºå¤„ç†
    FOR product_record IN 
        SELECT jsonb_array_elements(product_updates) 
        ORDER BY (jsonb_array_elements->>'id')::INTEGER
    LOOP
        UPDATE products 
        SET price = (product_record->>'price')::NUMERIC,
            stock = (product_record->>'stock')::INTEGER
        WHERE id = (product_record->>'id')::INTEGER;
        
        updated_count := updated_count + 1;
        
        -- å°æ‰¹é‡æäº¤é¿å…å¤§äº‹åŠ¡
        IF updated_count % 100 = 0 THEN
            COMMIT;
            BEGIN;
        END IF;
    END LOOP;
    
    RETURN updated_count;
END;
$$ LANGUAGE plpgsql;
```

### 3. é”æ€§èƒ½ä¼˜åŒ–

#### ç´¢å¼•ä¼˜åŒ–å‡å°‘é”ç«äº‰
```sql
-- åˆ†æé”ç­‰å¾…çš„æŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS)
SELECT p.name, p.price, c.name as category
FROM products p
JOIN categories c ON p.category_id = c.id
WHERE p.price > 100
ORDER BY p.name;

-- ä¼˜åŒ–ç´¢å¼•å‡å°‘é”èŒƒå›´
-- åˆ›å»ºè¦†ç›–ç´¢å¼•
CREATE INDEX idx_products_price_covering 
ON products(price) INCLUDE (name, category_id);

-- åˆ›å»ºå¤åˆç´¢å¼•ä¼˜åŒ–JOIN
CREATE INDEX idx_products_category_price 
ON products(category_id, price);

-- åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    100.0 * idx_tup_fetch / nullif(idx_tup_read, 0) as fetch_ratio
FROM pg_stat_user_indexes 
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;
```

#### é…ç½®ä¼˜åŒ–
```sql
-- é”ç›¸å…³é…ç½®ä¼˜åŒ–
ALTER SYSTEM SET deadlock_timeout = '1s';           -- æ­»é”æ£€æµ‹è¶…æ—¶
ALTER SYSTEM SET lock_timeout = '30s';              -- é”ç­‰å¾…è¶…æ—¶
ALTER SYSTEM SET max_locks_per_transaction = 128;   -- æ¯äº‹åŠ¡æœ€å¤§é”æ•°
ALTER SYSTEM SET max_pred_locks_per_transaction = 128; -- æ¯äº‹åŠ¡é¢„æµ‹é”æ•°

-- å†…å­˜é…ç½®ä¼˜åŒ–
ALTER SYSTEM SET shared_buffers = '2GB';            -- å…±äº«ç¼“å†²åŒº
ALTER SYSTEM SET effective_cache_size = '6GB';      -- æœ‰æ•ˆç¼“å­˜å¤§å°
ALTER SYSTEM SET work_mem = '64MB';                 -- å·¥ä½œå†…å­˜
ALTER SYSTEM SET maintenance_work_mem = '512MB';    -- ç»´æŠ¤å·¥ä½œå†…å­˜

-- é‡æ–°åŠ è½½é…ç½®
SELECT pg_reload_conf();

-- ç›‘æ§é”æ€§èƒ½
SELECT 
    datname,
    usename,
    wait_event_type,
    wait_event,
    state,
    query
FROM pg_stat_activity 
WHERE wait_event_type IS NOT NULL;
```

---

## ğŸƒ MongoDBé”ç­‰å¾…åˆ†æå®è·µ

### 1. MongoDBé”æœºåˆ¶ç›‘æ§

#### é”çŠ¶æ€æŸ¥è¯¢
```javascript
// MongoDBé”ç›‘æ§
use admin

// æŸ¥çœ‹å½“å‰æ“ä½œå’Œé”çŠ¶æ€
db.currentOp({
    "$or": [
        { "lockType": { "$exists": true } },
        { "waitingForLock": true }
    ]
})

// æŸ¥çœ‹æ•°æ®åº“çº§åˆ«çš„é”ä¿¡æ¯
db.serverStatus().locks

// æŸ¥çœ‹å…¨å±€é”ç»Ÿè®¡
db.serverStatus().globalLock

// åˆ†æç‰¹å®šé›†åˆçš„é”æƒ…å†µ
function analyzeCollectionLocks(databaseName, collectionName) {
    const db = db.getSiblingDB(databaseName);
    const collection = db[collectionName];
    
    // è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
    const stats = collection.stats();
    
    print(`=== ${databaseName}.${collectionName} Lock Analysis ===`);
    print(`Document Count: ${stats.count}`);
    print(`Average Object Size: ${stats.avgObjSize} bytes`);
    print(`Storage Size: ${stats.storageSize} bytes`);
    
    // æŸ¥çœ‹æ­£åœ¨è¿›è¡Œçš„æ“ä½œ
    const currentOps = db.currentOp({
        "ns": `${databaseName}.${collectionName}`,
        "waitingForLock": true
    });
    
    if (currentOps.inprog.length > 0) {
        print("\nOperations waiting for locks:");
        currentOps.inprog.forEach(op => {
            print(`- PID: ${op.connectionId}`);
            print(`  Operation: ${op.op}`);
            print(`  Query: ${JSON.stringify(op.query)}`);
            print(`  Waiting Time: ${op.waitingForLock ? 'Yes' : 'No'}`);
            print(`  Lock Type: ${op.lockType || 'None'}`);
        });
    }
    
    return stats;
}

// ä½¿ç”¨ç¤ºä¾‹
analyzeCollectionLocks("myapp", "users");
```

#### å®æ—¶é”ç›‘æ§è„šæœ¬
```python
#!/usr/bin/env python3
# mongodb_lock_monitor.py

from pymongo import MongoClient
from datetime import datetime, timedelta
import json

class MongoDBLockMonitor:
    def __init__(self, connection_string="mongodb://localhost:27017/"):
        self.client = MongoClient(connection_string)
        self.db = self.client.admin
        
    def get_current_operations(self):
        """è·å–å½“å‰æ“ä½œ"""
        try:
            current_ops = self.db.current_op({
                "$or": [
                    {"lockType": {"$exists": True}},
                    {"waitingForLock": True},
                    {"secs_running": {"$gt": 30}}  # è¿è¡Œè¶…è¿‡30ç§’çš„æ“ä½œ
                ]
            })
            return current_ops.get('inprog', [])
        except Exception as e:
            print(f"Error getting current operations: {e}")
            return []
    
    def analyze_lock_contention(self):
        """åˆ†æé”äº‰ç”¨æƒ…å†µ"""
        current_ops = self.get_current_operations()
        
        lock_analysis = {
            'timestamp': datetime.utcnow(),
            'total_operations': len(current_ops),
            'waiting_for_lock': 0,
            'long_running_ops': 0,
            'lock_types': {},
            'problematic_operations': []
        }
        
        for op in current_ops:
            # ç»Ÿè®¡ç­‰å¾…é”çš„æ“ä½œ
            if op.get('waitingForLock'):
                lock_analysis['waiting_for_lock'] += 1
                lock_analysis['problematic_operations'].append({
                    'op': op.get('op'),
                    'ns': op.get('ns'),
                    'secs_running': op.get('secs_running', 0),
                    'desc': op.get('desc', ''),
                    'client': op.get('client', '')
                })
            
            # ç»Ÿè®¡é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
            if op.get('secs_running', 0) > 60:
                lock_analysis['long_running_ops'] += 1
            
            # ç»Ÿè®¡é”ç±»å‹
            lock_type = op.get('lockType', 'unknown')
            lock_analysis['lock_types'][lock_type] = lock_analysis['lock_types'].get(lock_type, 0) + 1
        
        return lock_analysis
    
    def get_database_lock_info(self):
        """è·å–æ•°æ®åº“é”ä¿¡æ¯"""
        try:
            server_status = self.db.command("serverStatus")
            return {
                'globalLock': server_status.get('globalLock', {}),
                'locks': server_status.get('locks', {}),
                'wiredTiger': server_status.get('wiredTiger', {}).get('concurrentTransactions', {})
            }
        except Exception as e:
            print(f"Error getting lock info: {e}")
            return {}
    
    def identify_lock_problems(self, lock_analysis):
        """è¯†åˆ«é”é—®é¢˜"""
        problems = []
        
        # é«˜ç­‰å¾…é”æ¯”ä¾‹
        if lock_analysis['total_operations'] > 0:
            wait_ratio = lock_analysis['waiting_for_lock'] / lock_analysis['total_operations']
            if wait_ratio > 0.3:
                problems.append({
                    'type': 'HIGH_LOCK_WAIT_RATIO',
                    'severity': 'HIGH',
                    'description': f'é”ç­‰å¾…æ¯”ä¾‹è¿‡é«˜: {wait_ratio:.2%}',
                    'current_value': lock_analysis['waiting_for_lock'],
                    'total_operations': lock_analysis['total_operations']
                })
        
        # å¤§é‡é•¿æ—¶é—´è¿è¡Œæ“ä½œ
        if lock_analysis['long_running_ops'] > 10:
            problems.append({
                'type': 'MANY_LONG_RUNNING_OPS',
                'severity': 'HIGH',
                'description': f'å­˜åœ¨{lock_analysis["long_running_ops"]}ä¸ªé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ',
                'threshold': 10
            })
        
        return problems
    
    def generate_recommendations(self, lock_analysis, lock_info):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        problems = self.identify_lock_problems(lock_analysis)
        
        for problem in problems:
            if problem['type'] == 'HIGH_LOCK_WAIT_RATIO':
                recommendations.append({
                    'category': 'IMMEDIATE_ACTION',
                    'issue': problem['description'],
                    'recommendation': 'æ£€æŸ¥å¹¶ä¼˜åŒ–å¼•èµ·é”ç­‰å¾…çš„æŸ¥è¯¢ï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•æˆ–è°ƒæ•´æŸ¥è¯¢é¡ºåº'
                })
            elif problem['type'] == 'MANY_LONG_RUNNING_OPS':
                recommendations.append({
                    'category': 'IMMEDIATE_ACTION',
                    'issue': problem['description'],
                    'recommendation': 'ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œï¼Œåˆ†æå…¶æŸ¥è¯¢è®¡åˆ’å¹¶ä¼˜åŒ–'
                })
        
        # åŸºäºé”ä¿¡æ¯çš„å»ºè®®
        wired_tiger = lock_info.get('wiredTiger', {})
        if wired_tiger:
            read_out = wired_tiger.get('read', {}).get('out', 0)
            write_out = wired_tiger.get('write', {}).get('out', 0)
            
            if read_out > 50 or write_out > 50:
                recommendations.append({
                    'category': 'CONFIGURATION',
                    'issue': f'å¹¶å‘äº‹åŠ¡æ•°è¾ƒé«˜ - è¯»:{read_out}, å†™:{write_out}',
                    'recommendation': 'è€ƒè™‘è°ƒæ•´WiredTigerå¹¶å‘è®¾ç½®æˆ–ä¼˜åŒ–åº”ç”¨ç¨‹åº'
                })
        
        return recommendations
    
    def export_monitoring_report(self, filename):
        """å¯¼å‡ºç›‘æ§æŠ¥å‘Š"""
        lock_analysis = self.analyze_lock_contention()
        lock_info = self.get_database_lock_info()
        recommendations = self.generate_recommendations(lock_analysis, lock_info)
        
        report = {
            'generated_at': datetime.utcnow().isoformat(),
            'lock_analysis': lock_analysis,
            'lock_info': lock_info,
            'identified_problems': self.identify_lock_problems(lock_analysis),
            'optimization_recommendations': recommendations
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        return report

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    monitor = MongoDBLockMonitor()
    report = monitor.export_monitoring_report('/var/reports/mongodb_lock_report.json')
    print(f"é”ç›‘æ§æŠ¥å‘Šå·²ç”Ÿæˆï¼Œå‘ç°é—®é¢˜: {len(report['identified_problems'])}ä¸ª")
```

### 2. é”ä¼˜åŒ–å’Œé¢„é˜²

#### æŸ¥è¯¢ä¼˜åŒ–å‡å°‘é”ç«äº‰
```javascript
// MongoDBæŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹

// 1. æ·»åŠ é€‚å½“ç´¢å¼•å‡å°‘é”èŒƒå›´
db.products.createIndex({ "category": 1, "price": 1 })
db.orders.createIndex({ "userId": 1, "createdAt": -1 })

// 2. ä½¿ç”¨æŠ•å½±å‡å°‘æ•°æ®ä¼ è¾“
// ä¼˜åŒ–å‰
db.users.find({ "status": "active" })

// ä¼˜åŒ–å
db.users.find(
    { "status": "active" }, 
    { "name": 1, "email": 1, "lastLogin": 1, "_id": 0 }
)

// 3. åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
function batchProcessUsers(batchSize = 1000) {
    let skip = 0;
    let processed = 0;
    
    while (true) {
        const users = db.users.find({ "status": "pending" })
                              .skip(skip)
                              .limit(batchSize)
                              .toArray();
        
        if (users.length === 0) break;
        
        // æ‰¹é‡å¤„ç†
        users.forEach(user => {
            // å¤„ç†å•ä¸ªç”¨æˆ·
            db.users.updateOne(
                { "_id": user._id },
                { "$set": { "status": "processed" } }
            );
        });
        
        processed += users.length;
        skip += batchSize;
        
        // çŸ­æš‚å»¶è¿Ÿé¿å…é”ç«äº‰
        sleep(100);
    }
    
    return processed;
}

// 4. ä½¿ç”¨findAndModifyåŸå­æ“ä½œ
function atomicInventoryUpdate(productId, quantityChange) {
    return db.inventory.findAndModify({
        query: { 
            "_id": productId, 
            "quantity": { "$gte": quantityChange > 0 ? 0 : Math.abs(quantityChange) }
        },
        update: { "$inc": { "quantity": quantityChange } },
        new: true
    });
}

// 5. ä¼˜åŒ–èšåˆç®¡é“å‡å°‘ä¸­é—´ç»“æœ
db.orders.aggregate([
    { $match: { "status": "completed", "createdAt": { "$gte": new Date("2024-01-01") } } },
    { $project: { 
        "userId": 1, 
        "totalAmount": 1, 
        "month": { "$month": "$createdAt" } 
    }},
    { $group: { 
        "_id": { "userId": "$userId", "month": "$month" },
        "totalSpent": { "$sum": "$totalAmount" },
        "orderCount": { "$sum": 1 }
    }},
    { $sort: { "totalSpent": -1 } },
    { $limit: 100 }
]);
```

#### åº”ç”¨å±‚é”ç®¡ç†
```python
# MongoDBåº”ç”¨å±‚é”ç®¡ç†
from pymongo import MongoClient, ReadPreference
import threading
import time
from contextlib import contextmanager

class MongoLockManager:
    def __init__(self, connection_string):
        self.client = MongoClient(connection_string)
        self.db = self.client.myapp
        self.lock_collection = self.db.locks
        self.default_timeout = 30  # 30ç§’è¶…æ—¶
        
    @contextmanager
    def distributed_lock(self, lock_name, timeout=None):
        """åˆ†å¸ƒå¼é”å®ç°"""
        timeout = timeout or self.default_timeout
        lock_doc = {
            "_id": lock_name,
            "locked_at": time.time(),
            "expires_at": time.time() + timeout,
            "owner": f"{threading.current_thread().ident}"
        }
        
        try:
            # å°è¯•è·å–é”
            result = self.lock_collection.replace_one(
                {"_id": lock_name, "expires_at": {"$lt": time.time()}},
                lock_doc,
                upsert=True
            )
            
            if result.modified_count > 0 or result.upserted_id:
                yield True
            else:
                yield False
                
        finally:
            # é‡Šæ”¾é”
            self.lock_collection.delete_one({
                "_id": lock_name,
                "owner": f"{threading.current_thread().ident}"
            })
    
    def optimistic_lock_update(self, collection_name, doc_id, updates, version_field="version"):
        """ä¹è§‚é”æ›´æ–°"""
        collection = self.db[collection_name]
        
        # è·å–å½“å‰æ–‡æ¡£
        current_doc = collection.find_one({"_id": doc_id})
        if not current_doc:
            raise ValueError("Document not found")
        
        current_version = current_doc.get(version_field, 0)
        
        # æ·»åŠ ç‰ˆæœ¬å·åˆ°æ›´æ–°æ¡ä»¶
        updates["$inc"] = {version_field: 1}
        
        result = collection.update_one(
            {"_id": doc_id, version_field: current_version},
            updates
        )
        
        if result.modified_count == 0:
            raise Exception("Concurrent modification detected")
        
        return result
    
    def batch_operation_with_retry(self, operation_func, max_retries=3):
        """å¸¦é‡è¯•çš„æ‰¹é‡æ“ä½œ"""
        for attempt in range(max_retries):
            try:
                return operation_func()
            except Exception as e:
                if "E11000 duplicate key" in str(e) or "WriteConflict" in str(e):
                    if attempt < max_retries - 1:
                        time.sleep(0.1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                        continue
                raise e

# ä½¿ç”¨ç¤ºä¾‹
def update_user_profile(user_id, profile_updates):
    lock_manager = MongoLockManager("mongodb://localhost:27017/")
    
    def update_operation():
        with lock_manager.distributed_lock(f"user_profile_{user_id}"):
            # ä½¿ç”¨ä¹è§‚é”æ›´æ–°
            return lock_manager.optimistic_lock_update(
                "users",
                user_id,
                {"$set": profile_updates}
            )
    
    return lock_manager.batch_operation_with_retry(update_operation)

# æ‰¹é‡å¤„ç†ç¤ºä¾‹
def process_batch_orders(order_ids, status_update):
    lock_manager = MongoLockManager("mongodb://localhost:27017/")
    
    # æŒ‰IDæ’åºé¿å…æ­»é”
    sorted_ids = sorted(order_ids)
    
    def batch_operation():
        # åˆ†æ‰¹å¤„ç†
        batch_size = 100
        for i in range(0, len(sorted_ids), batch_size):
            batch_ids = sorted_ids[i:i + batch_size]
            
            with lock_manager.distributed_lock("batch_order_processing"):
                # æ‰¹é‡æ›´æ–°
                result = lock_manager.db.orders.update_many(
                    {"_id": {"$in": batch_ids}},
                    {"$set": {"status": status_update}}
                )
                time.sleep(0.01)  # çŸ­æš‚å»¶è¿Ÿ
                
        return len(sorted_ids)
    
    return lock_manager.batch_operation_with_retry(batch_operation)
```

---

## ğŸ”§ é”é—®é¢˜å¤„ç†æœ€ä½³å®è·µ

### åº”æ€¥å¤„ç†æµç¨‹

#### 1. å¿«é€Ÿè¯Šæ–­æ­¥éª¤
```sql
-- MySQLç´§æ€¥è¯Šæ–­
-- 1. æŸ¥çœ‹å½“å‰é”ç­‰å¾…
SELECT * FROM information_schema.innodb_lock_waits;

-- 2. æŸ¥çœ‹é˜»å¡çš„äº‹åŠ¡
SELECT 
    blocking_trx.trx_mysql_thread_id as blocking_thread,
    blocking_trx.trx_query as blocking_query,
    waiting_trx.trx_mysql_thread_id as waiting_thread,
    waiting_trx.trx_query as waiting_query
FROM information_schema.innodb_lock_waits w
JOIN information_schema.innodb_trx blocking_trx 
    ON blocking_trx.trx_id = w.blocking_trx_id
JOIN information_schema.innodb_trx waiting_trx 
    ON waiting_trx.trx_id = w.requesting_trx_id;

-- 3. ç»ˆæ­¢é—®é¢˜äº‹åŠ¡ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
KILL 12345; -- æ›¿æ¢ä¸ºå®é™…çš„çº¿ç¨‹ID

-- PostgreSQLç´§æ€¥è¯Šæ–­
-- 1. æŸ¥çœ‹é˜»å¡å…³ç³»
SELECT 
    blocked.pid as blocked_pid,
    blocked.query as blocked_query,
    blocking.pid as blocking_pid,
    blocking.query as blocking_query
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked ON blocked.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking ON blocking.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- 2. ç»ˆæ­¢é˜»å¡çš„è¿›ç¨‹
SELECT pg_terminate_backend(blocking_pid) FROM (
    SELECT blocking.pid as blocking_pid
    FROM pg_catalog.pg_locks blocked_locks
    JOIN pg_catalog.pg_stat_activity blocked ON blocked.pid = blocked_locks.pid
    JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.pid != blocked_locks.pid
    JOIN pg_catalog.pg_stat_activity blocking ON blocking.pid = blocking_locks.pid
    WHERE NOT blocked_locks.granted
) blockers;
```

#### 2. é¢„é˜²æªæ–½å®æ–½
```markdown
# é”é—®é¢˜é¢„é˜²æ£€æŸ¥æ¸…å•

## åº”ç”¨å±‚é¢„é˜²
- [ ] å®æ–½ä¸€è‡´çš„èµ„æºè®¿é—®é¡ºåº
- [ ] ä½¿ç”¨åˆé€‚çš„äº‹åŠ¡éš”ç¦»çº§åˆ«
- [ ] å‡å°‘äº‹åŠ¡æŒæœ‰é”çš„æ—¶é—´
- [ ] é¿å…åœ¨äº‹åŠ¡ä¸­æ‰§è¡Œé•¿æ—¶é—´æ“ä½œ
- [ ] å®æ–½åˆç†çš„é‡è¯•æœºåˆ¶

## æ•°æ®åº“å±‚ä¼˜åŒ–
- [ ] æ·»åŠ å¿…è¦çš„ç´¢å¼•å‡å°‘é”èŒƒå›´
- [ ] ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’
- [ ] é…ç½®åˆé€‚çš„é”è¶…æ—¶æ—¶é—´
- [ ] å¯ç”¨æ­»é”æ£€æµ‹å’Œæ—¥å¿—è®°å½•
- [ ] å®šæœŸåˆ†æé”ç­‰å¾…æ¨¡å¼

## ç›‘æ§å‘Šè­¦
- [ ] å»ºç«‹é”ç­‰å¾…ç›‘æ§æœºåˆ¶
- [ ] è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼
- [ ] å®æ–½è‡ªåŠ¨åŒ–çš„é”é—®é¢˜æ£€æµ‹
- [ ] å»ºç«‹å®šæœŸçš„é”æ€§èƒ½è¯„ä¼°
- [ ] å®Œå–„é”é—®é¢˜å¤„ç†æµç¨‹
```

---

## ğŸ“Š é”æ€§èƒ½è¯„ä¼°æŠ¥å‘Šæ¨¡æ¿

```markdown
# æ•°æ®åº“é”æ€§èƒ½è¯„ä¼°æŠ¥å‘Š

## è¯„ä¼°å‘¨æœŸ
2024å¹´1æœˆé”æ€§èƒ½è¯„ä¼°

## é”æ€§èƒ½æŒ‡æ ‡

### MySQLé”æŒ‡æ ‡
| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | çŠ¶æ€ |
|------|--------|--------|------|
| å¹³å‡é”ç­‰å¾…æ—¶é—´ | 2.3ç§’ | < 1ç§’ | âš ï¸ éœ€æ”¹è¿› |
| æ­»é”å‘ç”Ÿé¢‘ç‡ | 3æ¬¡/å¤© | < 1æ¬¡/å‘¨ | âš ï¸ éœ€æ”¹è¿› |
| æœ€å¤§å¹¶å‘é”æ•° | 156ä¸ª | < 100ä¸ª | âš ï¸ éœ€ä¼˜åŒ– |
| é”è¶…æ—¶æ¬¡æ•° | 12æ¬¡/å°æ—¶ | < 5æ¬¡/å°æ—¶ | âš ï¸ éœ€æ”¹è¿› |

### PostgreSQLé”æŒ‡æ ‡
| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | çŠ¶æ€ |
|------|--------|--------|------|
| å¹³å‡äº‹åŠ¡ç­‰å¾…æ—¶é—´ | 1.8ç§’ | < 1ç§’ | âš ï¸ éœ€æ”¹è¿› |
| é˜»å¡äº‹åŠ¡æ•°é‡ | 8ä¸ª | < 3ä¸ª | âš ï¸ éœ€æ”¹è¿› |
| æ­»é”æ£€æµ‹æ¬¡æ•° | 2æ¬¡/å¤© | < 1æ¬¡/å‘¨ | âœ“ æ­£å¸¸ |
| é”å‡çº§é¢‘ç‡ | 15æ¬¡/å°æ—¶ | < 10æ¬¡/å°æ—¶ | âš ï¸ éœ€ä¼˜åŒ– |

## ä¸»è¦é—®é¢˜åˆ†æ

### 1. é”ç­‰å¾…çƒ­ç‚¹è¡¨
- **usersè¡¨**: å¹³å‡ç­‰å¾…æ—¶é—´3.2ç§’ï¼Œä¸»è¦ç”±äºç”¨æˆ·çŠ¶æ€æ›´æ–°å†²çª
- **ordersè¡¨**: å¹³å‡ç­‰å¾…æ—¶é—´2.8ç§’ï¼Œä¸»è¦ç”±äºè®¢å•çŠ¶æ€å˜æ›´
- **inventoryè¡¨**: å¹³å‡ç­‰å¾…æ—¶é—´4.1ç§’ï¼Œä¸»è¦ç”±äºåº“å­˜æ‰£å‡æ“ä½œ

### 2. æ­»é”æ¨¡å¼åˆ†æ
- **æ¨¡å¼1**: ç”¨æˆ·èµ„æ–™æ›´æ–° â†” è®¢å•åˆ›å»º (å 40%)
- **æ¨¡å¼2**: åº“å­˜æ‰£å‡ â†” è®¢å•å–æ¶ˆ (å 35%)
- **æ¨¡å¼3**: æ‰¹é‡å¯¼å…¥ â†” å®æ—¶æŸ¥è¯¢ (å 25%)

## ä¼˜åŒ–å»ºè®®

### ç«‹å³æ‰§è¡Œ
1. ä¸ºusersè¡¨æ·»åŠ statuså­—æ®µç´¢å¼•
2. ä¼˜åŒ–è®¢å•çŠ¶æ€å˜æ›´çš„äº‹åŠ¡é¡ºåº
3. å®æ–½åº“å­˜æ“ä½œçš„é˜Ÿåˆ—æœºåˆ¶

### çŸ­æœŸè®¡åˆ’
1. é‡æ„é«˜å¹¶å‘ä¸šåŠ¡é€»è¾‘
2. å®æ–½åº”ç”¨å±‚åˆ†å¸ƒå¼é”
3. ä¼˜åŒ–æ‰¹é‡æ“ä½œçš„æ‰§è¡Œæ—¶æœº

### é•¿æœŸè§„åˆ’
1. è€ƒè™‘è¯»å†™åˆ†ç¦»æ¶æ„
2. å®æ–½å¾®æœåŠ¡æ‹†åˆ†å‡å°‘æ•°æ®ç«äº‰
3. å»ºç«‹æ™ºèƒ½é”ç®¡ç†å¹³å°

## ROIåˆ†æ
- **ä¼˜åŒ–æŠ•å…¥**: 20äººå¤©å¼€å‘å’Œæµ‹è¯•å·¥ä½œ
- **æ€§èƒ½æå‡**: é¢„æœŸé”ç­‰å¾…æ—¶é—´é™ä½60%
- **ä¸šåŠ¡æ”¶ç›Š**: ç³»ç»Ÿååé‡æå‡40%
- **æŠ•èµ„å›æŠ¥ç‡**: çº¦300%
```

---
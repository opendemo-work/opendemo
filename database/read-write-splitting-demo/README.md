# æ•°æ®åº“è¯»å†™åˆ†ç¦»å®Œæ•´æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æ•°æ®åº“è¯»å†™åˆ†ç¦»æ˜¯æå‡ç³»ç»Ÿæ€§èƒ½å’Œå¯ç”¨æ€§çš„å…³é”®æŠ€æœ¯ï¼Œé€šè¿‡å°†è¯»æ“ä½œå’Œå†™æ“ä½œåˆ†å‘åˆ°ä¸åŒçš„æ•°æ®åº“å®ä¾‹ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œæ€§èƒ½ä¼˜åŒ–ã€‚æœ¬æŒ‡å—æä¾›ä»åŸºç¡€ç†è®ºåˆ°ä¼ä¸šçº§å®è·µçš„å®Œæ•´è¯»å†™åˆ†ç¦»è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

1. [è¯»å†™åˆ†ç¦»åŸºç¡€ç†è®º](#1-è¯»å†™åˆ†ç¦»åŸºç¡€ç†è®º)
2. [MySQLè¯»å†™åˆ†ç¦»å®ç°](#2-mysqlè¯»å†™åˆ†ç¦»å®ç°)
3. [PostgreSQLè¯»å†™åˆ†ç¦»é…ç½®](#3-postgresqlè¯»å†™åˆ†ç¦»é…ç½®)
4. [è´Ÿè½½å‡è¡¡ç­–ç•¥](#4-è´Ÿè½½å‡è¡¡ç­–ç•¥)
5. [æ•…éšœå¤„ç†æœºåˆ¶](#5-æ•…éšœå¤„ç†æœºåˆ¶)
6. [ç›‘æ§ä¸ä¼˜åŒ–](#6-ç›‘æ§ä¸ä¼˜åŒ–)

---

## 1. è¯»å†™åˆ†ç¦»åŸºç¡€ç†è®º

### 1.1 æ ¸å¿ƒæ¦‚å¿µä¸æ¶æ„

#### è¯»å†™åˆ†ç¦»æ¶æ„æ¨¡å¼
```mermaid
graph TD
    A[åº”ç”¨å±‚] --> B[è¯»å†™åˆ†ç¦»ä»£ç†]
    B --> C[ä¸»èŠ‚ç‚¹-å†™æ“ä½œ]
    B --> D[ä»èŠ‚ç‚¹1-è¯»æ“ä½œ]
    B --> E[ä»èŠ‚ç‚¹2-è¯»æ“ä½œ]
    B --> F[ä»èŠ‚ç‚¹3-è¯»æ“ä½œ]
    
    C --> G[æ•°æ®åŒæ­¥]
    G --> D
    G --> E
    G --> F
    
    subgraph "å†™æ“ä½œæµå‘"
        A --> H[INSERT/UPDATE/DELETE]
        H --> B
        B --> C
    end
    
    subgraph "è¯»æ“ä½œæµå‘"
        A --> I[SELECT]
        I --> B
        B --> J[è´Ÿè½½å‡è¡¡]
        J --> D
        J --> E
        J --> F
    end
    
    K[ç›‘æ§ç³»ç»Ÿ] --> B
    K --> C
    K --> D
    K --> E
    K --> F
```

#### è¯»å†™åˆ†ç¦»ä¼˜åŠ¿åˆ†æ
```yaml
read_write_splitting_advantages:
  performance_improvement:
    description: "æ€§èƒ½æå‡"
    benefits: 
      - "è¯»æ“ä½œåˆ†æ•£åˆ°å¤šä¸ªä»èŠ‚ç‚¹"
      - "å†™æ“ä½œé›†ä¸­åœ¨ä¸»èŠ‚ç‚¹"
      - "æ•´ä½“ååé‡æ˜¾è‘—æå‡"
    metrics: "é€šå¸¸å¯æå‡2-5å€è¯»æ€§èƒ½"
  
  availability_enhancement:
    description: "å¯ç”¨æ€§å¢å¼º"
    benefits:
      - "ä»èŠ‚ç‚¹æ•…éšœä¸å½±å“å†™æ“ä½œ"
      - "ä¸»èŠ‚ç‚¹æ•…éšœå¯å¿«é€Ÿåˆ‡æ¢"
      - "ç³»ç»Ÿæ•´ä½“ç¨³å®šæ€§æå‡"
    metrics: "å¯ç”¨æ€§å¯è¾¾åˆ°99.9%ä»¥ä¸Š"
  
  scalability:
    description: "å¯æ‰©å±•æ€§"
    benefits:
      - "å¯æ ¹æ®è¯»è´Ÿè½½åŠ¨æ€å¢åŠ ä»èŠ‚ç‚¹"
      - "æ”¯æŒæ°´å¹³æ‰©å±•"
      - "èµ„æºåˆ©ç”¨æ›´åŠ çµæ´»"
    metrics: "æ”¯æŒæ•°åä¸ªä»èŠ‚ç‚¹æ‰©å±•"
  
  maintenance_flexibility:
    description: "ç»´æŠ¤çµæ´»æ€§"
    benefits:
      - "å¯åœ¨ä»èŠ‚ç‚¹è¿›è¡Œå¤‡ä»½æ“ä½œ"
      - "æ”¯æŒåœ¨çº¿DDLæ“ä½œ"
      - "ä¾¿äºç³»ç»Ÿå‡çº§å’Œç»´æŠ¤"
    metrics: "ç»´æŠ¤çª—å£å¤§å¹…ç¼©çŸ­"
```

### 1.2 å®ç°æ–¹å¼å¯¹æ¯”

#### ä¸»è¦å®ç°æ–¹æ¡ˆ
```python
# è¯»å†™åˆ†ç¦»å®ç°æ–¹æ¡ˆå¯¹æ¯”åˆ†æ
class ReadWriteSplittingComparison:
    def __init__(self):
        self.solutions = {
            'application_level': {
                'description': 'åº”ç”¨å±‚å®ç°',
                'implementation': 'åœ¨åº”ç”¨ä»£ç ä¸­åŒºåˆ†è¯»å†™è¿æ¥',
                'advantages': ['æ§åˆ¶ç²¾ç»†', 'æ€§èƒ½å¥½', 'æ— é¢å¤–ç»„ä»¶'],
                'disadvantages': ['å¼€å‘å¤æ‚', 'ç»´æŠ¤æˆæœ¬é«˜', 'è€¦åˆåº¦é«˜'],
                'use_cases': ['å®šåˆ¶åŒ–éœ€æ±‚å¼º', 'å¯¹æ€§èƒ½è¦æ±‚æé«˜']
            },
            
            'middleware_proxy': {
                'description': 'ä¸­é—´ä»¶ä»£ç†',
                'implementation': 'ä½¿ç”¨æ•°æ®åº“ä»£ç†ä¸­é—´ä»¶',
                'advantages': ['å¯¹åº”ç”¨é€æ˜', 'åŠŸèƒ½ä¸°å¯Œ', 'æ˜“äºç®¡ç†'],
                'disadvantages': ['å¢åŠ ç³»ç»Ÿå¤æ‚åº¦', 'å¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ'],
                'use_cases': ['å¿«é€Ÿéƒ¨ç½²', 'æ ‡å‡†åŒ–éœ€æ±‚']
            },
            
            'database_builtin': {
                'description': 'æ•°æ®åº“å†…ç½®',
                'implementation': 'ä½¿ç”¨æ•°æ®åº“è‡ªå¸¦çš„è¯»å†™åˆ†ç¦»åŠŸèƒ½',
                'advantages': ['é›†æˆåº¦é«˜', 'é…ç½®ç®€å•', 'ç¨³å®šæ€§å¥½'],
                'disadvantages': ['åŠŸèƒ½å—é™', 'å‚å•†ç»‘å®š', 'æ‰©å±•æ€§å·®'],
                'use_cases': ['äº‘æ•°æ®åº“æœåŠ¡', 'æ ‡å‡†åŒ–éƒ¨ç½²']
            }
        }
    
    def recommend_solution(self, requirements):
        """æ ¹æ®éœ€æ±‚æ¨èæ–¹æ¡ˆ"""
        scores = {}
        
        for solution_name, solution in self.solutions.items():
            score = 0
            
            # æ€§èƒ½è¦æ±‚è¯„åˆ†
            if requirements.get('high_performance', False) and 'æ€§èƒ½å¥½' in solution['advantages']:
                score += 30
            
            # å¼€å‘å¤æ‚åº¦è¯„åˆ†
            if requirements.get('quick_deployment', False) and 'é…ç½®ç®€å•' in solution['advantages']:
                score += 25
            
            # ç»´æŠ¤æˆæœ¬è¯„åˆ†
            if requirements.get('low_maintenance', False) and 'æ˜“äºç®¡ç†' in solution['advantages']:
                score += 20
            
            # æ‰©å±•æ€§è¯„åˆ†
            if requirements.get('scalability', False) and 'æ”¯æŒæ°´å¹³æ‰©å±•' in solution['advantages']:
                score += 25
            
            scores[solution_name] = score
        
        best_solution = max(scores, key=scores.get)
        return {
            'recommended': best_solution,
            'score': scores[best_solution],
            'details': self.solutions[best_solution]
        }

# ä½¿ç”¨ç¤ºä¾‹
comparator = ReadWriteSplittingComparison()
requirements = {
    'high_performance': True,
    'quick_deployment': False,
    'low_maintenance': True,
    'scalability': True
}
recommendation = comparator.recommend_solution(requirements)
```

## 2. MySQLè¯»å†™åˆ†ç¦»å®ç°

### 2.1 ä¸»ä»å¤åˆ¶é…ç½®

#### ä¸»èŠ‚ç‚¹é…ç½®
```ini
# my.cnf - MySQLä¸»èŠ‚ç‚¹é…ç½®
[mysqld]
# åŸºç¡€é…ç½®
server-id = 1
log-bin = mysql-bin
binlog-format = ROW
binlog-do-db = your_database
binlog-ignore-db = mysql

# å¤åˆ¶é…ç½®
log-slave-updates = 1
binlog-checksum = CRC32
binlog-row-image = FULL
expire_logs_days = 7
max_binlog_size = 100M

# æ€§èƒ½ä¼˜åŒ–
innodb_flush_log_at_trx_commit = 2
sync_binlog = 1
innodb_buffer_pool_size = 2G
```

#### ä»èŠ‚ç‚¹é…ç½®
```ini
# my.cnf - MySQLä»èŠ‚ç‚¹é…ç½®
[mysqld]
# åŸºç¡€é…ç½®
server-id = 2
relay-log = relay-bin
read-only = 1
skip-slave-start = 1

# å¤åˆ¶é…ç½®
log-slave-updates = 1
relay-log-recovery = 1
slave-net-timeout = 60
slave-skip-errors = ddl_exist_errors

# æ€§èƒ½ä¼˜åŒ–
innodb_buffer_pool_size = 4G
innodb_read_io_threads = 8
innodb_write_io_threads = 8
```

#### å¤åˆ¶åˆå§‹åŒ–è„šæœ¬
```bash
#!/bin/bash
# MySQLä¸»ä»å¤åˆ¶åˆå§‹åŒ–

initialize_mysql_replication() {
    echo "=== MySQLä¸»ä»å¤åˆ¶åˆå§‹åŒ– ==="
    
    # 1. ä¸»èŠ‚ç‚¹å‡†å¤‡
    setup_master() {
        # åˆ›å»ºå¤åˆ¶ç”¨æˆ·
        mysql -e "
            CREATE USER 'repl'@'%' IDENTIFIED BY 'repl_password';
            GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
            FLUSH PRIVILEGES;
        "
        
        # é”å®šè¡¨å¹¶è·å–äºŒè¿›åˆ¶æ—¥å¿—ä½ç½®
        mysql -e "FLUSH TABLES WITH READ LOCK;"
        master_status=$(mysql -e "SHOW MASTER STATUS\G")
        
        # è®°å½•æ—¥å¿—æ–‡ä»¶å’Œä½ç½®
        log_file=$(echo "$master_status" | grep "File:" | awk '{print $2}')
        log_pos=$(echo "$master_status" | grep "Position:" | awk '{print $2}')
        
        # å¤‡ä»½æ•°æ®
        mysqldump --all-databases --single-transaction --flush-logs --master-data=2 > master_backup.sql
        
        # è§£é”è¡¨
        mysql -e "UNLOCK TABLES;"
        
        echo "ä¸»èŠ‚ç‚¹é…ç½®å®Œæˆ"
        echo "æ—¥å¿—æ–‡ä»¶: $log_file"
        echo "æ—¥å¿—ä½ç½®: $log_pos"
    }
    
    # 2. ä»èŠ‚ç‚¹é…ç½®
    setup_slave() {
        local master_host=$1
        local log_file=$2
        local log_pos=$3
        
        # æ¢å¤æ•°æ®
        mysql < master_backup.sql
        
        # é…ç½®ä¸»ä»å…³ç³»
        mysql -e "
            CHANGE MASTER TO
                MASTER_HOST='$master_host',
                MASTER_USER='repl',
                MASTER_password: "${DB_PASSWORD}",
                MASTER_LOG_FILE='$log_file',
                MASTER_LOG_POS=$log_pos;
        "
        
        # å¯åŠ¨å¤åˆ¶
        mysql -e "START SLAVE;"
        
        # éªŒè¯å¤åˆ¶çŠ¶æ€
        sleep 10
        mysql -e "SHOW SLAVE STATUS\G" | grep -E "(Slave_IO_Running|Slave_SQL_Running|Seconds_Behind_Master)"
    }
    
    # æ‰§è¡Œé…ç½®
    setup_master
    setup_slave "master_host" "$log_file" "$log_pos"
}
```

### 2.2 è¯»å†™åˆ†ç¦»ä¸­é—´ä»¶

#### MaxScaleé…ç½®
```ini
# maxscale.cnf - MaxScaleé…ç½®æ–‡ä»¶
[maxscale]
threads=4

# æœåŠ¡å™¨å®šä¹‰
[server1]
type=server
address=master_host
port=3306
protocol=MariaDBBackend

[server2]
type=server
address=slave1_host
port=3306
protocol=MariaDBBackend

[server3]
type=server
address=slave2_host
port=3306
protocol=MariaDBBackend

# ç›‘æ§å™¨é…ç½®
[MariaDB-Monitor]
type=monitor
module=mariadbmon
servers=server1,server2,server3
user=maxscale
passwd=maxscale_password
monitor_interval=2000

# è¯»å†™åˆ†ç¦»æœåŠ¡
[Read-Write-Service]
type=service
router=readwritesplit
servers=server1,server2,server3
user=maxscale
passwd=maxscale_password
max_slave_connections=100%
max_sescmd_history=1000

# ç›‘å¬å™¨é…ç½®
[Read-Write-Listener]
type=listener
service=Read-Write-Service
protocol=MariaDBClient
port=4006
```

#### åº”ç”¨è¿æ¥é…ç½®
```python
# Pythonåº”ç”¨è¿æ¥è¯»å†™åˆ†ç¦»
import pymysql
from pymysql.constants import CLIENT

class ReadWriteSplitConnection:
    def __init__(self, master_config, slave_configs):
        self.master_config = master_config
        self.slave_configs = slave_configs
        self.slave_index = 0
    
    def get_master_connection(self):
        """è·å–ä¸»èŠ‚ç‚¹è¿æ¥ï¼ˆç”¨äºå†™æ“ä½œï¼‰"""
        return pymysql.connect(
            host=self.master_config['host'],
            port=self.master_config['port'],
            user=self.master_config['user'],
            password=self.master_config['password'],
            database=self.master_config['database'],
            client_flag=CLIENT.MULTI_STATEMENTS
        )
    
    def get_slave_connection(self):
        """è·å–ä»èŠ‚ç‚¹è¿æ¥ï¼ˆç”¨äºè¯»æ“ä½œï¼‰"""
        # è½®è¯¢é€‰æ‹©ä»èŠ‚ç‚¹
        slave_config = self.slave_configs[self.slave_index]
        self.slave_index = (self.slave_index + 1) % len(self.slave_configs)
        
        return pymysql.connect(
            host=slave_config['host'],
            port=slave_config['port'],
            user=slave_config['user'],
            password=slave_config['password'],
            database=slave_config['database'],
            client_flag=CLIENT.MULTI_STATEMENTS
        )
    
    def execute_query(self, sql, params=None, write=False):
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        if write or self.is_write_operation(sql):
            conn = self.get_master_connection()
            operation_type = "å†™æ“ä½œ"
        else:
            conn = self.get_slave_connection()
            operation_type = "è¯»æ“ä½œ"
        
        try:
            with conn.cursor() as cursor:
                cursor.execute(sql, params)
                if write:
                    conn.commit()
                    return cursor.rowcount
                else:
                    return cursor.fetchall()
        finally:
            conn.close()
    
    def is_write_operation(self, sql):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå†™æ“ä½œ"""
        write_keywords = ['INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER']
        sql_upper = sql.upper().strip()
        return any(keyword in sql_upper for keyword in write_keywords)

# ä½¿ç”¨ç¤ºä¾‹
db_config = {
    'master': {
        'host': 'master_host',
        'port': 3306,
        'user': 'app_user',
        'password: "${DB_PASSWORD}",
        'database': 'myapp'
    },
    'slaves': [
        {
            'host': 'slave1_host',
            'port': 3306,
            'user': 'app_user',
            'password: "${DB_PASSWORD}",
            'database': 'myapp'
        },
        {
            'host': 'slave2_host',
            'port': 3306,
            'user': 'app_user',
            'password: "${DB_PASSWORD}",
            'database': 'myapp'
        }
    ]
}

db = ReadWriteSplitConnection(db_config['master'], db_config['slaves'])

# è¯»æ“ä½œ
users = db.execute_query("SELECT * FROM users WHERE status = %s", ('active',))

# å†™æ“ä½œ
affected_rows = db.execute_query(
    "UPDATE users SET last_login = NOW() WHERE id = %s", 
    (123,), 
    write=True
)
```

## 3. PostgreSQLè¯»å†™åˆ†ç¦»é…ç½®

### 3.1 é€»è¾‘å¤åˆ¶é…ç½®

#### å‘å¸ƒè€…é…ç½®
```sql
-- ä¸»èŠ‚ç‚¹é…ç½® - åˆ›å»ºå‘å¸ƒ
-- postgresql.conf
wal_level = logical
max_replication_slots = 10
max_wal_senders = 10

-- åˆ›å»ºå¤åˆ¶ç”¨æˆ·
CREATE USER replicator WITH REPLICATION PASSWORD 'rep_password';

-- åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION my_publication FOR TABLE users, orders, products;

-- æˆäºˆæƒé™
GRANT SELECT ON TABLE users, orders, products TO replicator;
```

#### è®¢é˜…è€…é…ç½®
```sql
-- ä»èŠ‚ç‚¹é…ç½® - åˆ›å»ºè®¢é˜…
-- postgresql.conf
wal_level = replica
hot_standby = on

-- åˆ›å»ºè®¢é˜…
CREATE SUBSCRIPTION my_subscription
CONNECTION 'host=master_host port=5432 dbname=mydb user=replicator password=rep_password'
PUBLICATION my_publication;

-- éªŒè¯è®¢é˜…çŠ¶æ€
SELECT subname, subenabled, subslotname FROM pg_subscription;
```

### 3.2 PgBouncerè¯»å†™åˆ†ç¦»

#### PgBounceré…ç½®
```ini
# pgbouncer.ini
[databases]
mydb = host=master_host port=5432 dbname=mydb fallback_application_name=pgbouncer

[pgbouncer]
# åŸºç¡€é…ç½®
pool_mode = transaction
listen_port = 6432
listen_addr = 0.0.0.0
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
admin_users = postgres

# è¿æ¥æ± é…ç½®
default_pool_size = 50
min_pool_size = 10
reserve_pool_size = 10
reserve_pool_timeout = 5

# è¶…æ—¶é…ç½®
server_reset_query = DISCARD ALL
server_check_delay = 30
server_lifetime = 3600
server_idle_timeout = 600

# è¯»å†™åˆ†ç¦»é…ç½®
query_wait_timeout = 120
client_idle_timeout = 0
```

#### HAProxyè´Ÿè½½å‡è¡¡é…ç½®
```haproxy
# haproxy.cfg
global
    daemon
    maxconn 4096
    user haproxy
    group haproxy

defaults
    mode tcp
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

# å†™æ“ä½œè·¯ç”±åˆ°ä¸»èŠ‚ç‚¹
frontend write_frontend
    bind *:5432
    default_backend master_backend

# è¯»æ“ä½œè·¯ç”±åˆ°ä»èŠ‚ç‚¹
frontend read_frontend
    bind *:5433
    default_backend slave_backend

backend master_backend
    server master master_host:5432 check

backend slave_backend
    balance roundrobin
    server slave1 slave1_host:5432 check
    server slave2 slave2_host:5432 check
    server slave3 slave3_host:5432 check
```

## 4. è´Ÿè½½å‡è¡¡ç­–ç•¥

### 4.1 è´Ÿè½½å‡è¡¡ç®—æ³•

#### è´Ÿè½½å‡è¡¡ç­–ç•¥å®ç°
```python
# æ•°æ®åº“è´Ÿè½½å‡è¡¡å™¨
import random
import time
from enum import Enum

class LoadBalancingStrategy(Enum):
    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    RESPONSE_TIME = "response_time"
    RANDOM = "random"

class DatabaseLoadBalancer:
    def __init__(self, servers, strategy=LoadBalancingStrategy.ROUND_ROBIN):
        self.servers = servers
        self.strategy = strategy
        self.current_index = 0
        self.server_stats = {server['host']: {'connections': 0, 'response_time': 0} 
                           for server in servers}
    
    def get_next_server(self):
        """æ ¹æ®ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ªæœåŠ¡å™¨"""
        if self.strategy == LoadBalancingStrategy.ROUND_ROBIN:
            return self._round_robin()
        elif self.strategy == LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN:
            return self._weighted_round_robin()
        elif self.strategy == LoadBalancingStrategy.LEAST_CONNECTIONS:
            return self._least_connections()
        elif self.strategy == LoadBalancingStrategy.RESPONSE_TIME:
            return self._lowest_response_time()
        elif self.strategy == LoadBalancingStrategy.RANDOM:
            return self._random_selection()
    
    def _round_robin(self):
        """è½®è¯¢ç®—æ³•"""
        server = self.servers[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.servers)
        return server
    
    def _weighted_round_robin(self):
        """åŠ æƒè½®è¯¢ç®—æ³•"""
        # æ ¹æ®æƒé‡åˆ†é…é€‰æ‹©æ¦‚ç‡
        total_weight = sum(server.get('weight', 1) for server in self.servers)
        rand_num = random.randint(1, total_weight)
        
        current_weight = 0
        for server in self.servers:
            current_weight += server.get('weight', 1)
            if rand_num <= current_weight:
                return server
    
    def _least_connections(self):
        """æœ€å°‘è¿æ¥ç®—æ³•"""
        return min(self.servers, 
                  key=lambda s: self.server_stats[s['host']]['connections'])
    
    def _lowest_response_time(self):
        """æœ€ä½å“åº”æ—¶é—´ç®—æ³•"""
        return min(self.servers,
                  key=lambda s: self.server_stats[s['host']]['response_time'])
    
    def _random_selection(self):
        """éšæœºé€‰æ‹©ç®—æ³•"""
        return random.choice(self.servers)
    
    def update_server_stats(self, server_host, connections=None, response_time=None):
        """æ›´æ–°æœåŠ¡å™¨ç»Ÿè®¡ä¿¡æ¯"""
        if connections is not None:
            self.server_stats[server_host]['connections'] = connections
        if response_time is not None:
            self.server_stats[server_host]['response_time'] = response_time

# ä½¿ç”¨ç¤ºä¾‹
servers = [
    {'host': 'master_host', 'port': 3306, 'weight': 1, 'role': 'master'},
    {'host': 'slave1_host', 'port': 3306, 'weight': 2, 'role': 'slave'},
    {'host': 'slave2_host', 'port': 3306, 'weight': 2, 'role': 'slave'},
    {'host': 'slave3_host', 'port': 3306, 'weight': 2, 'role': 'slave'}
]

# åˆ›å»ºä¸åŒç­–ç•¥çš„è´Ÿè½½å‡è¡¡å™¨
rr_lb = DatabaseLoadBalancer(servers, LoadBalancingStrategy.ROUND_ROBIN)
wrr_lb = DatabaseLoadBalancer(servers, LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN)
lc_lb = DatabaseLoadBalancer(servers, LoadBalancingStrategy.LEAST_CONNECTIONS)

# æ¨¡æ‹Ÿè¯·æ±‚åˆ†å‘
for i in range(10):
    server = rr_lb.get_next_server()
    print(f"è¯·æ±‚ {i+1}: åˆ†é…åˆ° {server['host']}:{server['port']}")
```

### 4.2 æ™ºèƒ½è·¯ç”±ç­–ç•¥

#### æ™ºèƒ½è¯»å†™è·¯ç”±
```python
# æ™ºèƒ½è¯»å†™è·¯ç”±å™¨
class SmartReadWriteRouter:
    def __init__(self, master_config, slave_configs):
        self.master = master_config
        self.slaves = slave_configs
        self.load_balancer = DatabaseLoadBalancer(slave_configs)
        self.query_classifier = QueryClassifier()
    
    def route_query(self, sql_query, transaction_context=None):
        """æ™ºèƒ½è·¯ç”±æŸ¥è¯¢"""
        # 1. åˆ†ææŸ¥è¯¢ç±»å‹
        query_type = self.query_classifier.classify_query(sql_query)
        
        # 2. æ£€æŸ¥äº‹åŠ¡ä¸Šä¸‹æ–‡
        if transaction_context and transaction_context.get('in_transaction'):
            return self.master  # äº‹åŠ¡å†…æŸ¥è¯¢èµ°ä¸»åº“
        
        # 3. æ ¹æ®æŸ¥è¯¢ç±»å‹è·¯ç”±
        if query_type == 'WRITE':
            return self.master
        elif query_type == 'READ':
            # æ£€æŸ¥æ•°æ®æ–°é²œåº¦è¦æ±‚
            if self.requires_fresh_data(sql_query):
                return self.master
            else:
                return self.load_balancer.get_next_server()
        elif query_type == 'DDL':
            return self.master  # DDLæ“ä½œèµ°ä¸»åº“
        else:
            return self.load_balancer.get_next_server()
    
    def requires_fresh_data(self, query):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœ€æ–°æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦æŸ¥è¯¢åˆšå†™å…¥çš„æ•°æ®
        fresh_indicators = ['LAST_INSERT_ID', 'FOUND_ROWS', 'ROW_COUNT']
        return any(indicator in query.upper() for indicator in fresh_indicators)
    
    def handle_failover(self, failed_server):
        """å¤„ç†æœåŠ¡å™¨æ•…éšœ"""
        if failed_server['host'] == self.master['host']:
            # ä¸»åº“æ•…éšœï¼Œé€‰æ‹©æ–°çš„ä¸»åº“
            self.promote_new_master()
        else:
            # ä»åº“æ•…éšœï¼Œä»è´Ÿè½½å‡è¡¡å™¨ä¸­ç§»é™¤
            self.load_balancer.servers = [
                s for s in self.load_balancer.servers 
                if s['host'] != failed_server['host']
            ]

class QueryClassifier:
    def classify_query(self, sql):
        """SQLæŸ¥è¯¢åˆ†ç±»"""
        sql_upper = sql.strip().upper()
        
        write_keywords = ['INSERT', 'UPDATE', 'DELETE', 'REPLACE', 'CREATE', 'DROP', 'ALTER', 'TRUNCATE']
        ddl_keywords = ['CREATE', 'DROP', 'ALTER', 'TRUNCATE', 'RENAME']
        
        if any(keyword in sql_upper for keyword in write_keywords):
            if any(keyword in sql_upper for keyword in ddl_keywords):
                return 'DDL'
            else:
                return 'WRITE'
        else:
            return 'READ'

# ä½¿ç”¨ç¤ºä¾‹
router = SmartReadWriteRouter(master_config, slave_configs)

queries = [
    "SELECT * FROM users WHERE id = 1",
    "INSERT INTO users (name, email) VALUES ('John', 'john@example.com')",
    "UPDATE users SET last_login = NOW() WHERE id = 1",
    "SELECT LAST_INSERT_ID()",
    "CREATE INDEX idx_email ON users(email)"
]

for query in queries:
    target_server = router.route_query(query)
    print(f"æŸ¥è¯¢: {query}")
    print(f"è·¯ç”±åˆ°: {target_server['host']}:{target_server['port']}")
    print("---")
```

## 5. æ•…éšœå¤„ç†æœºåˆ¶

### 5.1 å¥åº·æ£€æŸ¥ç³»ç»Ÿ

#### æ•°æ®åº“å¥åº·æ£€æŸ¥
```python
# æ•°æ®åº“å¥åº·æ£€æŸ¥ç³»ç»Ÿ
import threading
import time
from datetime import datetime

class HealthChecker:
    def __init__(self, servers, check_interval=30):
        self.servers = servers
        self.check_interval = check_interval
        self.health_status = {server['host']: True for server in servers}
        self.check_thread = None
        self.running = False
    
    def start_health_check(self):
        """å¯åŠ¨å¥åº·æ£€æŸ¥"""
        self.running = True
        self.check_thread = threading.Thread(target=self._health_check_loop)
        self.check_thread.daemon = True
        self.check_thread.start()
    
    def stop_health_check(self):
        """åœæ­¢å¥åº·æ£€æŸ¥"""
        self.running = False
        if self.check_thread:
            self.check_thread.join()
    
    def _health_check_loop(self):
        """å¥åº·æ£€æŸ¥å¾ªç¯"""
        while self.running:
            for server in self.servers:
                is_healthy = self._check_server_health(server)
                self.health_status[server['host']] = is_healthy
                
                if not is_healthy:
                    self._handle_server_failure(server)
            
            time.sleep(self.check_interval)
    
    def _check_server_health(self, server):
        """æ£€æŸ¥å•ä¸ªæœåŠ¡å™¨å¥åº·çŠ¶æ€"""
        try:
            # å°è¯•å»ºç«‹è¿æ¥
            conn = self._create_connection(server)
            
            # æ‰§è¡Œç®€å•æŸ¥è¯¢
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            result = cursor.fetchone()
            cursor.close()
            conn.close()
            
            return result is not None and result[0] == 1
            
        except Exception as e:
            print(f"å¥åº·æ£€æŸ¥å¤±è´¥ {server['host']}: {str(e)}")
            return False
    
    def _handle_server_failure(self, failed_server):
        """å¤„ç†æœåŠ¡å™¨æ•…éšœ"""
        print(f"[{datetime.now()}] æ£€æµ‹åˆ°æœåŠ¡å™¨æ•…éšœ: {failed_server['host']}")
        
        # è®°å½•æ•…éšœä¿¡æ¯
        self._log_failure(failed_server)
        
        # è§¦å‘å‘Šè­¦
        self._trigger_alert(failed_server)
        
        # æ‰§è¡Œæ•…éšœè½¬ç§»ï¼ˆå¦‚æœæ˜¯ä¸»åº“ï¼‰
        if failed_server.get('role') == 'master':
            self._initiate_failover(failed_server)
    
    def get_healthy_servers(self):
        """è·å–å¥åº·çš„æœåŠ¡å™¨åˆ—è¡¨"""
        return [server for server in self.servers 
                if self.health_status[server['host']]]
    
    def is_server_healthy(self, server_host):
        """æ£€æŸ¥æŒ‡å®šæœåŠ¡å™¨æ˜¯å¦å¥åº·"""
        return self.health_status.get(server_host, False)

# ä½¿ç”¨ç¤ºä¾‹
health_checker = HealthChecker(servers, check_interval=15)
health_checker.start_health_check()

# å®šæœŸæ£€æŸ¥å¥åº·çŠ¶æ€
while True:
    healthy_servers = health_checker.get_healthy_servers()
    print(f"å¥åº·æœåŠ¡å™¨æ•°é‡: {len(healthy_servers)}/{len(servers)}")
    time.sleep(60)
```

### 5.2 è‡ªåŠ¨æ•…éšœè½¬ç§»

#### æ•…éšœè½¬ç§»å®ç°
```python
# è‡ªåŠ¨æ•…éšœè½¬ç§»ç³»ç»Ÿ
class FailoverManager:
    def __init__(self, servers, health_checker):
        self.servers = servers
        self.health_checker = health_checker
        self.current_master = self._find_initial_master()
        self.failover_history = []
    
    def _find_initial_master(self):
        """æŸ¥æ‰¾åˆå§‹ä¸»åº“"""
        for server in self.servers:
            if server.get('role') == 'master':
                return server
        return self.servers[0]  # é»˜è®¤ç¬¬ä¸€ä¸ªä¸ºmaster
    
    def monitor_and_failover(self):
        """ç›‘æ§å¹¶æ‰§è¡Œæ•…éšœè½¬ç§»"""
        while True:
            # æ£€æŸ¥ä¸»åº“æ˜¯å¦å¥åº·
            if not self.health_checker.is_server_healthy(self.current_master['host']):
                print("æ£€æµ‹åˆ°ä¸»åº“æ•…éšœï¼Œå¯åŠ¨æ•…éšœè½¬ç§»...")
                self._execute_failover()
            
            time.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def _execute_failover(self):
        """æ‰§è¡Œæ•…éšœè½¬ç§»"""
        failover_start_time = time.time()
        
        # 1. ç¡®è®¤ä¸»åº“ç¡®å®æ•…éšœ
        if self.health_checker.is_server_healthy(self.current_master['host']):
            print("è¯¯æŠ¥ï¼Œä¸»åº“å®é™…ä¸Šå¥åº·")
            return False
        
        # 2. é€‰æ‹©æ–°çš„ä¸»åº“
        new_master = self._select_new_master()
        if not new_master:
            print("æ²¡æœ‰å¯ç”¨çš„ä»åº“è¿›è¡Œæ•…éšœè½¬ç§»")
            return False
        
        # 3. æå‡ä»åº“ä¸ºä¸»åº“
        if self._promote_slave(new_master):
            # 4. é‡æ–°é…ç½®å…¶ä»–ä»åº“æŒ‡å‘æ–°ä¸»åº“
            self._reconfigure_slaves(new_master)
            
            # 5. æ›´æ–°å½“å‰ä¸»åº“
            old_master = self.current_master
            self.current_master = new_master
            
            # 6. è®°å½•æ•…éšœè½¬ç§»å†å²
            self._record_failover(old_master, new_master, failover_start_time)
            
            print(f"æ•…éšœè½¬ç§»å®Œæˆ: {old_master['host']} -> {new_master['host']}")
            return True
        else:
            print("ä»åº“æå‡å¤±è´¥")
            return False
    
    def _select_new_master(self):
        """é€‰æ‹©æ–°çš„ä¸»åº“"""
        healthy_slaves = [
            server for server in self.servers
            if (server.get('role') == 'slave' and 
                self.health_checker.is_server_healthy(server['host']))
        ]
        
        if not healthy_slaves:
            return None
        
        # é€‰æ‹©æ•°æ®æœ€æ¥è¿‘åŸä¸»åº“çš„ä»åº“
        return max(healthy_slaves, key=lambda s: self._data_lag_score(s))
    
    def _promote_slave(self, slave_server):
        """æå‡ä»åº“ä¸ºä¸»åº“"""
        try:
            # è¿æ¥åˆ°ä»åº“æ‰§è¡Œæå‡æ“ä½œ
            conn = self._create_connection(slave_server)
            cursor = conn.cursor()
            
            # åœæ­¢å¤åˆ¶
            cursor.execute("STOP SLAVE;")
            
            # é‡ç½®å¤åˆ¶é…ç½®
            cursor.execute("RESET SLAVE ALL;")
            
            # è®¾ç½®ä¸ºå¯å†™æ¨¡å¼
            cursor.execute("SET GLOBAL read_only = OFF;")
            
            cursor.close()
            conn.close()
            
            # æ›´æ–°æœåŠ¡å™¨è§’è‰²
            slave_server['role'] = 'master'
            return True
            
        except Exception as e:
            print(f"æå‡ä»åº“å¤±è´¥: {str(e)}")
            return False
    
    def _reconfigure_slaves(self, new_master):
        """é‡æ–°é…ç½®ä»åº“æŒ‡å‘æ–°ä¸»åº“"""
        for server in self.servers:
            if (server['host'] != new_master['host'] and 
                self.health_checker.is_server_healthy(server['host'])):
                
                try:
                    self._change_master(server, new_master)
                except Exception as e:
                    print(f"é‡æ–°é…ç½®ä»åº“ {server['host']} å¤±è´¥: {str(e)}")
    
    def _change_master(self, slave_server, new_master):
        """æ›´æ”¹ä»åº“çš„ä¸»åº“é…ç½®"""
        conn = self._create_connection(slave_server)
        cursor = conn.cursor()
        
        # åœæ­¢å½“å‰å¤åˆ¶
        cursor.execute("STOP SLAVE;")
        
        # æ›´æ”¹ä¸»åº“é…ç½®
        change_master_sql = f"""
            CHANGE MASTER TO
                MASTER_HOST='{new_master['host']}',
                MASTER_PORT={new_master['port']},
                MASTER_USER='repl',
                MASTER_password: "${DB_PASSWORD}",
                MASTER_AUTO_POSITION=1;
        """
        cursor.execute(change_master_sql)
        
        # å¯åŠ¨å¤åˆ¶
        cursor.execute("START SLAVE;")
        
        cursor.close()
        conn.close()

# ä½¿ç”¨ç¤ºä¾‹
failover_manager = FailoverManager(servers, health_checker)
failover_thread = threading.Thread(target=failover_manager.monitor_and_failover)
failover_thread.daemon = True
failover_thread.start()
```

## 6. ç›‘æ§ä¸ä¼˜åŒ–

### 6.1 ç›‘æ§æŒ‡æ ‡ä½“ç³»

#### æ ¸å¿ƒç›‘æ§æŒ‡æ ‡
```python
# è¯»å†™åˆ†ç¦»ç›‘æ§ç³»ç»Ÿ
class ReadWriteMonitor:
    def __init__(self, servers):
        self.servers = servers
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
    
    def collect_metrics(self):
        """æ”¶é›†ç›‘æ§æŒ‡æ ‡"""
        metrics = {
            'routing_metrics': self._collect_routing_metrics(),
            'performance_metrics': self._collect_performance_metrics(),
            'health_metrics': self._collect_health_metrics(),
            'replication_metrics': self._collect_replication_metrics()
        }
        
        self.metrics_collector.store_metrics(metrics)
        self._check_alerts(metrics)
        return metrics
    
    def _collect_routing_metrics(self):
        """æ”¶é›†è·¯ç”±æŒ‡æ ‡"""
        return {
            'read_requests': self.metrics_collector.get_counter('read_requests'),
            'write_requests': self.metrics_collector.get_counter('write_requests'),
            'route_decisions': self.metrics_collector.get_counter('route_decisions'),
            'failover_events': self.metrics_collector.get_counter('failover_events')
        }
    
    def _collect_performance_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        performance_data = {}
        
        for server in self.servers:
            server_metrics = self._get_server_performance(server)
            performance_data[server['host']] = server_metrics
        
        return performance_data
    
    def _collect_health_metrics(self):
        """æ”¶é›†å¥åº·æŒ‡æ ‡"""
        return {
            'healthy_servers': len([s for s in self.servers 
                                  if self.health_checker.is_server_healthy(s['host'])]),
            'total_servers': len(self.servers),
            'uptime_percentage': self._calculate_uptime_percentage()
        }
    
    def _collect_replication_metrics(self):
        """æ”¶é›†å¤åˆ¶æŒ‡æ ‡"""
        replication_data = {}
        
        for server in self.servers:
            if server.get('role') == 'slave':
                lag = self._get_replication_lag(server)
                replication_data[server['host']] = {
                    'lag_seconds': lag,
                    'status': 'healthy' if lag < 30 else 'delayed'
                }
        
        return replication_data
    
    def _check_alerts(self, metrics):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []
        
        # æ£€æŸ¥å¤åˆ¶å»¶è¿Ÿ
        for host, rep_data in metrics['replication_metrics'].items():
            if rep_data['lag_seconds'] > 60:
                alerts.append({
                    'type': 'replication_lag',
                    'severity': 'warning',
                    'host': host,
                    'value': rep_data['lag_seconds']
                })
        
        # æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
        health_ratio = (metrics['health_metrics']['healthy_servers'] / 
                       metrics['health_metrics']['total_servers'])
        if health_ratio < 0.7:
            alerts.append({
                'type': 'server_unhealthy',
                'severity': 'critical',
                'value': health_ratio
            })
        
        # å‘é€å‘Šè­¦
        for alert in alerts:
            self.alert_manager.send_alert(alert)

# ç›‘æ§é¢æ¿é…ç½®
monitoring_dashboard = {
    'panels': [
        {
            'title': 'è¯»å†™è¯·æ±‚åˆ†å¸ƒ',
            'type': 'pie_chart',
            'query': 'rate(read_requests) vs rate(write_requests)',
            'refresh_interval': '30s'
        },
        {
            'title': 'æœåŠ¡å™¨å¥åº·çŠ¶æ€',
            'type': 'status_grid',
            'query': 'health_metrics.healthy_servers/total_servers',
            'thresholds': {'0.8': 'yellow', '0.9': 'green'}
        },
        {
            'title': 'å¤åˆ¶å»¶è¿Ÿç›‘æ§',
            'type': 'timeseries',
            'query': 'replication_metrics.lag_seconds',
            'warning_threshold': 30,
            'critical_threshold': 60
        },
        {
            'title': 'æŸ¥è¯¢å“åº”æ—¶é—´',
            'type': 'heatmap',
            'query': 'performance_metrics.response_time',
            'time_range': '1h'
        }
    ]
}
```

### 6.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### è‡ªåŠ¨åŒ–ä¼˜åŒ–ç³»ç»Ÿ
```python
# è¯»å†™åˆ†ç¦»æ€§èƒ½ä¼˜åŒ–å™¨
class PerformanceOptimizer:
    def __init__(self, monitor_system):
        self.monitor = monitor_system
        self.optimization_history = []
    
    def analyze_and_optimize(self):
        """åˆ†æå¹¶ä¼˜åŒ–æ€§èƒ½"""
        metrics = self.monitor.collect_metrics()
        recommendations = self._generate_recommendations(metrics)
        
        for recommendation in recommendations:
            if self._should_apply_optimization(recommendation, metrics):
                self._apply_optimization(recommendation)
                self._record_optimization(recommendation)
    
    def _generate_recommendations(self, metrics):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # è´Ÿè½½å‡è¡¡ä¼˜åŒ–
        load_distribution = self._analyze_load_distribution(metrics)
        if load_distribution['imbalance_ratio'] > 1.5:
            recommendations.append({
                'type': 'load_balancing',
                'action': 'adjust_weights',
                'parameters': self._calculate_optimal_weights(load_distribution)
            })
        
        # è¿æ¥æ± ä¼˜åŒ–
        connection_utilization = self._analyze_connection_usage(metrics)
        if connection_utilization['peak_usage'] > 0.85:
            recommendations.append({
                'type': 'connection_pool',
                'action': 'increase_pool_size',
                'parameters': {'increase_percentage': 20}
            })
        
        # æŸ¥è¯¢è·¯ç”±ä¼˜åŒ–
        routing_efficiency = self._analyze_routing_efficiency(metrics)
        if routing_efficiency['misroute_rate'] > 0.05:
            recommendations.append({
                'type': 'query_routing',
                'action': 'refine_classification_rules',
                'parameters': self._identify_problematic_queries(routing_efficiency)
            })
        
        return recommendations
    
    def _should_apply_optimization(self, recommendation, metrics):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åº”ç”¨ä¼˜åŒ–"""
        # é¿å…é¢‘ç¹ä¼˜åŒ–
        recent_optimizations = [
            opt for opt in self.optimization_history[-10:]
            if opt['type'] == recommendation['type']
        ]
        
        if len(recent_optimizations) > 2:
            return False  # åŒç±»å‹ä¼˜åŒ–è¿‡äºé¢‘ç¹
        
        # æ£€æŸ¥ä¼˜åŒ–æ¡ä»¶
        return self._check_optimization_conditions(recommendation, metrics)
    
    def _apply_optimization(self, recommendation):
        """åº”ç”¨ä¼˜åŒ–å»ºè®®"""
        print(f"åº”ç”¨ä¼˜åŒ–: {recommendation['type']} - {recommendation['action']}")
        
        if recommendation['type'] == 'load_balancing':
            self._adjust_load_balancer_weights(recommendation['parameters'])
        elif recommendation['type'] == 'connection_pool':
            self._resize_connection_pools(recommendation['parameters'])
        elif recommendation['type'] == 'query_routing':
            self._update_routing_rules(recommendation['parameters'])

# æ€§èƒ½åŸºå‡†æµ‹è¯•
def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    test_scenarios = [
        {
            'name': 'çº¯è¯»æµ‹è¯•',
            'queries': ['SELECT * FROM users LIMIT 100'] * 1000,
            'concurrent_users': 50
        },
        {
            'name': 'çº¯å†™æµ‹è¯•',
            'queries': ['INSERT INTO users (name) VALUES (?)'] * 1000,
            'concurrent_users': 20
        },
        {
            'name': 'æ··åˆè¯»å†™æµ‹è¯•',
            'queries': (['SELECT * FROM users WHERE id=?'] * 4 + 
                       ['UPDATE users SET name=? WHERE id=?']) * 200,
            'concurrent_users': 30
        }
    ]
    
    results = {}
    for scenario in test_scenarios:
        print(f"æ‰§è¡Œæµ‹è¯•: {scenario['name']}")
        result = execute_load_test(scenario)
        results[scenario['name']] = result
        print(f"TPS: {result['tps']}, å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']}ms")
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
monitor = ReadWriteMonitor(servers)
optimizer = PerformanceOptimizer(monitor)

# å®šæœŸä¼˜åŒ–
while True:
    optimizer.analyze_and_optimize()
    time.sleep(300)  # æ¯5åˆ†é’Ÿä¼˜åŒ–ä¸€æ¬¡
```

---

## ğŸ” å…³é”®è¦ç‚¹æ€»ç»“

### âœ… è¯»å†™åˆ†ç¦»æˆåŠŸè¦ç´ 
- **åˆç†çš„æ¶æ„è®¾è®¡**ï¼šæ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„å®ç°æ–¹æ¡ˆ
- **å®Œå–„çš„ç›‘æ§ä½“ç³»**ï¼šå®æ—¶ç›‘æ§è·¯ç”±æ•ˆæœå’Œç³»ç»Ÿæ€§èƒ½
- **è‡ªåŠ¨åŒ–çš„æ•…éšœå¤„ç†**ï¼šå»ºç«‹å¯é çš„æ•…éšœæ£€æµ‹å’Œè½¬ç§»æœºåˆ¶
- **æŒç»­çš„æ€§èƒ½ä¼˜åŒ–**ï¼šå®šæœŸåˆ†æå’Œä¼˜åŒ–è·¯ç”±ç­–ç•¥

### âš ï¸ å¸¸è§é£é™©æé†’
- **æ•°æ®ä¸€è‡´æ€§é£é™©**ï¼šä¸»ä»å»¶è¿Ÿå¯èƒ½å¯¼è‡´è¯»å–åˆ°è¿‡æœŸæ•°æ®
- **è·¯ç”±ç­–ç•¥é£é™©**ï¼šå¤æ‚çš„è·¯ç”±é€»è¾‘å¯èƒ½å¼•å…¥æ€§èƒ½ç“¶é¢ˆ
- **æ•…éšœè½¬ç§»é£é™©**ï¼šè‡ªåŠ¨æ•…éšœè½¬ç§»å¯èƒ½å¸¦æ¥çŸ­æš‚çš„æœåŠ¡ä¸­æ–­
- **è¿ç»´å¤æ‚åº¦**ï¼šç›¸æ¯”å•èŠ‚ç‚¹æ¶æ„ï¼Œè¿ç»´å¤æ‚åº¦æ˜¾è‘—å¢åŠ 

### ğŸ¯ æœ€ä½³å®è·µå»ºè®®
1. **æ¸è¿›å¼å®æ–½**ï¼šä»ç®€å•é…ç½®å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åŠŸèƒ½
2. **å……åˆ†æµ‹è¯•**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰å……åˆ†æµ‹è¯•å„ç§åœºæ™¯
3. **æ–‡æ¡£åŒ–é…ç½®**ï¼šè¯¦ç»†è®°å½•æ‰€æœ‰é…ç½®å‚æ•°å’Œå˜æ›´å†å²
4. **ç›‘æ§å‘Šè­¦**ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§å‘Šè­¦ä½“ç³»
5. **å®šæœŸè¯„ä¼°**ï¼šå®šæœŸå›é¡¾å’Œä¼˜åŒ–è¯»å†™åˆ†ç¦»æ•ˆæœ

é€šè¿‡ç§‘å­¦çš„è¯»å†™åˆ†ç¦»è®¾è®¡å’Œå®æ–½ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ•°æ®åº“ç³»ç»Ÿçš„æ€§èƒ½å’Œå¯ç”¨æ€§ï¼Œä¸ºä¼ä¸šä¸šåŠ¡å‘å±•æä¾›å¼ºæœ‰åŠ›çš„æ•°æ®æ”¯æ’‘ã€‚
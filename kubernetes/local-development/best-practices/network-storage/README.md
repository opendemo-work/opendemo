# ğŸŒğŸ’¾ Kubernetes ç½‘ç»œä¸å­˜å‚¨æœ€ä½³é…ç½®æŒ‡å—

> æœ¬åœ° Kubernetes ç¯å¢ƒä¸­çš„ç½‘ç»œå’Œå­˜å‚¨é…ç½®æœ€ä½³å®è·µ

## ğŸ¯ æ¦‚è¿°

åœ¨æœ¬åœ° Kubernetes å¼€å‘ç¯å¢ƒä¸­ï¼Œç½‘ç»œå’Œå­˜å‚¨é…ç½®å¯¹åº”ç”¨æ€§èƒ½å’Œå¼€å‘ä½“éªŒè‡³å…³é‡è¦ã€‚æœ¬æŒ‡å—å°†ä»‹ç»å¦‚ä½•ä¸ºæœ¬åœ°ç¯å¢ƒé…ç½®æœ€ä½³çš„ç½‘ç»œå’Œå­˜å‚¨æ–¹æ¡ˆã€‚

### ğŸ“‹ æ ¸å¿ƒå†…å®¹
- **ç½‘ç»œé…ç½®**ï¼šCNI æ’ä»¶é€‰æ‹©ã€æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡
- **å­˜å‚¨é…ç½®**ï¼šæŒä¹…åŒ–å­˜å‚¨ã€åŠ¨æ€ä¾›åº”ã€å­˜å‚¨æ€§èƒ½ä¼˜åŒ–
- **æ€§èƒ½è°ƒä¼˜**ï¼šç½‘ç»œå’Œå­˜å‚¨æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- **æ•…éšœæ’é™¤**ï¼šå¸¸è§ç½‘ç»œå’Œå­˜å‚¨é—®é¢˜çš„è§£å†³æ–¹æ³•

## ğŸŒ ç½‘ç»œé…ç½®æœ€ä½³å®è·µ

### 1. CNI æ’ä»¶é€‰æ‹©

#### æœ¬åœ°å¼€å‘ç¯å¢ƒæ¨è

```bash
# ä¸åŒå·¥å…·çš„é»˜è®¤ CNI æ’ä»¶
# kind: é»˜è®¤ä½¿ç”¨ kindnet (åŸºäº Calico)
# minikube: é»˜è®¤ä½¿ç”¨ Bridge CNI
# k3s: é»˜è®¤ä½¿ç”¨ Flannel
# Docker Desktop: é»˜è®¤ä½¿ç”¨å†…ç½®ç½‘ç»œ

# ä¸º kind é…ç½®é«˜çº§ CNI (Calico)
install_calico_kind() {
    # åˆ›å»º kind é›†ç¾¤é…ç½®
    cat <<EOF > kind-calico.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
EOF

    # åˆ›å»ºé›†ç¾¤
    kind create cluster --config kind-calico.yaml --name calico-cluster
    
    # å®‰è£… Calico
    kubectl apply -k github.com/projectcalico/calico?ref=v3.26.1
}

# ä¸º minikube é…ç½® CNI
configure_minikube_cni() {
    # ä½¿ç”¨ç‰¹å®š CNI æ’ä»¶
    minikube start --cni=calico
    # æˆ–
    minikube start --cni=cilium
    # æˆ–
    minikube start --cni=auto  # è‡ªåŠ¨é€‰æ‹©
}
```

#### ç½‘ç»œç­–ç•¥é…ç½®

```yaml
# ç½‘ç»œç­–ç•¥ç¤ºä¾‹ - é™åˆ¶åº”ç”¨é—´é€šä¿¡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: restrict-app-communication
  namespace: development
spec:
  podSelector:
    matchLabels:
      app: restricted-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: trusted
    - podSelector:
        matchLabels:
          role: trusted
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: trusted
    ports:
    - protocol: TCP
      port: 53  # DNS
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
```

### 2. æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡

#### DNS é…ç½®ä¼˜åŒ–

```bash
# ä¼˜åŒ– CoreDNS é…ç½®
optimize_coredns() {
    # æŸ¥çœ‹å½“å‰ CoreDNS é…ç½®
    kubectl get cm coredns -n kube-system -o yaml
    
    # åˆ›å»ºä¼˜åŒ–çš„ CoreDNS é…ç½®
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
            pods insecure
            fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
EOF

    # é‡å¯ CoreDNS
    kubectl rollout restart deployment coredns -n kube-system
}

# æµ‹è¯• DNS æ€§èƒ½
test_dns_performance() {
    # åˆ›å»º DNS æµ‹è¯• Pod
    kubectl run dns-test --image=nicolaka/netshoot --rm -it --restart=Never -- \
        bash -c "time nslookup kubernetes.default.svc.cluster.local"
}
```

#### Ingress é…ç½®

```bash
# æœ¬åœ°å¼€å‘ç¯å¢ƒ Ingress é…ç½®
setup_ingress_for_dev() {
    # ä¸º kind é›†ç¾¤å®‰è£… Nginx Ingress Controller
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml
    
    # ç­‰å¾… Ingress Controller å°±ç»ª
    kubectl wait --namespace ingress-nginx \
      --for=condition=ready pod \
      --selector=app.kubernetes.io/component=controller \
      --timeout=90s
    
    # åˆ›å»ºæµ‹è¯• Ingress
    cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dev-app-ingress
  namespace: development
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: dev.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: dev-app-service
            port:
              number: 80
EOF
}

# Ingress è°ƒè¯•
debug_ingress() {
    # æ£€æŸ¥ Ingress çŠ¶æ€
    kubectl get ingress -A
    
    # æ£€æŸ¥ Ingress Controller æ—¥å¿—
    kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller
    
    # æµ‹è¯• Ingress è¿æ¥
    curl -H "Host: dev.local" http://localhost
}
```

### 3. ç½‘ç»œæ€§èƒ½ä¼˜åŒ–

```bash
# ç½‘ç»œæ€§èƒ½æµ‹è¯•
test_network_performance() {
    # åˆ›å»ºç½‘ç»œæ€§èƒ½æµ‹è¯• Pod
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: network-test-server
  namespace: development
spec:
  containers:
  - name: server
    image: nicolaka/netshoot
    command: ["iperf3", "-s"]
---
apiVersion: v1
kind: Service
metadata:
  name: network-test-service
  namespace: development
spec:
  selector:
    name: network-test-server
  ports:
  - protocol: TCP
    port: 5201
    targetPort: 5201
EOF

    # è¿è¡Œå®¢æˆ·ç«¯æµ‹è¯•
    kubectl run network-test-client --image=nicolaka/netshoot --rm -it --restart=Never -- \
        iperf3 -c network-test-service -t 10
}

# ç½‘ç»œå»¶è¿Ÿæµ‹è¯•
test_network_latency() {
    kubectl run latency-test --image=nicolaka/netshoot --rm -it --restart=Never -- \
        bash -c "for i in {1..10}; do time curl -s http://kubernetes.default 2>&1 >/dev/null; done"
}
```

## ğŸ’¾ å­˜å‚¨é…ç½®æœ€ä½³å®è·µ

### 1. æœ¬åœ°å­˜å‚¨æ–¹æ¡ˆ

#### HostPath å­˜å‚¨

```bash
# HostPath å­˜å‚¨é…ç½®
setup_hostpath_storage() {
    # åˆ›å»º HostPath æŒä¹…å·
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  hostPath:
    path: /tmp/local-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-pvc
  namespace: development
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: local-storage
EOF
}

# éªŒè¯ HostPath å­˜å‚¨
verify_hostpath_storage() {
    # åˆ›å»ºæµ‹è¯• Pod
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: storage-test-pod
  namespace: development
spec:
  containers:
  - name: test-container
    image: busybox
    command: ["sh", "-c", "echo 'Hello from PV' > /data/hello.txt && sleep 3600"]
    volumeMounts:
    - name: test-volume
      mountPath: /data
  volumes:
  - name: test-volume
    persistentVolumeClaim:
      claimName: local-pvc
EOF

    # éªŒè¯æ•°æ®å†™å…¥
    sleep 10
    kubectl exec -n development storage-test-pod -- cat /data/hello.txt
}
```

#### Local Path Provisioner

```bash
# å®‰è£… Local Path Provisionerï¼ˆé€‚ç”¨äº k3s å’Œæœ¬åœ°ç¯å¢ƒï¼‰
install_local_path_provisioner() {
    # åˆ›å»º Local Path Provisioner
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: local-path-storage
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: local-path-provisioner-service-account
  namespace: local-path-storage
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: local-path-provisioner-role
rules:
- apiGroups: [""]
  resources: ["nodes", "persistentvolumeclaims"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["endpoints", "persistentvolumes", "pods"]
  verbs: ["*"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "patch"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: local-path-provisioner-bind
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: local-path-provisioner-role
subjects:
- kind: ServiceAccount
  name: local-path-provisioner-service-account
  namespace: local-path-storage
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-path-provisioner
  namespace: local-path-storage
spec:
  replicas: 1
  selector:
    matchLabels:
      app: local-path-provisioner
  template:
    metadata:
      labels:
        app: local-path-provisioner
    spec:
      serviceAccountName: local-path-provisioner-service-account
      containers:
      - name: local-path-provisioner
        image: rancher/local-path-provisioner:v0.0.24
        imagePullPolicy: IfNotPresent
        env:
        - name: LOG_LEVEL
          value: debug
        - name: BACKEND_TYPE
          value: "exec"
        - name: SHARED_FS
          value: "true"
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config-volume
          mountPath: /etc/config
      volumes:
      - name: data
        hostPath:
          path: /opt/local-path-provisioner
          type: DirectoryOrCreate
      - name: config-volume
        configMap:
          name: local-path-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-path-config
  namespace: local-path-storage
data:
  config.json: |-
        {
                "nodePathMap":[
                {
                        "node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",
                        "paths":["/opt/local-path-provisioner"]
                }
                ]
        }
  setup: |-
        #!/bin/sh
        set -eu
        mkdir -m 0777 -p "\$VOLPATH"
  teardown: |-
        #!/bin/sh
        set -eu
        rm -rf "\$VOLPATH"
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-path
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rancher.io/local-path
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
EOF

    echo "Local Path Provisioner å®‰è£…å®Œæˆ"
    echo "ç°åœ¨å¯ä»¥ä½¿ç”¨é»˜è®¤å­˜å‚¨ç±»åˆ›å»º PVC"
}

# ä½¿ç”¨é»˜è®¤å­˜å‚¨ç±»åˆ›å»º PVC
create_default_pvc() {
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: default-pvc
  namespace: development
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  # ä¸æŒ‡å®š storageClassNameï¼Œä½¿ç”¨é»˜è®¤å­˜å‚¨ç±»
EOF
}
```

### 2. å­˜å‚¨æ€§èƒ½ä¼˜åŒ–

#### æ€§èƒ½æµ‹è¯•

```bash
# å­˜å‚¨æ€§èƒ½æµ‹è¯•
test_storage_performance() {
    # åˆ›å»ºå­˜å‚¨æ€§èƒ½æµ‹è¯• Pod
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: storage-performance-test
  namespace: development
spec:
  containers:
  - name: fio-test
    image: polinux/stress
    command: ["/bin/bash", "-c"]
    args:
    - |
      dd if=/dev/zero of=/mnt/test.dat bs=1G count=1 oflag=dsync status=progress
      dd if=/dev/zero of=/mnt/test2.dat bs=1M count=1024 oflag=dsync status=progress
      sync
    volumeMounts:
    - name: test-storage
      mountPath: /mnt
  volumes:
  - name: test-storage
    persistentVolumeClaim:
      claimName: default-pvc
EOF

    # ç­‰å¾…æµ‹è¯•å®Œæˆ
    kubectl wait --for=condition=Ready pod/storage-performance-test -n development --timeout=300s
    kubectl logs storage-performance-test -n development
    kubectl delete pod storage-performance-test -n development
}
```

#### å­˜å‚¨ç±»é…ç½®

```bash
# åˆ›å»ºé«˜æ€§èƒ½å­˜å‚¨ç±»
create_high_performance_sc() {
    cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: high-performance
provisioner: rancher.io/local-path
parameters:
  # æ–‡ä»¶ç³»ç»Ÿç±»å‹
  fsType: ext4
  # æŒ‚è½½é€‰é¡¹
  mountOptions: ["noatime", "nodiratime"]
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
EOF
}

# åˆ›å»ºä½å»¶è¿Ÿå­˜å‚¨ç±»
create_low_latency_sc() {
    cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: low-latency
provisioner: rancher.io/local-path
parameters:
  # ä¼˜åŒ–å‚æ•°
  block: "true"
  # æŒ‚è½½é€‰é¡¹
  mountOptions: ["noatime", "nodiratime", "nobarrier"]
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
EOF
}
```

### 3. å­˜å‚¨ç›‘æ§å’Œç®¡ç†

```bash
# å­˜å‚¨ä½¿ç”¨ç›‘æ§
monitor_storage_usage() {
    echo "=== å­˜å‚¨ä½¿ç”¨æƒ…å†µ ==="
    
    # æŸ¥çœ‹ PV å’Œ PVC
    echo "æŒä¹…å· (PV):"
    kubectl get pv -o wide
    
    echo -e "\næŒä¹…å·å£°æ˜ (PVC):"
    kubectl get pvc --all-namespaces -o wide
    
    # æŸ¥çœ‹å­˜å‚¨ç±»
    echo -e "\nå­˜å‚¨ç±» (StorageClass):"
    kubectl get storageclass -o wide
    
    # æ£€æŸ¥èŠ‚ç‚¹ç£ç›˜ä½¿ç”¨
    echo -e "\nèŠ‚ç‚¹ç£ç›˜ä½¿ç”¨æƒ…å†µ:"
    kubectl get nodes -o json | jq -r '.items[] | {name: .metadata.name, diskPressure: .status.conditions[] | select(.type == "DiskPressure") | .status}'
}

# å­˜å‚¨æ•…éšœè¯Šæ–­
diagnose_storage_issues() {
    local pvc_name=$1
    local namespace=${2:-default}
    
    if [ -z "$pvc_name" ]; then
        echo "ç”¨æ³•: diagnose_storage_issues <pvc-name> [namespace]"
        return 1
    fi
    
    echo "=== è¯Šæ–­ PVC: $pvc_name ==="
    
    # æ£€æŸ¥ PVC çŠ¶æ€
    echo "1. PVC çŠ¶æ€:"
    kubectl describe pvc $pvc_name -n $namespace
    
    # æ£€æŸ¥å…³è”çš„ PV
    local pv_name=$(kubectl get pvc $pvc_name -n $namespace -o jsonpath='{.spec.volumeName}' 2>/dev/null)
    if [ -n "$pv_name" ]; then
        echo -e "\n2. å…³è” PV çŠ¶æ€:"
        kubectl describe pv $pv_name
    fi
    
    # æ£€æŸ¥ç»‘å®šçŠ¶æ€
    local status=$(kubectl get pvc $pvc_name -n $namespace -o jsonpath='{.status.phase}')
    echo -e "\n3. ç»‘å®šçŠ¶æ€: $status"
    
    # æ£€æŸ¥äº‹ä»¶
    echo -e "\n4. ç›¸å…³äº‹ä»¶:"
    kubectl get events -n $namespace --sort-by='.lastTimestamp' | grep -i $pvc_name
}
```

## ğŸ”§ ç½‘ç»œå’Œå­˜å‚¨æ€§èƒ½è°ƒä¼˜

### 1. ç»¼åˆæ€§èƒ½æµ‹è¯•

```bash
# ç½‘ç»œå’Œå­˜å‚¨ç»¼åˆæµ‹è¯•
comprehensive_performance_test() {
    echo "=== ç»¼åˆæ€§èƒ½æµ‹è¯• ==="
    
    # 1. ç½‘ç»œæ€§èƒ½æµ‹è¯•
    echo "1. ç½‘ç»œæ€§èƒ½æµ‹è¯•..."
    test_network_performance
    
    # 2. å­˜å‚¨æ€§èƒ½æµ‹è¯•
    echo "2. å­˜å‚¨æ€§èƒ½æµ‹è¯•..."
    test_storage_performance
    
    # 3. åº”ç”¨æ€§èƒ½æµ‹è¯•
    echo "3. åº”ç”¨æ€§èƒ½æµ‹è¯•..."
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: perf-test-app
  namespace: development
spec:
  replicas: 1
  selector:
    matchLabels:
      app: perf-test-app
  template:
    metadata:
      labels:
        app: perf-test-app
    spec:
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: test-storage
          mountPath: /data
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: test-storage
        persistentVolumeClaim:
          claimName: default-pvc
EOF

    # ç­‰å¾…åº”ç”¨å°±ç»ª
    kubectl wait --for=condition=Ready pod -l app=perf-test-app -n development --timeout=120s
    
    # æµ‹è¯•åº”ç”¨å“åº”æ—¶é—´
    kubectl run test-client --image=nicolaka/netshoot --rm -it --restart=Never -n development -- \
        bash -c "time curl -s http://perf-test-app"
    
    # æ¸…ç†æµ‹è¯•èµ„æº
    kubectl delete deployment perf-test-app -n development
}
```

### 2. èµ„æºé…ç½®ä¼˜åŒ–

```bash
# ç½‘ç»œå’Œå­˜å‚¨èµ„æºä¼˜åŒ–é…ç½®
optimize_resources() {
    # ä¸ºåº”ç”¨é…ç½®åˆç†çš„ç½‘ç»œå’Œå­˜å‚¨èµ„æº
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: optimized-app
  namespace: development
spec:
  replicas: 1
  selector:
    matchLabels:
      app: optimized-app
  template:
    metadata:
      labels:
        app: optimized-app
      annotations:
        # ç½‘ç»œæ³¨è§£
        kubectl.kubernetes.io/default-container: app
    spec:
      # Pod çº§åˆ«çš„ç½‘ç»œé…ç½®
      hostNetwork: false  # ä¸ä½¿ç”¨ä¸»æœºç½‘ç»œ
      dnsPolicy: ClusterFirst  # ä½¿ç”¨é›†ç¾¤ DNS
      # å®¹å™¨é…ç½®
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
        # èµ„æºé™åˆ¶
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
            ephemeral-storage: "100Mi"
          limits:
            memory: "256Mi"
            cpu: "200m"
            ephemeral-storage: "500Mi"
        # å­˜å‚¨é…ç½®
        volumeMounts:
        - name: app-data
          mountPath: /usr/share/nginx/html
          readOnly: false
        # ç½‘ç»œé…ç½®
        securityContext:
          readOnlyRootFilesystem: false
          allowPrivilegeEscalation: false
      # å­˜å‚¨å·
      volumes:
      - name: app-data
        persistentVolumeClaim:
          claimName: default-pvc
      # å®‰å…¨ä¸Šä¸‹æ–‡
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
EOF
}
```

## ğŸš¨ æ•…éšœæ’é™¤å’Œè¯Šæ–­

### 1. ç½‘ç»œæ•…éšœè¯Šæ–­

```bash
# ç½‘ç»œæ•…éšœè¯Šæ–­è„šæœ¬
diagnose_network_issues() {
    echo "=== ç½‘ç»œæ•…éšœè¯Šæ–­ ==="
    
    # 1. æ£€æŸ¥èŠ‚ç‚¹ç½‘ç»œçŠ¶æ€
    echo "1. èŠ‚ç‚¹ç½‘ç»œçŠ¶æ€:"
    kubectl get nodes -o wide
    
    # 2. æ£€æŸ¥ç³»ç»Ÿç»„ä»¶
    echo "2. ç³»ç»Ÿç»„ä»¶çŠ¶æ€:"
    kubectl get pods -n kube-system -o wide
    
    # 3. æ£€æŸ¥ CoreDNS
    echo "3. CoreDNS çŠ¶æ€:"
    kubectl get pods -n kube-system -l k8s-app=kube-dns
    
    # 4. æ£€æŸ¥ CNI æ’ä»¶
    echo "4. CNI æ’ä»¶çŠ¶æ€:"
    kubectl get pods -n kube-system -l k8s-app=calico,k8s-app=flannel,k8s-app=cilium 2>/dev/null || echo "æœªæ‰¾åˆ° CNI æ’ä»¶"
    
    # 5. DNS è§£ææµ‹è¯•
    echo "5. DNS è§£ææµ‹è¯•:"
    kubectl run dns-test --image=busybox --rm -it --restart=Never -- nslookup kubernetes.default
    
    # 6. ç½‘ç»œè¿é€šæ€§æµ‹è¯•
    echo "6. ç½‘ç»œè¿é€šæ€§æµ‹è¯•:"
    kubectl run connectivity-test --image=busybox --rm -it --restart=Never -- ping -c 3 kubernetes.default
}

# Pod ç½‘ç»œè¿é€šæ€§æµ‹è¯•
test_pod_connectivity() {
    local source_pod=$1
    local target_service=$2
    local namespace=${3:-default}
    
    if [ -z "$source_pod" ] || [ -z "$target_service" ]; then
        echo "ç”¨æ³•: test_pod_connectivity <source-pod> <target-service> [namespace]"
        return 1
    fi
    
    kubectl exec $source_pod -n $namespace -- nslookup $target_service
    kubectl exec $source_pod -n $namespace -- ping -c 3 $target_service
}
```

### 2. å­˜å‚¨æ•…éšœè¯Šæ–­

```bash
# å­˜å‚¨æ•…éšœè¯Šæ–­è„šæœ¬
diagnose_storage_issues_detailed() {
    echo "=== å­˜å‚¨æ•…éšœè¯Šæ–­ ==="
    
    # 1. æ£€æŸ¥ PV çŠ¶æ€
    echo "1. æŒä¹…å·çŠ¶æ€:"
    kubectl get pv -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,CAPACITY:.spec.capacity.storage,STORAGECLASS:.spec.storageClassName
    
    # 2. æ£€æŸ¥ PVC çŠ¶æ€
    echo "2. æŒä¹…å·å£°æ˜çŠ¶æ€:"
    kubectl get pvc --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,STATUS:.status.phase,CAPACITY:.spec.resources.requests.storage,STORAGECLASS:.spec.storageClassName
    
    # 3. æ£€æŸ¥å­˜å‚¨ç±»
    echo "3. å­˜å‚¨ç±»çŠ¶æ€:"
    kubectl get storageclass -o custom-columns=NAME:.metadata.name,PROVISIONER:.provisioner,RECLAIMPOLICY:.reclaimPolicy,VOLUMEBINDINGMODE:.volumeBindingMode
    
    # 4. æ£€æŸ¥äº‹ä»¶
    echo "4. å­˜å‚¨ç›¸å…³äº‹ä»¶:"
    kubectl get events --all-namespaces --field-selector reason=ProvisioningFailed,reason=FailedBinding --sort-by='.lastTimestamp'
    
    # 5. æ£€æŸ¥ Pod æŒ‚è½½çŠ¶æ€
    echo "5. Pod æŒ‚è½½çŠ¶æ€:"
    kubectl get pods --all-namespaces -o yaml | grep -A 20 volumeMounts
}
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### 1. è‡ªå®šä¹‰ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# ç½‘ç»œå’Œå­˜å‚¨ç›‘æ§è„šæœ¬ - network-storage-monitor.sh

MONITOR_VERSION="1.0.0"

show_help() {
    echo "Kubernetes ç½‘ç»œå’Œå­˜å‚¨ç›‘æ§å·¥å…· $MONITOR_VERSION"
    echo "ç”¨æ³•: $0 [command] [options]"
    echo ""
    echo "å‘½ä»¤:"
    echo "  status                    - æ˜¾ç¤ºç½‘ç»œå’Œå­˜å‚¨çŠ¶æ€"
    echo "  performance              - è¿è¡Œæ€§èƒ½æµ‹è¯•"
    echo "  diagnose NETWORK|STORAGE - è¯Šæ–­ç‰¹å®šç»„ä»¶"
    echo "  report                   - ç”Ÿæˆç›‘æ§æŠ¥å‘Š"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 status"
    echo "  $0 performance"
    echo "  $0 diagnose NETWORK"
}

show_status() {
    echo "=== Kubernetes ç½‘ç»œå’Œå­˜å‚¨çŠ¶æ€ ==="
    
    echo "ç½‘ç»œçŠ¶æ€:"
    echo "- èŠ‚ç‚¹ç½‘ç»œ: $(kubectl get nodes --no-headers | wc -l) ä¸ªèŠ‚ç‚¹"
    echo "- CoreDNS: $(kubectl get pods -n kube-system -l k8s-app=kube-dns --no-headers | wc -l) ä¸ªå®ä¾‹"
    echo "- Services: $(kubectl get services --all-namespaces --no-headers | wc -l) ä¸ªæœåŠ¡"
    echo "- Endpoints: $(kubectl get endpoints --all-namespaces --no-headers | wc -l) ä¸ªç«¯ç‚¹"
    
    echo -e "\nå­˜å‚¨çŠ¶æ€:"
    echo "- PV: $(kubectl get pv --no-headers | wc -l) ä¸ªå·"
    echo "- PVC: $(kubectl get pvc --all-namespaces --no-headers | wc -l) ä¸ªå£°æ˜"
    echo "- StorageClass: $(kubectl get storageclass --no-headers | wc -l) ä¸ªç±»"
    
    # æ£€æŸ¥èµ„æºä½¿ç”¨
    if kubectl top nodes &>/dev/null; then
        echo -e "\nèŠ‚ç‚¹èµ„æºä½¿ç”¨:"
        kubectl top nodes
    fi
}

run_performance_tests() {
    echo "è¿è¡Œæ€§èƒ½æµ‹è¯•..."
    test_network_performance
    test_storage_performance
}

diagnose_component() {
    local component=$1
    case $component in
        "NETWORK")
            diagnose_network_issues
            ;;
        "STORAGE")
            diagnose_storage_issues_detailed
            ;;
        *)
            echo "é”™è¯¯: æœªçŸ¥ç»„ä»¶ $componentï¼Œæ”¯æŒ NETWORK æˆ– STORAGE"
            return 1
            ;;
    esac
}

generate_report() {
    local report_file="/tmp/network-storage-report-$(date +%Y%m%d-%H%M%S).txt"
    echo "ç”Ÿæˆç›‘æ§æŠ¥å‘Š: $report_file"
    
    {
        echo "Kubernetes ç½‘ç»œå’Œå­˜å‚¨ç›‘æ§æŠ¥å‘Š"
        echo "================================"
        echo "ç”Ÿæˆæ—¶é—´: $(date)"
        echo ""
        
        echo "ç½‘ç»œçŠ¶æ€:"
        kubectl get nodes -o wide
        echo ""
        
        echo "å­˜å‚¨çŠ¶æ€:"
        kubectl get pv,pvc --all-namespaces
        echo ""
        
        echo "å­˜å‚¨ç±»:"
        kubectl get storageclass
        echo ""
        
        echo "CoreDNS çŠ¶æ€:"
        kubectl get pods -n kube-system -l k8s-app=kube-dns
        echo ""
        
        echo "äº‹ä»¶:"
        kubectl get events --all-namespaces --sort-by='.lastTimestamp' | tail -20
    } > $report_file
    
    echo "æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# ä¸»ç¨‹åºé€»è¾‘
case "${1:-status}" in
    "status")
        show_status
        ;;
    "performance")
        run_performance_tests
        ;;
    "diagnose")
        if [ -z "$2" ]; then
            echo "é”™è¯¯: è¯·æŒ‡å®šè¦è¯Šæ–­çš„ç»„ä»¶ (NETWORK|STORAGE)"
            exit 1
        fi
        diagnose_component "$2"
        ;;
    "report")
        generate_report
        ;;
    "help"|*)
        show_help
        ;;
esac
```

## ğŸ¯ æœ€ä½³å®è·µæ€»ç»“

### ç½‘ç»œæœ€ä½³å®è·µ
1. **é€‰æ‹©åˆé€‚çš„ CNI æ’ä»¶**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹© Calicoã€Flannel æˆ– Cilium
2. **é…ç½®ç½‘ç»œç­–ç•¥**ï¼šä½¿ç”¨ NetworkPolicy é™åˆ¶ä¸å¿…è¦çš„ç½‘ç»œè®¿é—®
3. **ä¼˜åŒ– DNS é…ç½®**ï¼šè°ƒæ•´ç¼“å­˜å’Œè´Ÿè½½å‡è¡¡è®¾ç½®
4. **ä½¿ç”¨ Ingress æ§åˆ¶å™¨**ï¼šåˆç†é…ç½®è´Ÿè½½å‡è¡¡å’Œ SSL ç»ˆç»“

### å­˜å‚¨æœ€ä½³å®è·µ
1. **é€‰æ‹©åˆé€‚çš„å­˜å‚¨æ–¹æ¡ˆ**ï¼šæ ¹æ®æ€§èƒ½éœ€æ±‚é€‰æ‹© HostPathã€Local Path æˆ–åŠ¨æ€ä¾›åº”
2. **é…ç½®å­˜å‚¨ç±»**ï¼šä½¿ç”¨ StorageClass å®ç°åŠ¨æ€å­˜å‚¨ä¾›åº”
3. **è®¾ç½®èµ„æºé™åˆ¶**ï¼šä¸ºå­˜å‚¨è®¾ç½®åˆç†çš„è¯·æ±‚å’Œé™åˆ¶
4. **ç›‘æ§å­˜å‚¨ä½¿ç”¨**ï¼šå®šæœŸæ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½

### æ€§èƒ½ä¼˜åŒ–
1. **åˆç†é…ç½®èµ„æº**ï¼šä¸ºåº”ç”¨è®¾ç½®åˆé€‚çš„ CPUã€å†…å­˜å’Œå­˜å‚¨èµ„æº
2. **ä½¿ç”¨ SSD å­˜å‚¨**ï¼šåœ¨å¯èƒ½çš„æƒ…å†µä¸‹ä½¿ç”¨ SSD ä½œä¸ºå­˜å‚¨åç«¯
3. **ä¼˜åŒ–ç½‘ç»œé…ç½®**ï¼šä½¿ç”¨åˆé€‚çš„ç½‘ç»œæ’ä»¶å’Œé…ç½®
4. **å®šæœŸç»´æŠ¤**ï¼šæ¸…ç†æœªä½¿ç”¨çš„èµ„æºï¼Œæ›´æ–°é…ç½®

---

> **ğŸ’¡ æç¤º**: ç½‘ç»œå’Œå­˜å‚¨é…ç½®å¯¹ Kubernetes é›†ç¾¤æ€§èƒ½è‡³å…³é‡è¦ã€‚æ ¹æ®åº”ç”¨éœ€æ±‚é€‰æ‹©åˆé€‚çš„é…ç½®ï¼Œå¹¶å®šæœŸç›‘æ§å’Œä¼˜åŒ–ã€‚

**ç‰ˆæœ¬**: v1.0.0  
**æ›´æ–°æ—¶é—´**: 2026å¹´2æœˆ6æ—¥